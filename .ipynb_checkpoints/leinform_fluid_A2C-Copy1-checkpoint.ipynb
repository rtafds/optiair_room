{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make A2C fluid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.spaces.box import Box\n",
    "\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import PyFoam\n",
    "import PyFoam.FoamInformation\n",
    "from PyFoam.RunDictionary.SolutionDirectory import SolutionDirectory\n",
    "from PyFoam.RunDictionary.ParsedParameterFile import ParsedParameterFile\n",
    "from PyFoam.Basics.DataStructures import Vector\n",
    "from PyFoam.Execution.BasicRunner import BasicRunner\n",
    "from PyFoam.Basics.TemplateFile import TemplateFile\n",
    "import shlex,sys,json\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory\n",
    "CASE = SolutionDirectory(\"../aircond5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行環境の設定\n",
    "# 参考：https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py\n",
    "\n",
    "import cv2\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "\n",
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        '''工夫1のNo-Operationです。リセット後適当なステップの間何もしないようにし、\n",
    "        ゲーム開始の初期状態を様々にすることｆで、特定の開始状態のみで学習するのを防ぐ'''\n",
    "\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = self.unwrapped.np_random.randint(\n",
    "                1, self.noop_max + 1)  # pylint: disable=E1101\n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, done, _ = self.env.step(self.noop_action)\n",
    "            if done:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)\n",
    "\n",
    "\n",
    "class EpisodicLifeEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        '''工夫2のEpisodic Lifeです。1機失敗したときにリセットし、失敗時の状態から次を始める'''\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.was_real_done = done\n",
    "        # check current lives, make loss of life terminal,\n",
    "        # then update lives to handle bonus lives\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if lives < self.lives and lives > 0:\n",
    "            # for Qbert sometimes we stay in lives == 0 condtion for a few frames\n",
    "            # so its important to keep lives > 0, so that we only reset once\n",
    "            # the environment advertises done.\n",
    "            done = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        '''5機とも失敗したら、本当にリセット'''\n",
    "        if self.was_real_done:\n",
    "            obs = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            # no-op step to advance from terminal/lost life state\n",
    "            obs, _, _, _ = self.env.step(0)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs\n",
    "\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        '''工夫3のMax and Skipです。4フレーム連続で同じ行動を実施し、最後の3、4フレームの最大値をとった画像をobsにする'''\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = np.zeros(\n",
    "            (2,)+env.observation_space.shape, dtype=np.uint8)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            if i == self._skip - 2:\n",
    "                self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1:\n",
    "                self._obs_buffer[1] = obs\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # Note that the observation on the done=True frame\n",
    "        # doesn't matter\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "\n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        '''工夫4のWarp frameです。画像サイズをNatureのDQN論文と同じ84x84の白黒にします'''\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.width = 84\n",
    "        self.height = 84\n",
    "        self.observation_space = spaces.Box(low=0, high=255,\n",
    "                                            shape=(self.height, self.width, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (self.width, self.height),\n",
    "                           interpolation=cv2.INTER_AREA)\n",
    "        return frame[:, :, None]\n",
    "\n",
    "\n",
    "class WrapPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        '''PyTorchのミニバッチのインデックス順に変更するラッパー'''\n",
    "        super(WrapPyTorch, self).__init__(env)\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = Box(\n",
    "            self.observation_space.low[0, 0, 0],\n",
    "            self.observation_space.high[0, 0, 0],\n",
    "            [obs_shape[2], obs_shape[1], obs_shape[0]],\n",
    "            dtype=self.observation_space.dtype)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return observation.transpose(2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行環境生成関数の定義\n",
    "\n",
    "# 並列実行環境\n",
    "from baselines.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "\n",
    "\n",
    "def make_env(env_id, seed, rank):\n",
    "    def _thunk():\n",
    "        '''_thunk()がマルチプロセス環境のSubprocVecEnvを実行するのに必要'''\n",
    "\n",
    "        env = gym.make(env_id)\n",
    "        env = NoopResetEnv(env, noop_max=30)\n",
    "        env = MaxAndSkipEnv(env, skip=4)\n",
    "        env.seed(seed + rank)  # 乱数シードの設定\n",
    "        env = EpisodicLifeEnv(env)\n",
    "        env = WarpFrame(env)\n",
    "        env = WrapPyTorch(env)\n",
    "\n",
    "        return env\n",
    "\n",
    "    return _thunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定数の設定\n",
    "\n",
    "ENV_NAME = 'BreakoutNoFrameskip-v4' \n",
    "# Breakout-v0ではなく、BreakoutNoFrameskip-v4を使用\n",
    "# v0はフレームが自動的に2-4のランダムにskipされますが、今回はフレームスキップはさせないバージョンを使用\n",
    "# 参考URL https://becominghuman.ai/lets-build-an-atari-ai-part-1-dqn-df57e8ff3b26\n",
    "# https://github.com/openai/gym/blob/5cb12296274020db9bb6378ce54276b31e7002da/gym/envs/__init__.py#L371\n",
    "    \n",
    "NUM_SKIP_FRAME = 4 # skipするframe数です\n",
    "NUM_STACK_FRAME = 4  # 状態として連続的に保持するframe数です\n",
    "NOOP_MAX = 30  #  reset時に何もしないフレームを挟む（No-operation）フレーム数の乱数上限です\n",
    "NUM_PROCESSES = 16 #  並列して同時実行するプロセス数です\n",
    "NUM_ADVANCED_STEP = 5  # 何ステップ進めて報酬和を計算するのか設定\n",
    "GAMMA = 0.99  # 時間割引率\n",
    "\n",
    "TOTAL_FRAMES=10e6  #  学習に使用する総フレーム数\n",
    "NUM_UPDATES = int(TOTAL_FRAMES / NUM_ADVANCED_STEP / NUM_PROCESSES)  # ネットワークの総更新回数\n",
    "# NUM_UPDATESは125,000となる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2Cの損失関数の計算のための定数設定\n",
    "value_loss_coef = 0.5\n",
    "entropy_coef = 0.01\n",
    "max_grad_norm = 0.5\n",
    "\n",
    "# 学習手法RMSpropの設定\n",
    "lr = 7e-4\n",
    "eps = 1e-5\n",
    "alpha = 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GPUの使用の設定\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メモリオブジェクトの定義\n",
    "\n",
    "\n",
    "class RolloutStorage(object):\n",
    "    '''Advantage学習するためのメモリクラスです'''\n",
    "\n",
    "    def __init__(self, num_steps, num_processes, obs_shape):\n",
    "\n",
    "        self.observations = torch.zeros(\n",
    "            num_steps + 1, num_processes, *obs_shape).to(device)\n",
    "        # *を使うと()リストの中身を取り出す\n",
    "        # obs_shape→(4,84,84)\n",
    "        # *obs_shape→ 4 84 84\n",
    "\n",
    "        self.masks = torch.ones(num_steps + 1, num_processes, 1).to(device)\n",
    "        self.rewards = torch.zeros(num_steps, num_processes, 1).to(device)\n",
    "        self.actions = torch.zeros(\n",
    "            num_steps, num_processes, 1).long().to(device)\n",
    "\n",
    "        # 割引報酬和を格納\n",
    "        self.returns = torch.zeros(num_steps + 1, num_processes, 1).to(device)\n",
    "        self.index = 0  # insertするインデックス\n",
    "\n",
    "    def insert(self, current_obs, action, reward, mask):\n",
    "        '''次のindexにtransitionを格納する'''\n",
    "        self.observations[self.index + 1].copy_(current_obs)\n",
    "        self.masks[self.index + 1].copy_(mask)\n",
    "        self.rewards[self.index].copy_(reward)\n",
    "        self.actions[self.index].copy_(action)\n",
    "\n",
    "        self.index = (self.index + 1) % NUM_ADVANCED_STEP  # インデックスの更新\n",
    "\n",
    "    def after_update(self):\n",
    "        '''Advantageするstep数が完了したら、最新のものをindex0に格納'''\n",
    "        self.observations[0].copy_(self.observations[-1])\n",
    "        self.masks[0].copy_(self.masks[-1])\n",
    "\n",
    "    def compute_returns(self, next_value):\n",
    "        '''Advantageするステップ中の各ステップの割引報酬和を計算する'''\n",
    "\n",
    "        # 注意：5step目から逆向きに計算しています\n",
    "        # 注意：5step目はAdvantage1となる。4ステップ目はAdvantage2となる。・・・\n",
    "        self.returns[-1] = next_value\n",
    "        for ad_step in reversed(range(self.rewards.size(0))):\n",
    "            self.returns[ad_step] = self.returns[ad_step + 1] * \\\n",
    "                GAMMA * self.masks[ad_step + 1] + self.rewards[ad_step]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2Cのディープ・ニューラルネットワークの構築\n",
    "\n",
    "\n",
    "def init(module, gain):\n",
    "    '''層の結合パラメータを初期化する関数を定義'''\n",
    "    nn.init.orthogonal_(module.weight.data, gain=gain)\n",
    "    nn.init.constant_(module.bias.data, 0)\n",
    "    return module\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    '''コンボリューション層の出力画像を1次元に変換する層を定義'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_out):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 結合パラメータの初期化関数\n",
    "        def init_(module): return init(\n",
    "            module, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        # コンボリューション層の定義\n",
    "        self.conv = nn.Sequential(\n",
    "            # 画像サイズの変化84*84→20*20\n",
    "            init_(nn.Conv2d(NUM_STACK_FRAME, 32, kernel_size=8, stride=4)),\n",
    "            # stackするflameは4画像なのでinput=NUM_STACK_FRAME=4である、出力は32とする、\n",
    "            # sizeの計算  size = (Input_size - Kernel_size + 2*Padding_size)/ Stride_size + 1\n",
    "\n",
    "            nn.ReLU(),\n",
    "            # 画像サイズの変化20*20→9*9\n",
    "            init_(nn.Conv2d(32, 64, kernel_size=4, stride=2)),\n",
    "            nn.ReLU(),\n",
    "            init_(nn.Conv2d(64, 64, kernel_size=3, stride=1)),  # 画像サイズの変化9*9→7*7\n",
    "            nn.ReLU(),\n",
    "            Flatten(),  # 画像形式を1次元に変換\n",
    "            init_(nn.Linear(64 * 7 * 7, 512)),  # 64枚の7×7の画像を、512次元のoutputへ\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 結合パラメータの初期化関数\n",
    "        def init_(module): return init(module, gain=1.0)\n",
    "\n",
    "        # Criticの定義\n",
    "        self.critic = init_(nn.Linear(512, 1))  # 状態価値なので出力は1つ\n",
    "\n",
    "        # 結合パラメータの初期化関数\n",
    "        def init_(module): return init(module, gain=0.01)\n",
    "\n",
    "        # Actorの定義\n",
    "        self.actor = init_(nn.Linear(512, n_out))  # 行動を決めるので出力は行動の種類数\n",
    "\n",
    "        # ネットワークを訓練モードに設定\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''ネットワークのフォワード計算を定義します'''\n",
    "        input = x / 255.0  # 画像のピクセル値0-255を0-1に正規化する\n",
    "        conv_output = self.conv(input)  # Convolution層の計算\n",
    "        critic_output = self.critic(conv_output)  # 状態価値の計算\n",
    "        actor_output = self.actor(conv_output)  # 行動の計算\n",
    "\n",
    "        return critic_output, actor_output\n",
    "\n",
    "    def act(self, x):\n",
    "        '''状態xから行動を確率的に求めます'''\n",
    "        value, actor_output = self(x)\n",
    "        probs = F.softmax(actor_output, dim=1)    # dim=1で行動の種類方向に計算\n",
    "        action = probs.multinomial(num_samples=1)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def get_value(self, x):\n",
    "        '''状態xから状態価値を求めます'''\n",
    "        value, actor_output = self(x)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def evaluate_actions(self, x, actions):\n",
    "        '''状態xから状態価値、実際の行動actionsのlog確率とエントロピーを求めます'''\n",
    "        value, actor_output = self(x)\n",
    "\n",
    "        log_probs = F.log_softmax(actor_output, dim=1)  # dim=1で行動の種類方向に計算\n",
    "        action_log_probs = log_probs.gather(1, actions)  # 実際の行動のlog_probsを求める\n",
    "\n",
    "        probs = F.softmax(actor_output, dim=1)  # dim=1で行動の種類方向に計算\n",
    "        dist_entropy = -(log_probs * probs).sum(-1).mean()\n",
    "\n",
    "        return value, action_log_probs, dist_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エージェントが持つ頭脳となるクラスを定義、全エージェントで共有する\n",
    "\n",
    "\n",
    "class Brain(object):\n",
    "    def __init__(self, actor_critic):\n",
    "\n",
    "        self.actor_critic = actor_critic  # actor_criticはクラスNetのディープ・ニューラルネットワーク\n",
    "\n",
    "        # 結合パラメータをロードする場合\n",
    "        #filename = 'weight.pth'\n",
    "        #param = torch.load(filename, map_location='cpu')\n",
    "        # self.actor_critic.load_state_dict(param)\n",
    "\n",
    "        # パラメータ更新の勾配法の設定\n",
    "        self.optimizer = optim.RMSprop(\n",
    "            actor_critic.parameters(), lr=lr, eps=eps, alpha=alpha)\n",
    "\n",
    "    def update(self, rollouts):\n",
    "        '''advanced計算した5つのstepの全てを使って更新します'''\n",
    "        obs_shape = rollouts.observations.size()[2:]  # torch.Size([4, 84, 84])\n",
    "        num_steps = NUM_ADVANCED_STEP\n",
    "        num_processes = NUM_PROCESSES\n",
    "\n",
    "        values, action_log_probs, dist_entropy = self.actor_critic.evaluate_actions(\n",
    "            rollouts.observations[:-1].view(-1, *obs_shape),\n",
    "            rollouts.actions.view(-1, 1))\n",
    "\n",
    "        # 注意：各変数のサイズ\n",
    "        # rollouts.observations[:-1].view(-1, *obs_shape) torch.Size([80, 4, 84, 84])\n",
    "        # rollouts.actions.view(-1, 1) torch.Size([80, 1])\n",
    "        # values torch.Size([80, 1])\n",
    "        # action_log_probs torch.Size([80, 1])\n",
    "        # dist_entropy torch.Size([])\n",
    "\n",
    "        values = values.view(num_steps, num_processes,\n",
    "                             1)  # torch.Size([5, 16, 1])\n",
    "        action_log_probs = action_log_probs.view(num_steps, num_processes, 1)\n",
    "\n",
    "        advantages = rollouts.returns[:-1] - values  # torch.Size([5, 16, 1])\n",
    "        value_loss = advantages.pow(2).mean()\n",
    "\n",
    "        action_gain = (advantages.detach() * action_log_probs).mean()\n",
    "        # detachしてadvantagesを定数として扱う\n",
    "\n",
    "        total_loss = (value_loss * value_loss_coef -\n",
    "                      action_gain - dist_entropy * entropy_coef)\n",
    "\n",
    "        self.optimizer.zero_grad()  # 勾配をリセット\n",
    "        total_loss.backward()  # バックプロパゲーションを計算\n",
    "        nn.utils.clip_grad_norm_(self.actor_critic.parameters(), max_grad_norm)\n",
    "        #  一気に結合パラメータが変化しすぎないように、勾配の大きさは最大0.5までにする\n",
    "\n",
    "        self.optimizer.step()  # 結合パラメータを更新\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakoutを実行する環境のクラス\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    def run(self):\n",
    "\n",
    "        # seedの設定\n",
    "        seed_num = 1\n",
    "        torch.manual_seed(seed_num)\n",
    "        if use_cuda:\n",
    "            torch.cuda.manual_seed(seed_num)\n",
    "\n",
    "        # 実行環境を構築\n",
    "        torch.set_num_threads(seed_num)\n",
    "        envs = [make_env(ENV_NAME, seed_num, i) for i in range(NUM_PROCESSES)]\n",
    "        envs = SubprocVecEnv(envs)  # マルチプロセスの実行環境にする\n",
    "\n",
    "        # 全エージェントが共有して持つ頭脳Brainを生成\n",
    "        n_out = envs.action_space.n  # 行動の種類は4\n",
    "        actor_critic = Net(n_out).to(device)  # GPUへ\n",
    "        global_brain = Brain(actor_critic)\n",
    "\n",
    "        # 格納用変数の生成\n",
    "        obs_shape = envs.observation_space.shape  # (1, 84, 84)\n",
    "        obs_shape = (obs_shape[0] * NUM_STACK_FRAME,\n",
    "                     *obs_shape[1:])  # (4, 84, 84)\n",
    "        # torch.Size([16, 4, 84, 84])\n",
    "        current_obs = torch.zeros(NUM_PROCESSES, *obs_shape).to(device)\n",
    "        rollouts = RolloutStorage(\n",
    "            NUM_ADVANCED_STEP, NUM_PROCESSES, obs_shape)  # rolloutsのオブジェクト\n",
    "        episode_rewards = torch.zeros([NUM_PROCESSES, 1])  # 現在の試行の報酬を保持\n",
    "        final_rewards = torch.zeros([NUM_PROCESSES, 1])  # 最後の試行の報酬和を保持\n",
    "\n",
    "        # 初期状態の開始\n",
    "        obs = envs.reset()\n",
    "        obs = torch.from_numpy(obs).float()  # torch.Size([16, 1, 84, 84])\n",
    "        current_obs[:, -1:] = obs  # flameの4番目に最新のobsを格納\n",
    "\n",
    "        # advanced学習用のオブジェクトrolloutsの状態の1つ目に、現在の状態を保存\n",
    "        rollouts.observations[0].copy_(current_obs)\n",
    "\n",
    "        # 実行ループ\n",
    "        for j in tqdm(range(NUM_UPDATES)):\n",
    "            # advanced学習するstep数ごとに計算\n",
    "            for step in range(NUM_ADVANCED_STEP):\n",
    "\n",
    "                # 行動を求める\n",
    "                with torch.no_grad():\n",
    "                    action = actor_critic.act(rollouts.observations[step])\n",
    "\n",
    "                cpu_actions = action.squeeze(1).cpu().numpy()  # tensorをNumPyに\n",
    "\n",
    "                # 1stepの並列実行、なお返り値のobsのsizeは(16, 1, 84, 84)\n",
    "                obs, reward, done, info = envs.step(cpu_actions)\n",
    "\n",
    "                # 報酬をtensorに変換し、試行の総報酬に足す\n",
    "                # sizeが(16,)になっているのを(16, 1)に変換\n",
    "                reward = np.expand_dims(np.stack(reward), 1)\n",
    "                reward = torch.from_numpy(reward).float()\n",
    "                episode_rewards += reward\n",
    "\n",
    "                # 各実行環境それぞれについて、doneならmaskは0に、継続中ならmaskは1にする\n",
    "                masks = torch.FloatTensor(\n",
    "                    [[0.0] if done_ else [1.0] for done_ in done])\n",
    "\n",
    "                # 最後の試行の総報酬を更新する\n",
    "                final_rewards *= masks  # 継続中の場合は1をかけ算してそのまま、done時には0を掛けてリセット\n",
    "                # 継続中は0を足す、done時にはepisode_rewardsを足す\n",
    "                final_rewards += (1 - masks) * episode_rewards\n",
    "\n",
    "                # 試行の総報酬を更新する\n",
    "                episode_rewards *= masks  # 継続中のmaskは1なのでそのまま、doneの場合は0に\n",
    "\n",
    "                # masksをGPUへ\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                # 現在の状態をdone時には全部0にする\n",
    "                # maskのサイズをtorch.Size([16, 1])→torch.Size([16, 1, 1 ,1])へ変換して、かけ算\n",
    "                current_obs *= masks.unsqueeze(2).unsqueeze(2)\n",
    "\n",
    "                # frameをstackする\n",
    "                # torch.Size([16, 1, 84, 84])\n",
    "                obs = torch.from_numpy(obs).float()\n",
    "                current_obs[:, :-1] = current_obs[:, 1:]  # 0～2番目に1～3番目を上書き\n",
    "                current_obs[:, -1:] = obs  # 4番目に最新のobsを格納\n",
    "\n",
    "                # メモリオブジェクトに今stepのtransitionを挿入\n",
    "                rollouts.insert(current_obs, action.data, reward, masks)\n",
    "\n",
    "            # advancedのfor loop終了\n",
    "\n",
    "            # advancedした最終stepの状態から予想する状態価値を計算\n",
    "            with torch.no_grad():\n",
    "                next_value = actor_critic.get_value(\n",
    "                    rollouts.observations[-1]).detach()\n",
    "\n",
    "            # 全stepの割引報酬和を計算して、rolloutsの変数returnsを更新\n",
    "            rollouts.compute_returns(next_value)\n",
    "\n",
    "            # ネットワークとrolloutの更新\n",
    "            global_brain.update(rollouts)\n",
    "            rollouts.after_update()\n",
    "\n",
    "            # ログ：途中経過の出力\n",
    "            if j % 100 == 0:\n",
    "                print(\"finished frames {}, mean/median reward {:.1f}/{:.1f}, min/max reward {:.1f}/{:.1f}\".\n",
    "                      format(j*NUM_PROCESSES*NUM_ADVANCED_STEP,\n",
    "                             final_rewards.mean(),\n",
    "                             final_rewards.median(),\n",
    "                             final_rewards.min(),\n",
    "                             final_rewards.max()))\n",
    "\n",
    "            # 結合パラメータの保存\n",
    "            if j % 12500 == 0:\n",
    "                torch.save(global_brain.actor_critic.state_dict(),\n",
    "                           'weight_'+str(j)+'.pth')\n",
    "        \n",
    "        # 実行ループの終了\n",
    "        torch.save(global_brain.actor_critic.state_dict(), 'weight_end.pth')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 実行\n",
    "breakout_env = Environment()\n",
    "breakout_env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## この環境の部分を変える\n",
    "\n",
    "class Aircond:\n",
    "    '''Aircondのクラス'''\n",
    "    def __init__(self, CASE, xCells=40,\n",
    "                         insert_list = [15,15,15,15,33,33,33,51,69,69,69,87,105,105,105,142,142,142,342,342,380,380]):\n",
    "        self.CASE = CASE\n",
    "        # メッシュを作らないとpolymeshがないので。\n",
    "        os.system(CASE.name + '/Makemesh')\n",
    "        # get nCells\n",
    "        with open (self.CASE.name + '/constant/polyMesh/neighbour') as f:\n",
    "            neighbour = f.read()\n",
    "        nCells_index = neighbour.find('nCells')\n",
    "        nCells_ = neighbour[nCells_index : nCells_index+15]\n",
    "        nCells = int(re.sub(r'\\D', '', nCells_))\n",
    "        self.nCells = nCells\n",
    "        \n",
    "        self.action_SPEED = np.array([0.1,0.3,0.5])\n",
    "        self.action_DIRECTION = np.array([-1*np.pi/8, -2*np.pi/8,-3*np.pi/8])\n",
    "        self.action_TEMPERTURE = np.array([18+273.15,22+273.15,26+273.15])\n",
    "        self.action_space = np.tile(np.array([0,0,0]),(27,1))\n",
    "        self.observation_space_ = np.tile(np.array([0,0,0]),(self.nCells,1))\n",
    "        #self.observation_space = np.tile(np.array([0]), (self.nCells*3,1)\n",
    "        \n",
    "        self.xCells = xCells\n",
    "        self.insert_list = insert_list\n",
    "        observation_space = np.tile(np.array([0,0,0]), (self.nCells+len(self.insert_list),1))\n",
    "        U_space_x = observation_space[:,0].reshape(self.xCells,-1)\n",
    "        U_space_y = observation_space[:,1].reshape(self.xCells,-1)\n",
    "        T_space = observation_space[:,2].reshape(self.xCells,-1)\n",
    "        self.observation_space = np.array([U_space_x, U_space_y, T_space]) \n",
    "        \n",
    "        self.stride = 500\n",
    "        self.startTime = 0  # startTimeの初期化\n",
    "        self.endTime = 500  # 初期化\n",
    "        self.end = 3000\n",
    "        \n",
    "        \n",
    "        # 各辞書ファイルの取得\n",
    "        self.initialDir = self.CASE.initialDir()+'/'\n",
    "        self.constant = self.CASE.name + \"/constant/\"\n",
    "        self.system = self.CASE.name + \"/system/\"\n",
    "        self.initialDir_file = []\n",
    "        for x in os.listdir(self.initialDir):\n",
    "            if os.path.isfile(self.initialDir + x):\n",
    "                self.initialDir_file.append(x)\n",
    "        self.constant_file = []\n",
    "        for y in os.listdir(self.constant):\n",
    "            if os.path.isfile(self.constant + y):\n",
    "                self.constant_file.append(y)\n",
    "        self.system_file = []\n",
    "        for z in os.listdir(self.system):\n",
    "            if os.path.isfile(self.system + z):\n",
    "                self.system_file.append(z)\n",
    "        \n",
    "        # 各辞書ファイルをそれぞれのファイル名で保存\n",
    "        for i in range(len(self.initialDir_file)):\n",
    "            self.__dict__[self.initialDir_file[i]] = ParsedParameterFile(self.initialDir + self.initialDir_file[i])\n",
    "\n",
    "        for i in range(len(self.system_file)):\n",
    "            self.__dict__[self.system_file[i]] = ParsedParameterFile(self.system + self.system_file[i])\n",
    "            \n",
    "    def initial_to_float(self, numpy_Parsed_value):\n",
    "        '''uniformをnp.arrayに変換'''\n",
    "        numpy_Parsed_value = np.array(numpy_Parsed_value)\n",
    "        if numpy_Parsed_value.ndim==0:\n",
    "            Parsed_raw = str(numpy_Parsed_value.all())\n",
    "            Parsed_str = Parsed_raw[8:].strip('()').split(' ')\n",
    "            Parsed_int = np.array(list(map(float,Parsed_str)))\n",
    "            #Parsed = np.tile(Parsed_int,(self.nCells,1))\n",
    "        return Parsed_int\n",
    "    \n",
    "    def initial_to_array(self, numpy_Parsed_value):\n",
    "        '''uniformをnCellの数だけnp.arrayに変換'''\n",
    "        numpy_Parsed_value = np.array(numpy_Parsed_value)\n",
    "        if numpy_Parsed_value.ndim==0:\n",
    "            Parsed_raw = str(numpy_Parsed_value.all())\n",
    "            Parsed_str = Parsed_raw[8:].strip('()').split(' ')\n",
    "            Parsed_int = np.array(list(map(float,Parsed_str)))\n",
    "            Parsed = np.tile(Parsed_int,(self.nCells,1))\n",
    "        return Parsed\n",
    "\n",
    "    def make_observation_old(self,Dir):\n",
    "        '''Dirのpathのobservationを取得'''\n",
    "        U_value = np.array(ParsedParameterFile(Dir + '/U').content['internalField'])\n",
    "        T_value = np.array(ParsedParameterFile(Dir + '/T').content['internalField'])\n",
    "        if U_value.ndim == 0:\n",
    "            U_value = self.initial_to_array(U_value)\n",
    "            T_value = self.initial_to_array(T_value)\n",
    "        U_value_xy = np.delete(U_value, axis=1, obj=2)\n",
    "        T_value_x = np.reshape(T_value, [-1,1], order='F')\n",
    "        Observation = np.concatenate([U_value_xy, T_value_x],axis=1)\n",
    "        return Observation    \n",
    "    \n",
    "    def make_observation_onerow(self,Dir):\n",
    "        '''Dirのpathのobservationを取得'''\n",
    "        U_value = np.array(ParsedParameterFile(Dir + '/U').content['internalField'])\n",
    "        T_value = np.array(ParsedParameterFile(Dir + '/T').content['internalField'])\n",
    "        if U_value.ndim == 0:\n",
    "            U_value = self.initial_to_array(U_value)\n",
    "            T_value = self.initial_to_array(T_value)\n",
    "        #U_value_xy = np.delete(U_value, axis=1, obj=2)\n",
    "        T_value_x = T_value.reshape(-1, 1)\n",
    "        U_value_x = U_value[:,0].reshape(-1, 1)\n",
    "        U_value_y = U_value[:,1].reshape(-1, 1)\n",
    "        observation = np.concatenate([U_value_x, U_value_y, T_value_x], axis=0)\n",
    "        return observation\n",
    "    \n",
    "    def make_observation(self,Dir):\n",
    "        '''observationを２次元で取得\n",
    "        self.xCells : x方向のセル数\n",
    "        self.insert_list : 障害物があり、値を0で埋めるべき場所\n",
    "        '''\n",
    "        U_value = np.array(ParsedParameterFile(Dir + '/U').content['internalField'])\n",
    "        T_value = np.array(ParsedParameterFile(Dir + '/T').content['internalField'])\n",
    "        if U_value.ndim == 0:\n",
    "            U_value = self.initial_to_array(U_value)\n",
    "            T_value = self.initial_to_array(T_value)\n",
    "        #U_value_xy = np.delete(U_value, axis=1, obj=2)\n",
    "        U_value_xy = np.delete(U_value, axis=1, obj=2)\n",
    "        T_value_x = np.reshape(T_value, [-1,1], order='F')\n",
    "        observation_ = np.concatenate([U_value_xy, T_value_x],axis=1)  # 3 axis observation\n",
    "        observation_ = np.insert(observation_, self.insert_list, [0,0,0], axis=0)\n",
    "        U_value_x = observation_[:,0].reshape(self.xCells,-1)\n",
    "        U_value_y = observation_[:,1].reshape(self.xCells,-1)\n",
    "        T_value = observation_[:,2].reshape(self.xCells,-1)\n",
    "        observation = np.array([U_value_x, U_value_y, T_value])\n",
    "        return observation\n",
    "    \n",
    "    def make_action(self):\n",
    "        '''actionの設定'''\n",
    "        Action = np.empty((0,3),float)\n",
    "        for i in range(len(self.action_SPEED)):\n",
    "            for j in range(len(self.action_DIRECTION)):\n",
    "                for k in range(len(self.action_TEMPERTURE)):\n",
    "                    Ux = self.action_SPEED[i]*np.cos(self.action_DIRECTION[j])\n",
    "                    Uy = self.action_SPEED[i]*np.sin(self.action_DIRECTION[j])\n",
    "                    Act = np.array([[Ux,Uy,self.action_TEMPERTURE[k]]])\n",
    "                    Action = np.append(Action,Act,axis=0)\n",
    "                    \n",
    "        return Action\n",
    "    \n",
    "    def getParsed(self,time_step):\n",
    "        '''各time_stepのParsedParameterFileを取得'''\n",
    "        T = ParsedParameterFile(self.CASE.name + '/' + str(time_step) + '/T')\n",
    "        U = ParsedParameterFile(self.CASE.name + '/' + str(time_step) + '/U')\n",
    "        TU_list = [T,U]\n",
    "        return TU_list\n",
    "    \n",
    "    \n",
    "    def getParsedList(self,first_step, last_step, write_step,):\n",
    "        '''各time_stepのParsedParameterFileを取得'''\n",
    "        TU_list = []\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            T = ParsedParameterFile(self.CASE.name + '/' + str(stp) + '/T')\n",
    "            U = ParsedParameterFile(self.CASE.name + '/' + str(stp) + '/U')\n",
    "            TU_list.append([T,U])\n",
    "        return TU_list\n",
    "    \n",
    "    # 後にcythonで書き直す予定\n",
    "    def calc_PMV(self, TA=20,VA=0.3,TR=20,RH=50,AL=1,CLO=1):\n",
    "        '''PMVとPPDを計算'''\n",
    "        #AL = 1  # 活動量[met]\n",
    "        #CLO = 1 # 着衣量[clo]\n",
    "        #TA = 20  #  温度[℃]\n",
    "        #TR = 20  # MRT[℃]\n",
    "        #VA = 0.3  # 流速[m/s]\n",
    "        #RH = 50  # 相対湿度[%]\n",
    "        #\n",
    "        #***************************************************\n",
    "        # 外部仕事 W＝0 [W/㎡]とする。\n",
    "        #***************************************************\n",
    "        # PMV 計算準備\n",
    "        #\n",
    "        M = AL * 58.15\n",
    "        LCL = CLO\n",
    "        W = 0\n",
    "        #PA = (RH / 100 * np.exp(18.6686 - 4030.18 / (TA + 235))) / 0.00750062\n",
    "        PPK = 673.4 - 1.8 * TA\n",
    "        PPA = 3.2437814 + 0.00326014 * PPK + 2.00658 * 1E-9 * PPK * PPK * PPK\n",
    "        PPB = (1165.09 - PPK) * (1 + 0.00121547 * PPK)\n",
    "        PA = RH / 100 * 22105.8416 / np.exp(2.302585 * PPK * PPA / PPB) * 1000\n",
    "        EPS = 1E-5\n",
    "        MW = M - W\n",
    "        # FCL＝着衣表面積／裸体表面積の比\n",
    "        if LCL > 0.5:\n",
    "            FCL = 1.05 + 0.1 * LCL\n",
    "        else:\n",
    "            FCL = 1 + 0.2 * LCL\n",
    "        # 衣服表面温度TCLの初期値設定\n",
    "        TCL = TA\n",
    "        TCLA = TCL\n",
    "        NOI = 1\n",
    "        # 着衣表面温度の計算\n",
    "        while True:\n",
    "            TCLA = 0.8 * TCLA + 0.2 * TCL\n",
    "            HC = 12.1 * np.sqrt(VA)\n",
    "            if 2.38 * np.sqrt(np.sqrt(abs(TCL - TA))) > HC:\n",
    "                HC = 2.38 * np.sqrt(np.sqrt(abs(TCL - TA)))\n",
    "            TCL = 35.7 - 0.028 * MW - 0.155 * LCL * (3.96 * 1E-8 * FCL * ((TCLA + 273) ** 4 - (TR + 273) ** 4) + FCL * HC * (TCLA - TA))\n",
    "            NOI = NOI + 1\n",
    "            if NOI > 150:\n",
    "                #PMV = 999990.999\n",
    "                PMB = 3.0\n",
    "                PPD = 100\n",
    "                return (PMV,PPD)\n",
    "            if not abs(TCLA - TCL) > EPS:\n",
    "                break\n",
    "        #PMVの計算\n",
    "        PM1 = 3.96 * 1E-8 * FCL * ((TCL + 273) ** 4 - (TA + 273) ** 4)\n",
    "        PM2 = FCL * HC * (TCL - TA)\n",
    "        PM3 = 0.303 * np.exp(-0.036 * M) + 0.028\n",
    "        if MW > 58.15:\n",
    "            PM4 = 0.42 * (MW - 58.15)\n",
    "        else:\n",
    "            PM4 = 0\n",
    "        PMV = PM3 * (MW - 3.05 * 0.001 * (5733 - 6.99 * MW - PA) - PM4 - 1.7 * 1E-5 * M * (5867 - PA) - 0.0014 * M * (34 - TA) - PM1 - PM2)\n",
    "            #PRINT PMV\n",
    "        if abs(PMV) > 3:\n",
    "            #PMV = 999990.999\n",
    "            PMV = 3.0\n",
    "            PPD = 100\n",
    "            return (PMV,PPD)\n",
    "        \n",
    "        PPD = 100 - 95 * np.exp(-0.0335 * PMV ** 4 - 0.2179 * PMV ** 2)\n",
    "        \n",
    "        return (PMV,PPD)\n",
    "    \n",
    "    def calc_MRT(self, T_Parsed):\n",
    "        '''MRTを計算'''\n",
    "        \n",
    "        T_wall_list = np.array([])\n",
    "        if np.array(T_Parsed['internalField']).ndim==0:  # time_step=0\n",
    "            for boundary in list(T_Parsed['boundaryField']):\n",
    "                if T_Parsed['boundaryField'][boundary]['type']=='zeroGradient' or \\\n",
    "                T_Parsed['boundaryField'][boundary]['type']=='empty' or \\\n",
    "                    T_Parsed['boundaryField'][boundary]['type']=='fixedValue':\n",
    "                    T_wall = np.array([])\n",
    "                else:\n",
    "                    numpy_Parsed_value = np.array(T_Parsed['boundaryField'][boundary]['value'])\n",
    "                    T_wall = self.initial_to_float(numpy_Parsed_value)\n",
    "                T_wall_list = np.append(T_wall_list, T_wall)\n",
    "                \n",
    "        else:\n",
    "            for boundary in list(T_Parsed['boundaryField']):\n",
    "                if T_Parsed['boundaryField'][boundary]['type']=='fixedValue':\n",
    "                    numpy_Parsed_value = np.array(T_Parsed['boundaryField'][boundary]['value'])\n",
    "                    T_wall = self.initial_to_float(numpy_Parsed_value)\n",
    "                elif T_Parsed['boundaryField'][boundary]['type']=='zeroGradient' or \\\n",
    "                T_Parsed['boundaryField'][boundary]['type']=='empty':\n",
    "                    T_wall = np.array([])\n",
    "                else:\n",
    "                    T_wall = np.array(T_Parsed['boundaryField'][boundary]['value'])\n",
    "                    if T_wall.ndim==0:\n",
    "                        T_wall = self.initial_to_float(T_wall)\n",
    "                T_wall_list = np.append(T_wall_list, T_wall)\n",
    "        return np.average(T_wall_list)\n",
    "    \n",
    "    def Celsius(self, T):\n",
    "        CelsiusT = T - 273.15\n",
    "        return CelsiusT\n",
    "    \n",
    "    def Celsius_(self, T):\n",
    "        '''セルシウス℃に変換'''\n",
    "        if np.array(T).size==1:\n",
    "            return self.Celsius(T)\n",
    "        else:\n",
    "            Celsiuss = np.frompyfunc(self.Celsius,1,1)  # リストに適用可にする\n",
    "            return Celsiuss(T)\n",
    "        \n",
    "    def UScalar(self, U):\n",
    "        '''Uをスカラーに変換'''\n",
    "        if np.array(U).size<=3:\n",
    "            return np.array([np.sqrt(U[0]**2 + U[1]**2)])\n",
    "        else:\n",
    "            return np.sqrt(U[:,0]**2 + U[:,1]**2)\n",
    "        \n",
    "    def calc_PMV_all(self, TU_Parsed):\n",
    "        '''PMVを一つのtime_stepで全点計算'''\n",
    "        \n",
    "        T_Parsed,U_Parsed = TU_Parsed\n",
    "        T = np.array(T_Parsed['internalField'])\n",
    "        U = np.array(U_Parsed['internalField'])\n",
    "        # time_step==0の場合\n",
    "        if T.ndim==0 or U.ndim==0:\n",
    "            T = self.initial_to_float(T)\n",
    "            U = self.initial_to_float(U)\n",
    "            # Uを速さに変換\n",
    "        Us = self.UScalar(U)\n",
    "        MRT = self.calc_MRT(T_Parsed)\n",
    "        # TとMRTをセルシウス温度に変換\n",
    "        Tc = list(self.Celsius_(T))\n",
    "        MRTc = self.Celsius_(MRT)\n",
    "\n",
    "        length = len(T)\n",
    "        # ループを早くするため、外に出す。\n",
    "        PMV = []\n",
    "        PPD = []\n",
    "        PMVappend = PMV.append\n",
    "        PPDappend = PPD.append\n",
    "        for i in range(length):\n",
    "            pmv,ppd = self.calc_PMV(TA=Tc[i],VA=Us[i],TR=MRTc,RH=50,AL=1,CLO=1)\n",
    "            PMVappend(pmv)\n",
    "            PPDappend(ppd)\n",
    "        return [PMV,PPD]\n",
    "    \n",
    "    def header(self, time_step, filename):\n",
    "        '''headerファイルを作成'''\n",
    "        header = \"\"\"/*--------------------------------*- C++ -*----------------------------------*\\\n",
    "=========                 |\n",
    "  \\\\      /  F ield         | OpenFOAM: The Open Source CFD Toolbox\n",
    "   \\\\    /   O peration     | Website:  https://openfoam.org\n",
    "    \\\\  /    A nd           | Version:  6\n",
    "     \\\\/     M anipulation  |\n",
    "\\*---------------------------------------------------------------------------*/\n",
    "FoamFile\n",
    "{{\n",
    "    version     2.0;\n",
    "    format      ascii;\n",
    "    class       volScalarField;\n",
    "    location    \"{}\";\n",
    "    object      {};\n",
    "}}\n",
    "// * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * //\n",
    "\"\"\".format(time_step, filename)\n",
    "        return header\n",
    "    \n",
    "    def internal(self, list_internal):\n",
    "        '''internalFieldの値の作成'''\n",
    "        if len(list_internal)==1:\n",
    "            internal = \"\"\"\n",
    "internalField   uniform {};\"\"\".format(list_internal[0])\n",
    "        else:\n",
    "            str_= np.frompyfunc(str,1,1)\n",
    "            str_internal = '\\n'.join(str_(list_internal))\n",
    "            internal = \"\"\"\n",
    "internalField   nonuniform List<scalar> \n",
    "{}\n",
    "(\n",
    "{}\n",
    ")\n",
    ";\n",
    "\"\"\".format(self.nCells, str_internal)\n",
    "        return internal\n",
    "    \n",
    "    def makePMVFile(self,time_step):\n",
    "        '''PMVとPPDファイルを書き込む'''\n",
    "        \n",
    "        path_pmv = self.CASE.name + '/' + str(time_step) + '/PMV' # 書き込むパス\n",
    "        path_ppd = self.CASE.name + '/' + str(time_step) + '/PPD'\n",
    "        \n",
    "        demensions = \"\"\"\n",
    "dimensions      [0 0 0 0 0 0 0];\n",
    "\"\"\"\n",
    "        \n",
    "        boundary = \"\"\"\n",
    "boundaryField\n",
    "{\n",
    "    \".*\"\n",
    "    {\n",
    "        type            zeroGradient;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// ************************************************************************* //\n",
    "\"\"\"\n",
    "        # header, dimensions, internal, boundaryの順に書き込む\n",
    "        f = open(path_pmv, 'w') # ファイルを開く(該当ファイルがなければ新規作成)\n",
    "        g = open(path_ppd, 'w')\n",
    "        f.write(self.header(time_step,\"PMV\")) # headerを記載する\n",
    "        g.write(self.header(time_step,\"PPD\"))\n",
    "        f.write(demensions) # dimensionsを記載する\n",
    "        g.write(demensions)\n",
    "        # internalFieldの計算\n",
    "        TU_Parsed = self.getParsed(time_step)\n",
    "        PMV,PPD = self.calc_PMV_all(TU_Parsed)\n",
    "        internal_PMV = self.internal(PMV)\n",
    "        internal_PPD = self.internal(PPD)\n",
    "        f.write(internal_PMV)  \n",
    "        g.write(internal_PPD)\n",
    "        f.write(boundary)\n",
    "        g.write(boundary)\n",
    "        f.close() \n",
    "        g.close()\n",
    "\n",
    "        \n",
    "    def makePMVList(self,first_step, last_step, write_step):\n",
    "        '''任意の範囲でPMVファイルを作成'''\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            self.makePMVFile(stp)\n",
    "            \n",
    "        \n",
    "    def meshNumberFile(self,time_step):\n",
    "        '''メッシュの並びを確認する'''\n",
    "        path_mesh = self.CASE.name + '/' + str(time_step) + '/Meshnumber' # 書き込むパス\n",
    "\n",
    "\n",
    "        demensions = \"\"\"\n",
    "dimensions      [0 0 0 0 0 0 0];\n",
    "\"\"\"\n",
    "        boundary = \"\"\"\n",
    "boundaryField\n",
    "{\n",
    "    \".*\"\n",
    "    {\n",
    "        type            zeroGradient;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// ************************************************************************* //\n",
    "\"\"\"\n",
    "        f = open(path_mesh, 'w') # ファイルを開く(該当ファイルがなければ新規作成)\n",
    "        f.write(self.header(time_step,\"PMV\")) # headerを記載する\n",
    "        f.write(demensions) # dimensionsを記載する\n",
    "        mesh_list = [x for x in range(1,self.nCells+1)]\n",
    "        internal_mesh = self.internal(mesh_list)\n",
    "        f.write(internal_mesh)  \n",
    "        f.write(boundary)\n",
    "        f.close() \n",
    "            \n",
    "    def calc_ADPI(self,TU_Parsed,occupied_zone_cell):\n",
    "        '''ADPIを計算する'''\n",
    "        \n",
    "        # occupied_zone_cellはaircond5の場合は1~340までのセルが居住域\n",
    "        T_Parsed,U_Parsed = TU_Parsed\n",
    "        T = np.array(T_Parsed['internalField'])\n",
    "        U = np.array(U_Parsed['internalField'])\n",
    "        # time_step==0の場合\n",
    "        if T.ndim==0 or U.ndim==0:\n",
    "            T = self.initial_to_float(T)\n",
    "            U = self.initial_to_float(U)\n",
    "        \n",
    "        Tc = np.average(T)  # 室内の平均温度\n",
    "        Us = self.UScalar(U)  # 流速\n",
    "        theta = (T - Tc) - 8.0*(Us - 0.15)  # 有効ドラフト温度\n",
    "        \n",
    "        satisfy_theta = np.where((theta > -1.5) & (theta < 1), 1, 0)\n",
    "        satisfy_Us = np.where(Us < 0.35,1, 0)  # 条件を満たすものを1,満たさないものを0\n",
    "        satisfy_all = satisfy_theta + satisfy_Us\n",
    "        satisfy = satisfy_all[:occupied_zone_cell]\n",
    "        nCells = satisfy.size\n",
    "        num_satisfy = np.sum(satisfy == 2)\n",
    "        ADPI = num_satisfy/nCells*100\n",
    "        \n",
    "        return (ADPI, theta)\n",
    "    \n",
    "    def calc_EUC(self,T_Parsed, occupied_zone_cell,last_cell):\n",
    "        '''EUCを計算する'''\n",
    "        \n",
    "        T = np.array(T_Parsed['internalField'])\n",
    "        T0 = self.initial_to_float(T_Parsed['boundaryField']['inlet']['value'])[0] # 給気温度\n",
    "\n",
    "        if T.ndim==0:\n",
    "            T = self.initial_to_float(T)[0]\n",
    "            Toz = T\n",
    "            Tiz = T\n",
    "        else:\n",
    "            Toz = np.average(T[occupied_zone_cell:last_cell])  # 居住域外の平均温度  \n",
    "            Tiz = np.average(T[:occupied_zone_cell])  # 居住域内の平均温度\n",
    "        EUC = (Toz-T0) / (Tiz-T0) * 100\n",
    "        return EUC\n",
    "        \n",
    "    def getPMVList(self, first_step, last_step, write_step):\n",
    "        '''任意の範囲のPMVの平均値ファイルを取得'''\n",
    "        \n",
    "        # ループを早くするため、外に出す。\n",
    "        PMV_list = []\n",
    "        PPD_list = []\n",
    "        PMVappend = PMV_list.append\n",
    "        PPDappend = PPD_list.append\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            TU_Parsed = self.getParsed(stp)\n",
    "            PMV,PPD = self.calc_PMV_all(TU_Parsed)\n",
    "            pmv = np.average(np.array(PMV))\n",
    "            ppd = np.average(np.array(PPD))\n",
    "            PMVappend(pmv)\n",
    "            PPDappend(ppd)\n",
    "        return [PMV_list, PPD_list]\n",
    "    \n",
    "    def getPMVerrorList(self, first_step, last_step, write_step):\n",
    "        '''任意の範囲のPMVの空間平均2乗誤差を取得'''\n",
    "        \n",
    "        # 工事中\n",
    "        PMV_list = []\n",
    "        PMVappend = PMV_list.append\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            TU_Parsed = self.getParsed(stp)\n",
    "            PMV,PPD = self.calc_PMV_all(TU_Parsed)\n",
    "            \n",
    "            pmv = np.average(np.array(PMV))\n",
    "            PMVappend(pmv)\n",
    "        return [PMV_list, PPD_list]\n",
    "    \n",
    "    def getADPIList(self, first_step, last_step, write_step,occupied_zone_cell=342):\n",
    "        '''任意の範囲のADPIの値を取得'''\n",
    "        \n",
    "        ADPI_list = []\n",
    "        ADPIappend = ADPI_list.append\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            TU_Parsed = self.getParsed(stp)\n",
    "            adpi,theta = self.calc_ADPI(TU_Parsed, occupied_zone_cell)\n",
    "            ADPIappend(adpi)\n",
    "        return ADPI_list\n",
    "    \n",
    "    def getEUCList(self, first_step, last_step, write_step,\n",
    "                    occupied_zone_cell=342, last_cell=100000):\n",
    "        '''任意の範囲のEUCの値を算出'''\n",
    "        \n",
    "        EUC_list = []\n",
    "        EUCappend = EUC_list.append\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            T_Parsed,U_Parsed = self.getParsed(stp)\n",
    "            euc = self.calc_EUC(T_Parsed, occupied_zone_cell, last_cell)\n",
    "            EUCappend(euc)\n",
    "        return EUC_list\n",
    "    \n",
    "    def getTUList(self, first_step, last_step, write_step):\n",
    "        '''任意の範囲のTとUの平均値を取得'''\n",
    "        \n",
    "        T_list = []\n",
    "        U_list = []\n",
    "        MRT_list = []\n",
    "        Tappend = T_list.append\n",
    "        Uappend = U_list.append\n",
    "        MRTappend = MRT_list.append\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            T_Parsed, U_Parsed = self.getParsed(stp)\n",
    "            T = np.array(T_Parsed['internalField'])\n",
    "            U = np.array(U_Parsed['internalField'])\n",
    "            # time_step==0の場合\n",
    "            if T.ndim==0 or U.ndim==0:\n",
    "                T = self.initial_to_float(T)\n",
    "                U = self.initial_to_float(U)\n",
    "            # Uを速さに変換\n",
    "            T = np.average(T)\n",
    "            Us = np.average(np.array(self.UScalar(U)))\n",
    "            MRT = np.average(np.array(self.calc_MRT(T_Parsed)))\n",
    "            # TとMRTをセルシウス温度に変換\n",
    "            Tc = self.Celsius(T)\n",
    "            MRTc = self.Celsius(MRT)\n",
    "            Tappend(Tc)\n",
    "            Uappend(Us)\n",
    "            MRTappend(MRTc)\n",
    "        return [T_list,U_list,MRT_list]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def change_control(self,control):\n",
    "        if control == 1:\n",
    "            self.blockMeshDict['blocks'][2] = Vector(20,10,1)\n",
    "            self.blockMeshDict.writeFile()\n",
    "            self.controlDict['deltaT'] = 0.02\n",
    "        if control == 2:\n",
    "            self.blockMeshDict['blocks'][2] = Vector(40,20,1)\n",
    "            self.blockMeshDict.writeFile()\n",
    "            self.controlDict['deltaT'] = 0.02\n",
    "        if control == 3:\n",
    "            self.blockMeshDict['blocks'][2] = Vector(20,10,1)\n",
    "            self.blockMeshDict.writeFile()\n",
    "            self.controlDict['deltaT'] = 0.01\n",
    "        if control == 4:\n",
    "            self.blockMeshDict['blocks'][2] = Vector(40,20,1)\n",
    "            self.blockMeshDict.writeFile()\n",
    "            self.controlDict['deltaT'] = 0.01\n",
    "            \n",
    "    def write_interval(self, writeInterval):\n",
    "        self.controlDict['writeInterval'] = writeInterval\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        '''環境のリセット'''\n",
    "        \n",
    "        # reset control Dict\n",
    "        clDict = ParsedParameterFile(self.CASE.controlDict())\n",
    "        clDict['startTime'] = 0\n",
    "        clDict['endTime'] = self.stride\n",
    "        #clDict['deltaT'] = 1\n",
    "        #clDict['writeInterval'] = 400\n",
    "        clDict.writeFile()\n",
    "        self.startTime = clDict['startTime']\n",
    "        self.endTime = clDict['endTime']\n",
    "        \n",
    "        #os.system('./Allclean')\n",
    "        os.system(self.CASE.name + '/Makemesh')\n",
    "        \n",
    "        # 初期条件の設定（ランダム）\n",
    "        T_initial = ParsedParameterFile(self.CASE.initialDir() + '/T')\n",
    "        # random parameter from 26 to 35\n",
    "        T_rand = np.random.randint(26+273,35+273)\n",
    "        T_initial['internalField'].setUniform(T_rand)\n",
    "        T_initial.writeFile()\n",
    "        \n",
    "        \n",
    "        # set action and observation\n",
    "        self.action_space= self.make_action()\n",
    "        self.observation = self.make_observation(self.CASE.initialDir())\n",
    "        return self.observation\n",
    "    \n",
    "    def step(self, action):\n",
    "        '''ステップを進める'''\n",
    "        \n",
    "        clDict = ParsedParameterFile(self.CASE.controlDict())      \n",
    "        if clDict['endTime'] > self.end:\n",
    "            done = True\n",
    "            runOK = 'end'\n",
    "        else:\n",
    "            done = False\n",
    "            \n",
    "            # actionに従った、境界条件を設定\n",
    "            # action is 0~26\n",
    "            U_latest = ParsedParameterFile(self.CASE.latestDir() + '/U')\n",
    "            T_latest = ParsedParameterFile(self.CASE.latestDir() + '/T')\n",
    "            self.act = self.action_space[action]\n",
    "            U_latest['boundaryField']['inlet']['value'].setUniform(Vector(self.act[0],self.act[1],0))\n",
    "            U_latest.writeFile()\n",
    "            T_latest['boundaryField']['inlet']['value'].setUniform(self.act[2])\n",
    "            T_latest.writeFile()\n",
    "            \n",
    "            # OpenFOAMのコマンドを実行\n",
    "            args=shlex.split(\"buoyantPimpleFoam -case \" + self.CASE.name)\n",
    "            buoyant=BasicRunner(args,silent=True)\n",
    "            self.summary=buoyant.start()\n",
    "            runOK = buoyant.runOK()\n",
    "            \n",
    "            #os.system(\"buoyantBoussinesqPimpleFoam\")\n",
    "            \n",
    "            # clDictのコントロール\n",
    "            #clDict = ParsedParameterFile(self.CASE.controlDict())\n",
    "            #clDict['startTime'] = self.startTime + self.stride\n",
    "            #clDict['endTime'] = self.endTime + self.stride\n",
    "            #clDict['deltaT'] = 1\n",
    "            #clDict['writeInterval'] = 400\n",
    "            #clDict.writeFile()\n",
    "            \n",
    "            self.startTime = clDict['startTime']\n",
    "            self.endTime = clDict['endTime']\n",
    "            \n",
    "            self.observation = self.make_observation(self.CASE.latestDir())\n",
    "            \n",
    "        return (self.observation, done, runOK)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 微妙。とりあえずは使わない方向。\n",
    "class SubprocAircond():\n",
    "    def __init__(self, envs):\n",
    "        # 今回は並列は考えない。\n",
    "        # いつか考えようかと思うけど、流体の方にGPU使えばいいかなー。\n",
    "        self.envs = envs\n",
    "        self.observation_space = envs[0].observation_space\n",
    "        self.action_space = envs[0].action_space\n",
    "\n",
    "    def reset(self):\n",
    "        Obs = []\n",
    "        Obs_append = Obs.append\n",
    "        for env in self.envs:\n",
    "            obs = env.reset()\n",
    "            Obs_append(obs)\n",
    "        return Obs\n",
    "    \n",
    "    def step(self, actions):\n",
    "        Obs, Done, RunOK = [], [], []\n",
    "        Obs_append = Obs.append\n",
    "        Done_append = Done.append\n",
    "        RunOK_append = RunOK.append\n",
    "        for env, action in zip(self.envs, actions):\n",
    "            obs, done, runOK = env.step(action)\n",
    "            Obs_append(obs)\n",
    "            Done_append(done)\n",
    "            RunOK_append(runOK)\n",
    "        return Obs, Done, RunOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# aircondを並列でたくさんつくるためのクラス\n",
    "\n",
    "# ケースの作成\n",
    "def makecase(NUM_PROCESSES):\n",
    "    os.system(\"./makecase {}\".format(NUM_PROCESSES))\n",
    "    Envs = []\n",
    "    Envs_append = Envs.append\n",
    "    for i in range(NUM_PROCESSES):\n",
    "        CASE = SolutionDirectory(\"./Case/case{}\".format(i))\n",
    "        aircond = Aircond(CASE)\n",
    "        Envs_append(aircond)\n",
    "    return Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Envs = makecase(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[303., 303., 303., ..., 303., 303., 303.],\n",
       "        [303., 303., 303., ..., 303., 303., 303.],\n",
       "        [303., 303., 303., ..., 303., 303., 303.],\n",
       "        ...,\n",
       "        [303., 303., 303., ..., 303., 303., 303.],\n",
       "        [303., 303., 303., ..., 303., 303., 303.],\n",
       "        [303., 303., 303., ..., 303., 303., 303.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Envs[0].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 9.33696e-02],\n",
       "        [-1.38918e-01],\n",
       "        [-1.28016e-01],\n",
       "        ...,\n",
       "        [ 3.02870e+02],\n",
       "        [ 3.02870e+02],\n",
       "        [ 3.02903e+02]]), False, True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Envs[0].step(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エージェントが持つ頭脳となるクラスを定義、全エージェントで共有する\n",
    "\n",
    "\n",
    "class Brain(object):\n",
    "    def __init__(self, actor_critic):\n",
    "\n",
    "        self.actor_critic = actor_critic  # actor_criticはクラスNetのディープ・ニューラルネットワーク\n",
    "\n",
    "        # 結合パラメータをロードする場合\n",
    "        #filename = 'weight.pth'\n",
    "        #param = torch.load(filename, map_location='cpu')\n",
    "        # self.actor_critic.load_state_dict(param)\n",
    "\n",
    "        # パラメータ更新の勾配法の設定\n",
    "        self.optimizer = optim.RMSprop(\n",
    "            actor_critic.parameters(), lr=lr, eps=eps, alpha=alpha)\n",
    "\n",
    "    def update(self, rollouts):\n",
    "        '''advanced計算した5つのstepの全てを使って更新します'''\n",
    "        obs_shape = rollouts.observations.size()[2:]  # torch.Size([4, 84, 84])\n",
    "        num_steps = NUM_ADVANCED_STEP\n",
    "        num_processes = NUM_PROCESSES\n",
    "\n",
    "        values, action_log_probs, dist_entropy = self.actor_critic.evaluate_actions(\n",
    "            rollouts.observations[:-1].view(-1, *obs_shape),\n",
    "            rollouts.actions.view(-1, 1))\n",
    "\n",
    "        # 注意：各変数のサイズ\n",
    "        # rollouts.observations[:-1].view(-1, *obs_shape) torch.Size([80, 4, 84, 84])\n",
    "        # rollouts.actions.view(-1, 1) torch.Size([80, 1])\n",
    "        # values torch.Size([80, 1])\n",
    "        # action_log_probs torch.Size([80, 1])\n",
    "        # dist_entropy torch.Size([])\n",
    "\n",
    "        values = values.view(num_steps, num_processes,\n",
    "                             1)  # torch.Size([5, 16, 1])\n",
    "        action_log_probs = action_log_probs.view(num_steps, num_processes, 1)\n",
    "\n",
    "        advantages = rollouts.returns[:-1] - values  # torch.Size([5, 16, 1])\n",
    "        value_loss = advantages.pow(2).mean()\n",
    "\n",
    "        action_gain = (advantages.detach() * action_log_probs).mean()\n",
    "        # detachしてadvantagesを定数として扱う\n",
    "\n",
    "        total_loss = (value_loss * value_loss_coef -\n",
    "                      action_gain - dist_entropy * entropy_coef)\n",
    "\n",
    "        self.optimizer.zero_grad()  # 勾配をリセット\n",
    "        total_loss.backward()  # バックプロパゲーションを計算\n",
    "        nn.utils.clip_grad_norm_(self.actor_critic.parameters(), max_grad_norm)\n",
    "        #  一気に結合パラメータが変化しすぎないように、勾配の大きさは最大0.5までにする\n",
    "\n",
    "        self.optimizer.step()  # 結合パラメータを更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定数の設定\n",
    "\n",
    "#ENV_NAME = 'BreakoutNoFrameskip-v4' \n",
    "# Breakout-v0ではなく、BreakoutNoFrameskip-v4を使用\n",
    "# v0はフレームが自動的に2-4のランダムにskipされますが、今回はフレームスキップはさせないバージョンを使用\n",
    "# 参考URL https://becominghuman.ai/lets-build-an-atari-ai-part-1-dqn-df57e8ff3b26\n",
    "# https://github.com/openai/gym/blob/5cb12296274020db9bb6378ce54276b31e7002da/gym/envs/__init__.py#L371\n",
    "    \n",
    "NUM_SKIP_FRAME = 4 # skipするframe数です\n",
    "NUM_STACK_FRAME = 1  # 状態として連続的に保持するframe数です\n",
    "NOOP_MAX = 30  #  reset時に何もしないフレームを挟む（No-operation）フレーム数の乱数上限です\n",
    "NUM_PROCESSES = 2 #  並列して同時実行するプロセス数です\n",
    "NUM_ADVANCED_STEP = 5  # 何ステップ進めて報酬和を計算するのか設定\n",
    "GAMMA = 0.99  # 時間割引率\n",
    "\n",
    "TOTAL_FRAMES=10e6  #  学習に使用する総フレーム数\n",
    "NUM_UPDATES = int(TOTAL_FRAMES / NUM_ADVANCED_STEP / NUM_PROCESSES)  # ネットワークの総更新回数\n",
    "# NUM_UPDATESは125,000となる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2Cの損失関数の計算のための定数設定\n",
    "value_loss_coef = 0.5\n",
    "entropy_coef = 0.01\n",
    "max_grad_norm = 0.5\n",
    "\n",
    "# 学習手法RMSpropの設定\n",
    "lr = 7e-4\n",
    "eps = 1e-5\n",
    "alpha = 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GPUの使用の設定\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_obs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8602d5115b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurrent_obs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'current_obs' is not defined"
     ]
    }
   ],
   "source": [
    "current_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5136a989c5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'obs' is not defined"
     ]
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
       "\n",
       "         [[306., 306., 306.,  ..., 306., 306., 306.],\n",
       "          [306., 306., 306.,  ..., 306., 306., 306.],\n",
       "          [306., 306., 306.,  ..., 306., 306., 306.],\n",
       "          ...,\n",
       "          [306., 306., 306.,  ..., 306., 306., 306.],\n",
       "          [306., 306., 306.,  ..., 306., 306., 306.],\n",
       "          [306., 306., 306.,  ..., 306., 306., 306.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
       "\n",
       "         [[305., 305., 305.,  ..., 305., 305., 305.],\n",
       "          [305., 305., 305.,  ..., 305., 305., 305.],\n",
       "          [305., 305., 305.,  ..., 305., 305., 305.],\n",
       "          ...,\n",
       "          [305., 305., 305.,  ..., 305., 305., 305.],\n",
       "          [305., 305., 305.,  ..., 305., 305., 305.],\n",
       "          [305., 305., 305.,  ..., 305., 305., 305.]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 流体版\n",
    "\n",
    "# seedの設定\n",
    "seed_num = 1\n",
    "torch.manual_seed(seed_num)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "\n",
    "# 実行環境を構築\n",
    "torch.set_num_threads(seed_num)\n",
    "# 実行環境を構築\n",
    "Envs = makecase(NUM_PROCESSES)\n",
    "#Envs = SubprocVecEnv(Envs)  # マルチプロセスの実行環境にする\n",
    "\n",
    "# 全エージェントが共有して持つ頭脳Brainを生成\n",
    "n_out = Envs[0].action_space.shape[0]  # 行動の種類は27\n",
    "actor_critic = Net(n_out).to(device)  # GPUへ\n",
    "global_brain = Brain(actor_critic)\n",
    "\n",
    "# 格納用変数の生成\n",
    "obs_shape = Envs[0].observation_space.shape  # (3, 40, 12)\n",
    "#obs_shape = (obs_shape[0] * NUM_STACK_FRAME,\n",
    "#             *obs_shape[1:])  # (4, 84, 84)\n",
    "# 状態数は一個でやる\n",
    "\n",
    "# torch.Size([16, 4, 84, 84])\n",
    "current_obs = torch.zeros(NUM_PROCESSES, *obs_shape).to(device)\n",
    "rollouts = RolloutStorage(\n",
    "    NUM_ADVANCED_STEP, NUM_PROCESSES, obs_shape)  # rolloutsのオブジェクト\n",
    "episode_rewards = torch.zeros([NUM_PROCESSES, 1])  # 現在の試行の報酬を保持\n",
    "final_rewards = torch.zeros([NUM_PROCESSES, 1])  # 最後の試行の報酬和を保持\n",
    "\n",
    "# 初期状態の開始\n",
    "for i in range(NUM_PROCESSES):\n",
    "    if i==0:\n",
    "        obs = Envs[i].reset()\n",
    "    else:\n",
    "        obs_ = Envs[i].reset()\n",
    "        obs = np.array([obs, obs_])\n",
    "\n",
    "obs = torch.from_numpy(obs).float()  # torch.Size([16, 1, 84, 84])\n",
    "#current_obs[:, -1:] = obs  # flameの4番目に最新のobsを格納\n",
    "\n",
    "# advanced学習用のオブジェクトrolloutsの状態の1つ目に、現在の状態を保存\n",
    "rollouts.observations[0].copy_(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2Cのディープ・ニューラルネットワークの構築\n",
    "\n",
    "\n",
    "def init(module, gain):\n",
    "    '''層の結合パラメータを初期化する関数を定義'''\n",
    "    nn.init.orthogonal_(module.weight.data, gain=gain)\n",
    "    nn.init.constant_(module.bias.data, 0)\n",
    "    return module\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    '''コンボリューション層の出力画像を1次元に変換する層を定義'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_out):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 結合パラメータの初期化関数\n",
    "        def init_(module): return init(\n",
    "            module, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        # コンボリューション層の定義\n",
    "        self.conv = nn.Sequential(\n",
    "            # 画像サイズの変化84*84→20*20\n",
    "            init_(nn.Conv2d(NUM_STACK_FRAME, 32, kernel_size=8, stride=4)),\n",
    "            # stackするflameは4画像なのでinput=NUM_STACK_FRAME=4である、出力は32とする、\n",
    "            # sizeの計算  size = (Input_size - Kernel_size + 2*Padding_size)/ Stride_size + 1\n",
    "\n",
    "            nn.ReLU(),\n",
    "            # 画像サイズの変化20*20→9*9\n",
    "            init_(nn.Conv2d(32, 64, kernel_size=4, stride=2)),\n",
    "            nn.ReLU(),\n",
    "            init_(nn.Conv2d(64, 64, kernel_size=3, stride=1)),  # 画像サイズの変化9*9→7*7\n",
    "            nn.ReLU(),\n",
    "            Flatten(),  # 画像形式を1次元に変換\n",
    "            init_(nn.Linear(64 * 7 * 7, 512)),  # 64枚の7×7の画像を、512次元のoutputへ\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 結合パラメータの初期化関数\n",
    "        def init_(module): return init(module, gain=1.0)\n",
    "\n",
    "        # Criticの定義\n",
    "        self.critic = init_(nn.Linear(512, 1))  # 状態価値なので出力は1つ\n",
    "\n",
    "        # 結合パラメータの初期化関数\n",
    "        def init_(module): return init(module, gain=0.01)\n",
    "\n",
    "        # Actorの定義\n",
    "        self.actor = init_(nn.Linear(512, n_out))  # 行動を決めるので出力は行動の種類数\n",
    "\n",
    "        # ネットワークを訓練モードに設定\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''ネットワークのフォワード計算を定義します'''\n",
    "        input = x / 255.0  # 画像のピクセル値0-255を0-1に正規化する\n",
    "        conv_output = self.conv(input)  # Convolution層の計算\n",
    "        critic_output = self.critic(conv_output)  # 状態価値の計算\n",
    "        actor_output = self.actor(conv_output)  # 行動の計算\n",
    "\n",
    "        return critic_output, actor_output\n",
    "\n",
    "    def act(self, x):\n",
    "        '''状態xから行動を確率的に求めます'''\n",
    "        value, actor_output = self(x)\n",
    "        probs = F.softmax(actor_output, dim=1)    # dim=1で行動の種類方向に計算\n",
    "        action = probs.multinomial(num_samples=1)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def get_value(self, x):\n",
    "        '''状態xから状態価値を求めます'''\n",
    "        value, actor_output = self(x)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def evaluate_actions(self, x, actions):\n",
    "        '''状態xから状態価値、実際の行動actionsのlog確率とエントロピーを求めます'''\n",
    "        value, actor_output = self(x)\n",
    "\n",
    "        log_probs = F.log_softmax(actor_output, dim=1)  # dim=1で行動の種類方向に計算\n",
    "        action_log_probs = log_probs.gather(1, actions)  # 実際の行動のlog_probsを求める\n",
    "\n",
    "        probs = F.softmax(actor_output, dim=1)  # dim=1で行動の種類方向に計算\n",
    "        dist_entropy = -(log_probs * probs).sum(-1).mean()\n",
    "\n",
    "        return value, action_log_probs, dist_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test():\n",
    "    def __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
       "\n",
       "         [[307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          ...,\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
       "\n",
       "         [[307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          ...,\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.],\n",
       "          [307., 307., 307.,  ..., 307., 307., 307.]]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollouts.observations[step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 行動を求める\n",
    "with torch.no_grad():\n",
    "    action = actor_critic.act(rollouts.observations[step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rollouts.observations[step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic = Net(n_out).to(device)  # GPUへ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 84, 84])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3842],\n",
       "         [-0.3842]], grad_fn=<ThAddmmBackward>),\n",
       " tensor([[0.0033, 0.0013, 0.0005, 0.0005],\n",
       "         [0.0033, 0.0013, 0.0005, 0.0005]], grad_fn=<ThAddmmBackward>))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 8, 8], expected input[2, 3, 40, 12] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-e17026f6d725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# dim=1で行動の種類方向に計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-cd17885e9e47>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;34m'''ネットワークのフォワード計算を定義します'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m  \u001b[0;31m# 画像のピクセル値0-255を0-1に正規化する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mconv_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convolution層の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mcritic_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 状態価値の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mactor_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 行動の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 8, 8], expected input[2, 3, 40, 12] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "value, actor_output = actor_critic(x)\n",
    "probs = F.softmax(actor_output, dim=1)    # dim=1で行動の種類方向に計算\n",
    "action = probs.multinomial(num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1716],\n",
       "        [0.1716]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0012, -0.0007, -0.0024, -0.0013],\n",
       "        [ 0.0012, -0.0007, -0.0024, -0.0013]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2505, 0.2500, 0.2496, 0.2499],\n",
       "        [0.2505, 0.2500, 0.2496, 0.2499]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 8, 8], expected input[2, 3, 40, 12] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b19675934145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 行動を求める\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcpu_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# tensorをNumPyに\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-cd17885e9e47>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m'''状態xから行動を確率的に求めます'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# dim=1で行動の種類方向に計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-cd17885e9e47>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;34m'''ネットワークのフォワード計算を定義します'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m  \u001b[0;31m# 画像のピクセル値0-255を0-1に正規化する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mconv_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convolution層の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mcritic_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 状態価値の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mactor_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 行動の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 8, 8], expected input[2, 3, 40, 12] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "\n",
    "# 実行ループ\n",
    "#for j in tqdm(range(NUM_UPDATES)):\n",
    "    # advanced学習するstep数ごとに計算\n",
    "    #for step in range(NUM_ADVANCED_STEP):\n",
    "\n",
    "\n",
    "j=0\n",
    "step=0\n",
    "\n",
    "# 行動を求める\n",
    "with torch.no_grad():\n",
    "    action = actor_critic.act(rollouts.observations[step])\n",
    "\n",
    "cpu_actions = action.squeeze(1).cpu().numpy()  # tensorをNumPyに\n",
    "\n",
    "# 1stepの並列実行、なお返り値のobsのsizeは(16, 1, 84, 84)\n",
    "obs, reward, done, info = envs.step(cpu_actions)\n",
    "\n",
    "# 報酬をtensorに変換し、試行の総報酬に足す\n",
    "# sizeが(16,)になっているのを(16, 1)に変換\n",
    "reward = np.expand_dims(np.stack(reward), 1)\n",
    "reward = torch.from_numpy(reward).float()\n",
    "episode_rewards += reward\n",
    "\n",
    "# 各実行環境それぞれについて、doneならmaskは0に、継続中ならmaskは1にする\n",
    "masks = torch.FloatTensor(\n",
    "    [[0.0] if done_ else [1.0] for done_ in done])\n",
    "\n",
    "# 最後の試行の総報酬を更新する\n",
    "final_rewards *= masks  # 継続中の場合は1をかけ算してそのまま、done時には0を掛けてリセット\n",
    "# 継続中は0を足す、done時にはepisode_rewardsを足す\n",
    "final_rewards += (1 - masks) * episode_rewards\n",
    "\n",
    "# 試行の総報酬を更新する\n",
    "episode_rewards *= masks  # 継続中のmaskは1なのでそのまま、doneの場合は0に\n",
    "\n",
    "# masksをGPUへ\n",
    "masks = masks.to(device)\n",
    "\n",
    "# 現在の状態をdone時には全部0にする\n",
    "# maskのサイズをtorch.Size([16, 1])→torch.Size([16, 1, 1 ,1])へ変換して、かけ算\n",
    "current_obs *= masks.unsqueeze(2).unsqueeze(2)\n",
    "\n",
    "# frameをstackする\n",
    "# torch.Size([16, 1, 84, 84])\n",
    "obs = torch.from_numpy(obs).float()\n",
    "current_obs[:, :-1] = current_obs[:, 1:]  # 0～2番目に1～3番目を上書き\n",
    "current_obs[:, -1:] = obs  # 4番目に最新のobsを格納\n",
    "\n",
    "# メモリオブジェクトに今stepのtransitionを挿入\n",
    "rollouts.insert(current_obs, action.data, reward, masks)\n",
    "\n",
    "\n",
    "# ------------------\n",
    "\n",
    "\n",
    "# advancedのfor loop終了\n",
    "\n",
    "# advancedした最終stepの状態から予想する状態価値を計算\n",
    "with torch.no_grad():\n",
    "    next_value = actor_critic.get_value(\n",
    "        rollouts.observations[-1]).detach()\n",
    "\n",
    "# 全stepの割引報酬和を計算して、rolloutsの変数returnsを更新\n",
    "rollouts.compute_returns(next_value)\n",
    "\n",
    "# ネットワークとrolloutの更新\n",
    "global_brain.update(rollouts)\n",
    "rollouts.after_update()\n",
    "\n",
    "# ログ：途中経過の出力\n",
    "if j % 100 == 0:\n",
    "    print(\"finished frames {}, mean/median reward {:.1f}/{:.1f}, min/max reward {:.1f}/{:.1f}\".\n",
    "          format(j*NUM_PROCESSES*NUM_ADVANCED_STEP,\n",
    "                 final_rewards.mean(),\n",
    "                 final_rewards.median(),\n",
    "                 final_rewards.min(),\n",
    "                 final_rewards.max()))\n",
    "\n",
    "# 結合パラメータの保存\n",
    "if j % 12500 == 0:\n",
    "    torch.save(global_brain.actor_critic.state_dict(),\n",
    "               'weight_'+str(j)+'.pth')\n",
    "\n",
    "# 実行ループの終了\n",
    "torch.save(global_brain.actor_critic.state_dict(), 'weight_end.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seedの設定\n",
    "seed_num = 1\n",
    "torch.manual_seed(seed_num)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "\n",
    "# 実行環境を構築\n",
    "torch.set_num_threads(seed_num)\n",
    "envs = [make_env(ENV_NAME, seed_num, i) for i in range(NUM_PROCESSES)]\n",
    "envs = SubprocVecEnv(envs)  # マルチプロセスの実行環境にする\n",
    "\n",
    "# 全エージェントが共有して持つ頭脳Brainを生成\n",
    "n_out = envs.action_space.n  # 行動の種類は4\n",
    "actor_critic = Net(n_out).to(device)  # GPUへ\n",
    "global_brain = Brain(actor_critic)\n",
    "\n",
    "# 格納用変数の生成\n",
    "obs_shape = envs.observation_space.shape  # (1, 84, 84)\n",
    "obs_shape = (obs_shape[0] * NUM_STACK_FRAME,\n",
    "             *obs_shape[1:])  # (4, 84, 84)\n",
    "# torch.Size([16, 4, 84, 84])\n",
    "current_obs = torch.zeros(NUM_PROCESSES, *obs_shape).to(device)\n",
    "rollouts = RolloutStorage(\n",
    "    NUM_ADVANCED_STEP, NUM_PROCESSES, obs_shape)  # rolloutsのオブジェクト\n",
    "episode_rewards = torch.zeros([NUM_PROCESSES, 1])  # 現在の試行の報酬を保持\n",
    "final_rewards = torch.zeros([NUM_PROCESSES, 1])  # 最後の試行の報酬和を保持\n",
    "\n",
    "# 初期状態の開始\n",
    "obs = envs.reset()\n",
    "obs = torch.from_numpy(obs).float()  # torch.Size([16, 1, 84, 84])\n",
    "current_obs[:, -1:] = obs  # flameの4番目に最新のobsを格納\n",
    "\n",
    "# advanced学習用のオブジェクトrolloutsの状態の1つ目に、現在の状態を保存\n",
    "rollouts.observations[0].copy_(current_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step=0\n",
    "with torch.no_grad():\n",
    "    action = actor_critic.act(rollouts.observations[step])\n",
    "cpu_actions = action.squeeze(1).cpu().numpy()  # tensorをNumPyに\n",
    "\n",
    "# 1stepの並列実行、なお返り値のobsのsizeは(16, 1, 84, 84)\n",
    "obs, reward, done, info = envs.step(cpu_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seedの設定\n",
    "seed_num = 1\n",
    "torch.manual_seed(seed_num)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "\n",
    "# 実行環境を構築\n",
    "torch.set_num_threads(seed_num)\n",
    "envs = [make_env(ENV_NAME, seed_num, i) for i in range(NUM_PROCESSES)]\n",
    "envs = SubprocVecEnv(envs)  # マルチプロセスの実行環境にする\n",
    "\n",
    "# 全エージェントが共有して持つ頭脳Brainを生成\n",
    "n_out = envs.action_space.n  # 行動の種類は4\n",
    "actor_critic = Net(n_out).to(device)  # GPUへ\n",
    "global_brain = Brain(actor_critic)\n",
    "\n",
    "# 格納用変数の生成\n",
    "obs_shape = envs.observation_space.shape  # (1, 84, 84)\n",
    "obs_shape = (obs_shape[0] * NUM_STACK_FRAME,\n",
    "             *obs_shape[1:])  # (4, 84, 84)\n",
    "# torch.Size([16, 4, 84, 84])\n",
    "current_obs = torch.zeros(NUM_PROCESSES, *obs_shape).to(device)\n",
    "rollouts = RolloutStorage(\n",
    "    NUM_ADVANCED_STEP, NUM_PROCESSES, obs_shape)  # rolloutsのオブジェクト\n",
    "episode_rewards = torch.zeros([NUM_PROCESSES, 1])  # 現在の試行の報酬を保持\n",
    "final_rewards = torch.zeros([NUM_PROCESSES, 1])  # 最後の試行の報酬和を保持\n",
    "\n",
    "# 初期状態の開始\n",
    "obs = envs.reset()\n",
    "obs = torch.from_numpy(obs).float()  # torch.Size([16, 1, 84, 84])\n",
    "current_obs[:, -1:] = obs  # flameの4番目に最新のobsを格納\n",
    "\n",
    "# advanced学習用のオブジェクトrolloutsの状態の1つ目に、現在の状態を保存\n",
    "rollouts.observations[0].copy_(current_obs)\n",
    "\n",
    "# 実行ループ\n",
    "for j in tqdm(range(NUM_UPDATES)):\n",
    "    # advanced学習するstep数ごとに計算\n",
    "    for step in range(NUM_ADVANCED_STEP):\n",
    "\n",
    "        # 行動を求める\n",
    "        with torch.no_grad():\n",
    "            action = actor_critic.act(rollouts.observations[step])\n",
    "\n",
    "        cpu_actions = action.squeeze(1).cpu().numpy()  # tensorをNumPyに\n",
    "\n",
    "        # 1stepの並列実行、なお返り値のobsのsizeは(16, 1, 84, 84)\n",
    "        obs, reward, done, info = envs.step(cpu_actions)\n",
    "\n",
    "        # 報酬をtensorに変換し、試行の総報酬に足す\n",
    "        # sizeが(16,)になっているのを(16, 1)に変換\n",
    "        reward = np.expand_dims(np.stack(reward), 1)\n",
    "        reward = torch.from_numpy(reward).float()\n",
    "        episode_rewards += reward\n",
    "\n",
    "        # 各実行環境それぞれについて、doneならmaskは0に、継続中ならmaskは1にする\n",
    "        masks = torch.FloatTensor(\n",
    "            [[0.0] if done_ else [1.0] for done_ in done])\n",
    "\n",
    "        # 最後の試行の総報酬を更新する\n",
    "        final_rewards *= masks  # 継続中の場合は1をかけ算してそのまま、done時には0を掛けてリセット\n",
    "        # 継続中は0を足す、done時にはepisode_rewardsを足す\n",
    "        final_rewards += (1 - masks) * episode_rewards\n",
    "\n",
    "        # 試行の総報酬を更新する\n",
    "        episode_rewards *= masks  # 継続中のmaskは1なのでそのまま、doneの場合は0に\n",
    "\n",
    "        # masksをGPUへ\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        # 現在の状態をdone時には全部0にする\n",
    "        # maskのサイズをtorch.Size([16, 1])→torch.Size([16, 1, 1 ,1])へ変換して、かけ算\n",
    "        current_obs *= masks.unsqueeze(2).unsqueeze(2)\n",
    "\n",
    "        # frameをstackする\n",
    "        # torch.Size([16, 1, 84, 84])\n",
    "        obs = torch.from_numpy(obs).float()\n",
    "        current_obs[:, :-1] = current_obs[:, 1:]  # 0～2番目に1～3番目を上書き\n",
    "        current_obs[:, -1:] = obs  # 4番目に最新のobsを格納\n",
    "\n",
    "        # メモリオブジェクトに今stepのtransitionを挿入\n",
    "        rollouts.insert(current_obs, action.data, reward, masks)\n",
    "\n",
    "    # advancedのfor loop終了\n",
    "\n",
    "    # advancedした最終stepの状態から予想する状態価値を計算\n",
    "    with torch.no_grad():\n",
    "        next_value = actor_critic.get_value(\n",
    "            rollouts.observations[-1]).detach()\n",
    "\n",
    "    # 全stepの割引報酬和を計算して、rolloutsの変数returnsを更新\n",
    "    rollouts.compute_returns(next_value)\n",
    "\n",
    "    # ネットワークとrolloutの更新\n",
    "    global_brain.update(rollouts)\n",
    "    rollouts.after_update()\n",
    "\n",
    "    # ログ：途中経過の出力\n",
    "    if j % 100 == 0:\n",
    "        print(\"finished frames {}, mean/median reward {:.1f}/{:.1f}, min/max reward {:.1f}/{:.1f}\".\n",
    "              format(j*NUM_PROCESSES*NUM_ADVANCED_STEP,\n",
    "                     final_rewards.mean(),\n",
    "                     final_rewards.median(),\n",
    "                     final_rewards.min(),\n",
    "                     final_rewards.max()))\n",
    "\n",
    "    # 結合パラメータの保存\n",
    "    if j % 12500 == 0:\n",
    "        torch.save(global_brain.actor_critic.state_dict(),\n",
    "                   'weight_'+str(j)+'.pth')\n",
    "\n",
    "# 実行ループの終了\n",
    "torch.save(global_brain.actor_critic.state_dict(), 'weight_end.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
