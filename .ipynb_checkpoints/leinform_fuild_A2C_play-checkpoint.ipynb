{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流体版強化学習を流すためのファイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "#!/usr/bin/python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.spaces.box import Box\n",
    "\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import PyFoam\n",
    "import PyFoam.FoamInformation\n",
    "from PyFoam.RunDictionary.SolutionDirectory import SolutionDirectory\n",
    "from PyFoam.RunDictionary.ParsedParameterFile import ParsedParameterFile\n",
    "from PyFoam.Basics.DataStructures import Vector\n",
    "from PyFoam.Execution.BasicRunner import BasicRunner\n",
    "from PyFoam.Basics.TemplateFile import TemplateFile\n",
    "import shlex,sys,json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from copy import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory\n",
    "# 試す用\n",
    "CASE = SolutionDirectory(\"../aircond5/Case/case0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 実行環境の設定\n",
    "\n",
    "class Aircond:\n",
    "    '''Aircondのクラス'''\n",
    "    def __init__(self, CASE, stride=500,end=3000,xCells=40,\n",
    "                         insert_list = [15,15,15,15,33,33,33,51,69,69,69,87,105,105,105,142,142,142,342,342,380,380]):\n",
    "        self.CASE = CASE\n",
    "        # メッシュを作らないとpolymeshがないので。\n",
    "        os.system(CASE.name + '/Makemesh')\n",
    "        # get nCells\n",
    "        with open (self.CASE.name + '/constant/polyMesh/neighbour') as f:\n",
    "            neighbour = f.read()\n",
    "        nCells_index = neighbour.find('nCells')\n",
    "        nCells_ = neighbour[nCells_index : nCells_index+15]\n",
    "        nCells = int(re.sub(r'\\D', '', nCells_))\n",
    "        self.nCells = nCells\n",
    "        \n",
    "        self.action_SPEED = np.array([0.1,0.3,0.5])\n",
    "        self.action_DIRECTION = np.array([-1*np.pi/8, -2*np.pi/8,-3*np.pi/8])\n",
    "        self.action_TEMPERTURE = np.array([18+273.15,22+273.15,26+273.15])\n",
    "        self.action_space = np.tile(np.array([0,0,0]),(27,1))\n",
    "        self.observation_space_ = np.tile(np.array([0,0,0]),(self.nCells,1))\n",
    "        #self.observation_space = np.tile(np.array([0]), (self.nCells*3,1)\n",
    "        \n",
    "        self.xCells = xCells\n",
    "        self.insert_list = insert_list\n",
    "        observation_space = np.tile(np.array([0,0,0]), (self.nCells+len(self.insert_list),1))\n",
    "        U_space_x = observation_space[:,0].reshape(self.xCells,-1)\n",
    "        U_space_y = observation_space[:,1].reshape(self.xCells,-1)\n",
    "        T_space = observation_space[:,2].reshape(self.xCells,-1)\n",
    "        self.observation_space = np.array([U_space_x, U_space_y, T_space]) \n",
    "        \n",
    "        self.stride = stride  # 進めるステップの幅\n",
    "        # stepが始まってからのtime。始まる前にstepを進めた場合は含まれず0\n",
    "        self.present_time = 0  \n",
    "        # openFoam側のcontrolDictに記載されているtime\n",
    "        self.startTime = 0\n",
    "        self.endTime = copy(self.stride)\n",
    "        # いつ終了するか\n",
    "        self.end = end\n",
    "        \n",
    "        # 各辞書ファイルの取得\n",
    "        self.initialDir = self.CASE.initialDir()+'/'\n",
    "        self.constant = self.CASE.name + \"/constant/\"\n",
    "        self.system = self.CASE.name + \"/system/\"\n",
    "        self.initialDir_file = []\n",
    "        for x in os.listdir(self.initialDir):\n",
    "            if os.path.isfile(self.initialDir + x):\n",
    "                self.initialDir_file.append(x)\n",
    "        self.constant_file = []\n",
    "        for y in os.listdir(self.constant):\n",
    "            if os.path.isfile(self.constant + y):\n",
    "                self.constant_file.append(y)\n",
    "        self.system_file = []\n",
    "        for z in os.listdir(self.system):\n",
    "            if os.path.isfile(self.system + z):\n",
    "                self.system_file.append(z)\n",
    "        \n",
    "        # 各辞書ファイルをそれぞれのファイル名で保存\n",
    "        for i in range(len(self.initialDir_file)):\n",
    "            self.__dict__[self.initialDir_file[i]] = ParsedParameterFile(self.initialDir + self.initialDir_file[i])\n",
    "\n",
    "        for i in range(len(self.system_file)):\n",
    "            self.__dict__[self.system_file[i]] = ParsedParameterFile(self.system + self.system_file[i])\n",
    "            \n",
    "    def initial_to_float(self, numpy_Parsed_value):\n",
    "        '''uniformをnp.arrayに変換'''\n",
    "        numpy_Parsed_value = np.array(numpy_Parsed_value)\n",
    "        if numpy_Parsed_value.ndim==0:\n",
    "            Parsed_raw = str(numpy_Parsed_value.all())\n",
    "            Parsed_str = Parsed_raw[8:].strip('()').split(' ')\n",
    "            Parsed_int = np.array(list(map(float,Parsed_str)))\n",
    "            #Parsed = np.tile(Parsed_int,(self.nCells,1))\n",
    "        return Parsed_int\n",
    "    \n",
    "    def initial_to_array(self, numpy_Parsed_value):\n",
    "        '''uniformをnCellの数だけnp.arrayに変換'''\n",
    "        numpy_Parsed_value = np.array(numpy_Parsed_value)\n",
    "        if numpy_Parsed_value.ndim==0:\n",
    "            Parsed_raw = str(numpy_Parsed_value.all())\n",
    "            Parsed_str = Parsed_raw[8:].strip('()').split(' ')\n",
    "            Parsed_int = np.array(list(map(float,Parsed_str)))\n",
    "            Parsed = np.tile(Parsed_int,(self.nCells,1))\n",
    "        return Parsed\n",
    "\n",
    "    def make_observation_old(self,Dir):\n",
    "        '''Dirのpathのobservationを取得'''\n",
    "        U_value = np.array(ParsedParameterFile(Dir + '/U').content['internalField'])\n",
    "        T_value = np.array(ParsedParameterFile(Dir + '/T').content['internalField'])\n",
    "        if U_value.ndim == 0:\n",
    "            U_value = self.initial_to_array(U_value)\n",
    "            T_value = self.initial_to_array(T_value)\n",
    "        U_value_xy = np.delete(U_value, axis=1, obj=2)\n",
    "        T_value_x = np.reshape(T_value, [-1,1], order='F')\n",
    "        Observation = np.concatenate([U_value_xy, T_value_x],axis=1)\n",
    "        return Observation    \n",
    "    \n",
    "    def make_observation_onerow(self,Dir):\n",
    "        '''Dirのpathのobservationを取得\n",
    "        各U1, U2, Tがすべて一列で並んだ状態を返す'''\n",
    "        U_value = np.array(ParsedParameterFile(Dir + '/U').content['internalField'])\n",
    "        T_value = np.array(ParsedParameterFile(Dir + '/T').content['internalField'])\n",
    "        if U_value.ndim == 0:\n",
    "            U_value = self.initial_to_array(U_value)\n",
    "            T_value = self.initial_to_array(T_value)\n",
    "        #U_value_xy = np.delete(U_value, axis=1, obj=2)\n",
    "        T_value_x = T_value.reshape(-1, 1)\n",
    "        U_value_x = U_value[:,0].reshape(-1, 1)\n",
    "        U_value_y = U_value[:,1].reshape(-1, 1)\n",
    "        observation = np.concatenate([U_value_x, U_value_y, T_value_x], axis=0)\n",
    "        return observation\n",
    "    \n",
    "    def make_observation(self,Dir,celsius=True):\n",
    "        '''observationを２次元で取得。\n",
    "        障害物があるところは全て値を0で埋める。\n",
    "        self.xCells : x方向のセル数\n",
    "        self.insert_list : 障害物があり、値を0で埋めるべき場所\n",
    "        '''\n",
    "        U_value = np.array(ParsedParameterFile(Dir + '/U').content['internalField'])\n",
    "        T_value = np.array(ParsedParameterFile(Dir + '/T').content['internalField'])\n",
    "        if U_value.ndim == 0:\n",
    "            U_value = self.initial_to_array(U_value)\n",
    "            T_value = self.initial_to_array(T_value)\n",
    "        # セルシウス℃に直す\n",
    "        if celsius:\n",
    "            T_value = self.Celsius_(T_value)\n",
    "            T_value = T_value.astype(np.float64)\n",
    "        U_value_xy = np.delete(U_value, axis=1, obj=2)\n",
    "        T_value_x = np.reshape(T_value, [-1,1], order='F')\n",
    "        observation_ = np.concatenate([U_value_xy, T_value_x],axis=1)  # 3 axis observation\n",
    "        observation_ = np.insert(observation_, self.insert_list, [0,0,0], axis=0)\n",
    "        U_value_x = observation_[:,0].reshape(self.xCells,-1)\n",
    "        U_value_y = observation_[:,1].reshape(self.xCells,-1)\n",
    "        T_value = observation_[:,2].reshape(self.xCells,-1)\n",
    "        observation = np.array([U_value_x, U_value_y, T_value])\n",
    "        return observation\n",
    "    \n",
    "    def make_action(self):\n",
    "        '''actionの設定'''\n",
    "        Action = np.empty((0,3),float)\n",
    "        for i in range(len(self.action_SPEED)):\n",
    "            for j in range(len(self.action_DIRECTION)):\n",
    "                for k in range(len(self.action_TEMPERTURE)):\n",
    "                    Ux = self.action_SPEED[i]*np.cos(self.action_DIRECTION[j])\n",
    "                    Uy = self.action_SPEED[i]*np.sin(self.action_DIRECTION[j])\n",
    "                    Act = np.array([[Ux,Uy,self.action_TEMPERTURE[k]]])\n",
    "                    Action = np.append(Action,Act,axis=0)\n",
    "                    \n",
    "        return Action\n",
    "    \n",
    "    def getParsed(self,time_step):\n",
    "        '''各time_stepのParsedParameterFileを取得'''\n",
    "        T = ParsedParameterFile(self.CASE.name + '/' + str(time_step) + '/T')\n",
    "        U = ParsedParameterFile(self.CASE.name + '/' + str(time_step) + '/U')\n",
    "        TU_list = [T,U]\n",
    "        return TU_list\n",
    "    \n",
    "    \n",
    "    def getParsedList(self,first_step, last_step, write_step,):\n",
    "        '''各time_stepのParsedParameterFileを取得'''\n",
    "        TU_list = []\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            T = ParsedParameterFile(self.CASE.name + '/' + str(stp) + '/T')\n",
    "            U = ParsedParameterFile(self.CASE.name + '/' + str(stp) + '/U')\n",
    "            TU_list.append([T,U])\n",
    "        return TU_list\n",
    "    \n",
    "    # 後にcythonで書き直す予定\n",
    "    def calc_PMV(self, TA=20,VA=0.3,TR=20,RH=50,AL=1,CLO=1):\n",
    "        \"\"\"PMVとPPDを計算\n",
    "        デフォルト値。TA,VA,TR,RHまでは入力を推奨\n",
    "        TA = 20  #  温度[℃]\n",
    "        VA = 0.3  # 流速[m/s]\n",
    "        TR = 20  # MRT[℃]\n",
    "        RH = 50  # 相対湿度[%]\n",
    "        AL = 1  # 活動量[met]\n",
    "        CLO = 1 # 着衣量[clo]\n",
    "        \n",
    "        \"\"\"\n",
    "        #***************************************************\n",
    "        # 外部仕事 W＝0 [W/㎡]とする。\n",
    "        #***************************************************\n",
    "        # PMV 計算準備\n",
    "        #\n",
    "        M = AL * 58.15\n",
    "        LCL = CLO\n",
    "        W = 0\n",
    "        #PA = (RH / 100 * np.exp(18.6686 - 4030.18 / (TA + 235))) / 0.00750062\n",
    "        PPK = 673.4 - 1.8 * TA\n",
    "        PPA = 3.2437814 + 0.00326014 * PPK + 2.00658 * 1E-9 * PPK * PPK * PPK\n",
    "        PPB = (1165.09 - PPK) * (1 + 0.00121547 * PPK)\n",
    "        PA = RH / 100 * 22105.8416 / np.exp(2.302585 * PPK * PPA / PPB) * 1000\n",
    "        EPS = 1E-5\n",
    "        MW = M - W\n",
    "        # FCL＝着衣表面積／裸体表面積の比\n",
    "        if LCL > 0.5:\n",
    "            FCL = 1.05 + 0.1 * LCL\n",
    "        else:\n",
    "            FCL = 1 + 0.2 * LCL\n",
    "        # 衣服表面温度TCLの初期値設定\n",
    "        TCL = TA\n",
    "        TCLA = TCL\n",
    "        NOI = 1\n",
    "        # 着衣表面温度の計算\n",
    "        while True:\n",
    "            TCLA = 0.8 * TCLA + 0.2 * TCL\n",
    "            HC = 12.1 * np.sqrt(VA)\n",
    "            if 2.38 * np.sqrt(np.sqrt(abs(TCL - TA))) > HC:\n",
    "                HC = 2.38 * np.sqrt(np.sqrt(abs(TCL - TA)))\n",
    "            TCL = 35.7 - 0.028 * MW - 0.155 * LCL * (3.96 * 1E-8 * FCL * ((TCLA + 273) ** 4 - (TR + 273) ** 4) + FCL * HC * (TCLA - TA))\n",
    "            NOI = NOI + 1\n",
    "            if NOI > 150:\n",
    "                #PMV = 999990.999\n",
    "                PMB = 3.0\n",
    "                PPD = 100\n",
    "                return (PMV,PPD)\n",
    "            if not abs(TCLA - TCL) > EPS:\n",
    "                break\n",
    "        #PMVの計算\n",
    "        PM1 = 3.96 * 1E-8 * FCL * ((TCL + 273) ** 4 - (TA + 273) ** 4)\n",
    "        PM2 = FCL * HC * (TCL - TA)\n",
    "        PM3 = 0.303 * np.exp(-0.036 * M) + 0.028\n",
    "        if MW > 58.15:\n",
    "            PM4 = 0.42 * (MW - 58.15)\n",
    "        else:\n",
    "            PM4 = 0\n",
    "        PMV = PM3 * (MW - 3.05 * 0.001 * (5733 - 6.99 * MW - PA) - PM4 - 1.7 * 1E-5 * M * (5867 - PA) - 0.0014 * M * (34 - TA) - PM1 - PM2)\n",
    "            #PRINT PMV\n",
    "        if abs(PMV) > 3:\n",
    "            #PMV = 999990.999\n",
    "            PMV = 3.0\n",
    "            PPD = 100\n",
    "            return (PMV,PPD)\n",
    "        \n",
    "        PPD = 100 - 95 * np.exp(-0.0335 * PMV ** 4 - 0.2179 * PMV ** 2)\n",
    "        \n",
    "        return (PMV,PPD)\n",
    "    \n",
    "    def calc_MRT(self, T_Parsed):\n",
    "        '''MRTを計算'''\n",
    "        \n",
    "        T_wall_list = np.array([])\n",
    "        if np.array(T_Parsed['internalField']).ndim==0:  # time_step=0\n",
    "            for boundary in list(T_Parsed['boundaryField']):\n",
    "                if T_Parsed['boundaryField'][boundary]['type']=='zeroGradient' or \\\n",
    "                T_Parsed['boundaryField'][boundary]['type']=='empty' or \\\n",
    "                    T_Parsed['boundaryField'][boundary]['type']=='fixedValue':\n",
    "                    T_wall = np.array([])\n",
    "                else:\n",
    "                    numpy_Parsed_value = np.array(T_Parsed['boundaryField'][boundary]['value'])\n",
    "                    T_wall = self.initial_to_float(numpy_Parsed_value)\n",
    "                T_wall_list = np.append(T_wall_list, T_wall)\n",
    "                \n",
    "        else:\n",
    "            for boundary in list(T_Parsed['boundaryField']):\n",
    "                if T_Parsed['boundaryField'][boundary]['type']=='fixedValue':\n",
    "                    numpy_Parsed_value = np.array(T_Parsed['boundaryField'][boundary]['value'])\n",
    "                    T_wall = self.initial_to_float(numpy_Parsed_value)\n",
    "                elif T_Parsed['boundaryField'][boundary]['type']=='zeroGradient' or \\\n",
    "                T_Parsed['boundaryField'][boundary]['type']=='empty':\n",
    "                    T_wall = np.array([])\n",
    "                else:\n",
    "                    T_wall = np.array(T_Parsed['boundaryField'][boundary]['value'])\n",
    "                    if T_wall.ndim==0:\n",
    "                        T_wall = self.initial_to_float(T_wall)\n",
    "                T_wall_list = np.append(T_wall_list, T_wall)\n",
    "        return np.average(T_wall_list)\n",
    "    \n",
    "    def Celsius(self, T):\n",
    "        CelsiusT = T - 273.15\n",
    "        return CelsiusT\n",
    "    \n",
    "    def Celsius_(self, T):\n",
    "        '''np.arrayの配列をセルシウス℃に変換'''\n",
    "        if np.array(T).size==1:\n",
    "            return self.Celsius(T)\n",
    "        else:\n",
    "            Celsiuss = np.frompyfunc(self.Celsius,1,1)  # リストに適用可にする\n",
    "            return Celsiuss(T)\n",
    "        \n",
    "    def UScalar(self, U):\n",
    "        '''Uをスカラーに変換'''\n",
    "        if np.array(U).size<=3:\n",
    "            return np.array([np.sqrt(U[0]**2 + U[1]**2)])\n",
    "        else:\n",
    "            return np.sqrt(U[:,0]**2 + U[:,1]**2)\n",
    "        \n",
    "    def calc_PMV_all(self, TU_Parsed,RH=50,AL=1,CLO=1):\n",
    "        '''PMVを一つのtime_stepで全点計算\n",
    "        TU_Parsed : TとUのParsedParameterFileをリストにしたもの\n",
    "        全ての点のPMVとPPVの値を返す\n",
    "        time=0でも、すべてのセルの値を返す。'''\n",
    "        T_Parsed,U_Parsed = TU_Parsed\n",
    "        T = np.array(T_Parsed['internalField'])\n",
    "        U = np.array(U_Parsed['internalField'])\n",
    "        # time_step==0の場合\n",
    "        if T.ndim==0 or U.ndim==0:\n",
    "            T = self.initial_to_float(T)\n",
    "            U = self.initial_to_float(U)\n",
    "            # Uを速さに変換\n",
    "            Us = self.UScalar(U)\n",
    "            MRT = self.calc_MRT(T_Parsed)\n",
    "            # TとMRTをセルシウス温度に変換\n",
    "            Tc = self.Celsius_(T)\n",
    "            MRTc = self.Celsius_(MRT)\n",
    "            pmv,ppd = self.calc_PMV(TA=Tc,VA=Us,TR=MRTc,RH=RH,AL=AL,CLO=CLO)\n",
    "            PMV = np.tile(pmv, self.nCells)\n",
    "            PPD = np.tile(ppd, self.nCells)\n",
    "        else:   \n",
    "            # Uを速さに変換\n",
    "            Us = self.UScalar(U)\n",
    "            MRT = self.calc_MRT(T_Parsed)\n",
    "            # TとMRTをセルシウス温度に変換\n",
    "            Tc = list(self.Celsius_(T))\n",
    "            MRTc = self.Celsius_(MRT)\n",
    "            \n",
    "            length = len(T)\n",
    "            # ループを早くするため、外に出す。\n",
    "            PMV = []\n",
    "            PPD = []\n",
    "            PMVappend = PMV.append\n",
    "            PPDappend = PPD.append\n",
    "            for i in range(length):\n",
    "                pmv,ppd = self.calc_PMV(TA=Tc[i],VA=Us[i],TR=MRTc,RH=RH,AL=AL,CLO=CLO)\n",
    "                PMVappend(pmv)\n",
    "                PPDappend(ppd)\n",
    "            PMV = np.array(PMV)\n",
    "            PPD = np.array(PPD)\n",
    "        return [PMV,PPD]\n",
    "    \n",
    "    def calc_PMV_error(self, TU_Parsed,RH=50,AL=1,CLO=1):\n",
    "        \"\"\"PMVの全点の2条誤差の合計を計算\n",
    "        入力はcalc_PMV_allと同じ。返すものだけが違う。\n",
    "        PMVは、0との2乗誤差、PPDは0との、根平均2乗誤差を返す。\n",
    "        \"\"\"\n",
    "        PMV, PPD = self.calc_PMV_all(TU_Parsed, RH=RH,AL=AL,CLO=CLO)\n",
    "        PMV_mae = ((PMV - 0)**2).mean()\n",
    "        PPD_rmse = np.sqrt( ((PPD - 0)**2).mean())\n",
    "        return PMV_mae, PPD_rmse\n",
    "    \n",
    "    def header(self, time_step, filename):\n",
    "        '''headerファイルを作成'''\n",
    "        header = \"\"\"/*--------------------------------*- C++ -*----------------------------------*\\\n",
    "=========                 |\n",
    "  \\\\      /  F ield         | OpenFOAM: The Open Source CFD Toolbox\n",
    "   \\\\    /   O peration     | Website:  https://openfoam.org\n",
    "    \\\\  /    A nd           | Version:  6\n",
    "     \\\\/     M anipulation  |\n",
    "\\*---------------------------------------------------------------------------*/\n",
    "FoamFile\n",
    "{{\n",
    "    version     2.0;\n",
    "    format      ascii;\n",
    "    class       volScalarField;\n",
    "    location    \"{}\";\n",
    "    object      {};\n",
    "}}\n",
    "// * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * //\n",
    "\"\"\".format(time_step, filename)\n",
    "        return header\n",
    "    \n",
    "    def internal(self, list_internal):\n",
    "        '''internalFieldの値の作成'''\n",
    "        if len(list_internal)==1:\n",
    "            internal = \"\"\"\n",
    "internalField   uniform {};\"\"\".format(list_internal[0])\n",
    "        else:\n",
    "            str_= np.frompyfunc(str,1,1)\n",
    "            str_internal = '\\n'.join(str_(list_internal))\n",
    "            internal = \"\"\"\n",
    "internalField   nonuniform List<scalar> \n",
    "{}\n",
    "(\n",
    "{}\n",
    ")\n",
    ";\n",
    "\"\"\".format(self.nCells, str_internal)\n",
    "        return internal\n",
    "    \n",
    "    def makePMVFile(self,time_step):\n",
    "        '''PMVとPPDファイルを書き込む'''\n",
    "        \n",
    "        path_pmv = self.CASE.name + '/' + str(time_step) + '/PMV' # 書き込むパス\n",
    "        path_ppd = self.CASE.name + '/' + str(time_step) + '/PPD'\n",
    "        \n",
    "        demensions = \"\"\"\n",
    "dimensions      [0 0 0 0 0 0 0];\n",
    "\"\"\"\n",
    "        \n",
    "        boundary = \"\"\"\n",
    "boundaryField\n",
    "{\n",
    "    \".*\"\n",
    "    {\n",
    "        type            zeroGradient;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// ************************************************************************* //\n",
    "\"\"\"\n",
    "        # header, dimensions, internal, boundaryの順に書き込む\n",
    "        f = open(path_pmv, 'w') # ファイルを開く(該当ファイルがなければ新規作成)\n",
    "        g = open(path_ppd, 'w')\n",
    "        f.write(self.header(time_step,\"PMV\")) # headerを記載する\n",
    "        g.write(self.header(time_step,\"PPD\"))\n",
    "        f.write(demensions) # dimensionsを記載する\n",
    "        g.write(demensions)\n",
    "        # internalFieldの計算\n",
    "        TU_Parsed = self.getParsed(time_step)\n",
    "        PMV,PPD = self.calc_PMV_all(TU_Parsed)\n",
    "        internal_PMV = self.internal(PMV)\n",
    "        internal_PPD = self.internal(PPD)\n",
    "        f.write(internal_PMV)  \n",
    "        g.write(internal_PPD)\n",
    "        f.write(boundary)\n",
    "        g.write(boundary)\n",
    "        f.close() \n",
    "        g.close()\n",
    "\n",
    "        \n",
    "    def makePMVList(self,first_step, last_step, write_step):\n",
    "        '''任意の範囲でPMVファイルを作成'''\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            self.makePMVFile(stp)\n",
    "            \n",
    "        \n",
    "    def meshNumberFile(self,time_step):\n",
    "        '''メッシュの並びを確認する'''\n",
    "        path_mesh = self.CASE.name + '/' + str(time_step) + '/Meshnumber' # 書き込むパス\n",
    "\n",
    "\n",
    "        demensions = \"\"\"\n",
    "dimensions      [0 0 0 0 0 0 0];\n",
    "\"\"\"\n",
    "        boundary = \"\"\"\n",
    "boundaryField\n",
    "{\n",
    "    \".*\"\n",
    "    {\n",
    "        type            zeroGradient;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// ************************************************************************* //\n",
    "\"\"\"\n",
    "        f = open(path_mesh, 'w') # ファイルを開く(該当ファイルがなければ新規作成)\n",
    "        f.write(self.header(time_step,\"PMV\")) # headerを記載する\n",
    "        f.write(demensions) # dimensionsを記載する\n",
    "        mesh_list = [x for x in range(1,self.nCells+1)]\n",
    "        internal_mesh = self.internal(mesh_list)\n",
    "        f.write(internal_mesh)  \n",
    "        f.write(boundary)\n",
    "        f.close() \n",
    "            \n",
    "    def calc_ADPI(self,TU_Parsed,occupied_zone_cell):\n",
    "        '''ADPIを計算する'''\n",
    "        \n",
    "        # occupied_zone_cellはaircond5の場合は1~340までのセルが居住域\n",
    "        T_Parsed,U_Parsed = TU_Parsed\n",
    "        T = np.array(T_Parsed['internalField'])\n",
    "        U = np.array(U_Parsed['internalField'])\n",
    "        # time_step==0の場合\n",
    "        if T.ndim==0 or U.ndim==0:\n",
    "            T = self.initial_to_float(T)\n",
    "            U = self.initial_to_float(U)\n",
    "        \n",
    "        Tc = np.average(T)  # 室内の平均温度\n",
    "        Us = self.UScalar(U)  # 流速\n",
    "        theta = (T - Tc) - 8.0*(Us - 0.15)  # 有効ドラフト温度\n",
    "        \n",
    "        satisfy_theta = np.where((theta > -1.5) & (theta < 1), 1, 0)\n",
    "        satisfy_Us = np.where(Us < 0.35,1, 0)  # 条件を満たすものを1,満たさないものを0\n",
    "        satisfy_all = satisfy_theta + satisfy_Us\n",
    "        satisfy = satisfy_all[:occupied_zone_cell]\n",
    "        nCells = satisfy.size\n",
    "        num_satisfy = np.sum(satisfy == 2)\n",
    "        ADPI = num_satisfy/nCells*100\n",
    "        \n",
    "        return (ADPI, theta)\n",
    "    \n",
    "    def calc_EUC(self,T_Parsed, occupied_zone_cell,last_cell):\n",
    "        '''EUCを計算する'''\n",
    "        \n",
    "        T = np.array(T_Parsed['internalField'])\n",
    "        T0 = self.initial_to_float(T_Parsed['boundaryField']['inlet']['value'])[0] # 給気温度\n",
    "\n",
    "        if T.ndim==0:\n",
    "            T = self.initial_to_float(T)[0]\n",
    "            Toz = T\n",
    "            Tiz = T\n",
    "        else:\n",
    "            Toz = np.average(T[occupied_zone_cell:last_cell])  # 居住域外の平均温度  \n",
    "            Tiz = np.average(T[:occupied_zone_cell])  # 居住域内の平均温度\n",
    "        EUC = (Toz-T0) / (Tiz-T0) * 100\n",
    "        return EUC\n",
    "        \n",
    "    def getPMVList(self, first_step, last_step, write_step):\n",
    "        '''任意の範囲のPMVの平均値ファイルを取得'''\n",
    "        \n",
    "        # ループを早くするため、外に出す。\n",
    "        PMV_list = []\n",
    "        PPD_list = []\n",
    "        PMVappend = PMV_list.append\n",
    "        PPDappend = PPD_list.append\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            TU_Parsed = self.getParsed(stp)\n",
    "            PMV,PPD = self.calc_PMV_all(TU_Parsed)\n",
    "            pmv = np.average(np.array(PMV))\n",
    "            ppd = np.average(np.array(PPD))\n",
    "            PMVappend(pmv)\n",
    "            PPDappend(ppd)\n",
    "        return [PMV_list, PPD_list]\n",
    "    \n",
    "    \n",
    "    def getADPIList(self, first_step, last_step, write_step,occupied_zone_cell=342):\n",
    "        '''任意の範囲のADPIの値を取得'''\n",
    "        \n",
    "        ADPI_list = []\n",
    "        ADPIappend = ADPI_list.append\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            TU_Parsed = self.getParsed(stp)\n",
    "            adpi,theta = self.calc_ADPI(TU_Parsed, occupied_zone_cell)\n",
    "            ADPIappend(adpi)\n",
    "        return ADPI_list\n",
    "    \n",
    "    def getEUCList(self, first_step, last_step, write_step,\n",
    "                    occupied_zone_cell=342, last_cell=100000):\n",
    "        '''任意の範囲のEUCの値を算出'''\n",
    "        \n",
    "        EUC_list = []\n",
    "        EUCappend = EUC_list.append\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            T_Parsed,U_Parsed = self.getParsed(stp)\n",
    "            euc = self.calc_EUC(T_Parsed, occupied_zone_cell, last_cell)\n",
    "            EUCappend(euc)\n",
    "        return EUC_list\n",
    "    \n",
    "    def getTUList(self, first_step, last_step, write_step):\n",
    "        '''任意の範囲のTとUの平均値を取得'''\n",
    "        \n",
    "        T_list = []\n",
    "        U_list = []\n",
    "        MRT_list = []\n",
    "        Tappend = T_list.append\n",
    "        Uappend = U_list.append\n",
    "        MRTappend = MRT_list.append\n",
    "        for stp in range(first_step, last_step, write_step):\n",
    "            T_Parsed, U_Parsed = self.getParsed(stp)\n",
    "            T = np.array(T_Parsed['internalField'])\n",
    "            U = np.array(U_Parsed['internalField'])\n",
    "            # time_step==0の場合\n",
    "            if T.ndim==0 or U.ndim==0:\n",
    "                T = self.initial_to_float(T)\n",
    "                U = self.initial_to_float(U)\n",
    "            # Uを速さに変換\n",
    "            T = np.average(T)\n",
    "            Us = np.average(np.array(self.UScalar(U)))\n",
    "            MRT = np.average(np.array(self.calc_MRT(T_Parsed)))\n",
    "            # TとMRTをセルシウス温度に変換\n",
    "            Tc = self.Celsius(T)\n",
    "            MRTc = self.Celsius(MRT)\n",
    "            Tappend(Tc)\n",
    "            Uappend(Us)\n",
    "            MRTappend(MRTc)\n",
    "        return [T_list,U_list,MRT_list]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def change_control(self,control):\n",
    "        if control == 1:\n",
    "            self.blockMeshDict['blocks'][2] = Vector(20,10,1)\n",
    "            self.blockMeshDict.writeFile()\n",
    "            self.controlDict['deltaT'] = 0.02\n",
    "        if control == 2:\n",
    "            self.blockMeshDict['blocks'][2] = Vector(40,20,1)\n",
    "            self.blockMeshDict.writeFile()\n",
    "            self.controlDict['deltaT'] = 0.02\n",
    "        if control == 3:\n",
    "            self.blockMeshDict['blocks'][2] = Vector(20,10,1)\n",
    "            self.blockMeshDict.writeFile()\n",
    "            self.controlDict['deltaT'] = 0.01\n",
    "        if control == 4:\n",
    "            self.blockMeshDict['blocks'][2] = Vector(40,20,1)\n",
    "            self.blockMeshDict.writeFile()\n",
    "            self.controlDict['deltaT'] = 0.01\n",
    "            \n",
    "    def change_write_interval(self, writeInterval):\n",
    "        self.controlDict['writeInterval'] = writeInterval\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        '''環境のリセット'''\n",
    "        \n",
    "        # reset parameter\n",
    "        self.present_time = 0  \n",
    "        self.startTime = 0\n",
    "        self.endTime = copy(self.stride)\n",
    "        \n",
    "        # reset control Dict\n",
    "        clDict = ParsedParameterFile(self.CASE.controlDict())\n",
    "        clDict['startTime'] = self.startTime\n",
    "        clDict['endTime'] = self.endTime\n",
    "        clDict.writeFile()\n",
    "        #self.startTime = clDict['startTime']\n",
    "        #self.endTime = clDict['endTime']\n",
    "        \n",
    "        #os.system('./Allclean')\n",
    "        os.system(self.CASE.name + '/Makemesh')\n",
    "        \n",
    "        # 初期条件の設定（ランダム）\n",
    "        T_initial = ParsedParameterFile(self.CASE.initialDir() + '/T')\n",
    "        # random parameter from 26 to 35\n",
    "        T_rand = np.random.randint(26+273,35+273)\n",
    "        T_initial['internalField'].setUniform(T_rand)\n",
    "        T_initial.writeFile()\n",
    "        \n",
    "        \n",
    "        # set action and observation\n",
    "        self.action_space= self.make_action()\n",
    "        self.observation = self.make_observation(self.CASE.initialDir())\n",
    "        return self.observation\n",
    "    \n",
    "    def step_old(self, action):\n",
    "        '''ステップを進める'''\n",
    "        #clDict = ParsedParameterFile(self.CASE.controlDict())      \n",
    "        if self.present_time >= self.end:\n",
    "            done = True\n",
    "            runOK = 'end'\n",
    "        else:\n",
    "            done = False\n",
    "            \n",
    "            # actionに従った、境界条件を設定\n",
    "            # action is 0~26\n",
    "            U_latest = ParsedParameterFile(self.CASE.latestDir() + '/U')\n",
    "            T_latest = ParsedParameterFile(self.CASE.latestDir() + '/T')\n",
    "            self.act = self.action_space[action]\n",
    "            U_latest['boundaryField']['inlet']['value'].setUniform(Vector(self.act[0],self.act[1],0))\n",
    "            U_latest.writeFile()\n",
    "            T_latest['boundaryField']['inlet']['value'].setUniform(self.act[2])\n",
    "            T_latest.writeFile()\n",
    "            \n",
    "            # OpenFOAMのコマンドを実行\n",
    "            args=shlex.split(\"buoyantPimpleFoam -case \" + self.CASE.name)\n",
    "            buoyant=BasicRunner(args,silent=True)\n",
    "            self.summary=buoyant.start()\n",
    "            runOK = buoyant.runOK()\n",
    "            \n",
    "            #os.system(\"buoyantBoussinesqPimpleFoam\")\n",
    "            \n",
    "            # clDictのコントロール\n",
    "            self.present_time += self.stride\n",
    "            clDict = ParsedParameterFile(self.CASE.controlDict())\n",
    "            self.startTime += self.stride\n",
    "            self.endTime += self.stride\n",
    "            clDict['startTime'] = self.startTime\n",
    "            clDict['endTime'] = self.endTime\n",
    "            clDict.writeFile()\n",
    "            \n",
    "            self.startTime = clDict['startTime']\n",
    "            self.endTime = clDict['endTime']\n",
    "            \n",
    "            self.observation = self.make_observation(self.CASE.latestDir())\n",
    "            \n",
    "        return (self.observation, done, runOK)\n",
    "    \n",
    "    \n",
    "    def step(self, action, reward='PMV'):\n",
    "        '''ステップを進める\n",
    "        報酬はPMV等から選択\n",
    "        '''\n",
    "        #clDict = ParsedParameterFile(self.CASE.controlDict())      \n",
    "        if self.present_time >= self.end:\n",
    "            done = True\n",
    "            runOK = 'end'\n",
    "            # rewardと、observationは1ステップ前の値をそのまま使う。\n",
    "        else:\n",
    "            done = False\n",
    "            \n",
    "            # actionに従った、境界条件を設定\n",
    "            # action is 0~26\n",
    "            U_latest = ParsedParameterFile(self.CASE.latestDir() + '/U')\n",
    "            T_latest = ParsedParameterFile(self.CASE.latestDir() + '/T')\n",
    "            self.act = self.action_space[action]\n",
    "            U_latest['boundaryField']['inlet']['value'].setUniform(Vector(self.act[0],self.act[1],0))\n",
    "            U_latest.writeFile()\n",
    "            T_latest['boundaryField']['inlet']['value'].setUniform(self.act[2])\n",
    "            T_latest.writeFile()\n",
    "            \n",
    "            # OpenFOAMのコマンドを実行\n",
    "            args=shlex.split(\"buoyantPimpleFoam -case \" + self.CASE.name)\n",
    "            buoyant=BasicRunner(args,silent=True)\n",
    "            self.summary=buoyant.start()\n",
    "            runOK = buoyant.runOK()\n",
    "            \n",
    "            #os.system(\"buoyantBoussinesqPimpleFoam\")\n",
    "            \n",
    "            # clDictのコントロール\n",
    "            self.present_time += self.stride\n",
    "            clDict = ParsedParameterFile(self.CASE.controlDict())\n",
    "            self.startTime += self.stride\n",
    "            self.endTime += self.stride\n",
    "            clDict['startTime'] = self.startTime\n",
    "            clDict['endTime'] = self.endTime\n",
    "            clDict.writeFile()\n",
    "            \n",
    "            self.startTime = clDict['startTime']\n",
    "            self.endTime = clDict['endTime']\n",
    "            \n",
    "            self.observation = self.make_observation(self.CASE.latestDir())\n",
    "            \n",
    "            # 報酬の計算。make_observationでは、0を補完していれているため、用いない。\n",
    "            T_new = ParsedParameterFile(self.CASE.latestDir() + '/T')\n",
    "            U_new = ParsedParameterFile(self.CASE.latestDir() + '/U')\n",
    "            TU_Parsed = [T_new,U_new]\n",
    "            PMV_mae, PPD_rmse = self.calc_PMV_error(TU_Parsed, RH=50,AL=1,CLO=1)\n",
    "            # 報酬は、ズレ分をマイナス、ちかづいたら、プラスにする。\n",
    "            self.reward = -PMV_mae + 1\n",
    "            \n",
    "        \n",
    "        return (self.observation, self.reward, done, runOK)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aircondを並列でたくさんつくるためのクラス\n",
    "\n",
    "# ケースの作成\n",
    "def makecase(NUM_PROCESSES,casename='Case',stride=500, end=3000, xCells=40,\n",
    "                         insert_list = [15,15,15,15,33,33,33,51,69,69,69,87,105,105,105,142,142,142,342,342,380,380]):\n",
    "    \"\"\"並列でたくさんのケースをつくる\n",
    "    xCells : x方向のセル数\n",
    "    insert_list : 障害物があり、ゼロ埋めするセル\n",
    "    \"\"\"\n",
    "    os.system(\"./makecase {} {}\".format(NUM_PROCESSES, casename))\n",
    "    Envs = []\n",
    "    Envs_append = Envs.append\n",
    "    for i in range(NUM_PROCESSES):\n",
    "        CASE = SolutionDirectory(\"./{}/case{}\".format(casename, i))\n",
    "        aircond = Aircond(CASE, stride=stride, end=end, xCells=xCells, insert_list=insert_list)\n",
    "        Envs_append(aircond)\n",
    "    return Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定数の設定\n",
    "\n",
    "#ENV_NAME = 'BreakoutNoFrameskip-v4' \n",
    "# Breakout-v0ではなく、BreakoutNoFrameskip-v4を使用\n",
    "# v0はフレームが自動的に2-4のランダムにskipされますが、今回はフレームスキップはさせないバージョンを使用\n",
    "# 参考URL https://becominghuman.ai/lets-build-an-atari-ai-part-1-dqn-df57e8ff3b26\n",
    "# https://github.com/openai/gym/blob/5cb12296274020db9bb6378ce54276b31e7002da/gym/envs/__init__.py#L371\n",
    "    \n",
    "#NUM_SKIP_FRAME = 4 # skipするframe数です  # 使用しない。\n",
    "NUM_STACK_FRAME = 1  # 状態として連続的に保持するframe数です\n",
    "#NOOP_MAX = 30  #  reset時に何もしないフレームを挟む（No-operation）フレーム数の乱数上限です\n",
    "NUM_PROCESSES = 2 #  並列して同時実行するプロセス数です\n",
    "NUM_ADVANCED_STEP = 5  # 何ステップ進めて報酬和を計算するのか設定\n",
    "GAMMA = 0.90  # 時間割引率\n",
    "\n",
    "TOTAL_FRAMES=10e6  #  学習に使用する総フレーム数\n",
    "NUM_UPDATES = int(TOTAL_FRAMES / NUM_ADVANCED_STEP / NUM_PROCESSES)  # ネットワークの総更新回数\n",
    "# NUM_UPDATESは125,000となる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_UPDATES = 1000\n",
    "STRIDE = 100\n",
    "END = 500\n",
    "XCELLS = 40\n",
    "INSERT_LIST = [15,15,15,15,33,33,33,51,69,69,69,87,105,105,105,142,142,142,342,342,380,380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2Cの損失関数の計算のための定数設定\n",
    "value_loss_coef = 0.5\n",
    "entropy_coef = 0.01\n",
    "max_grad_norm = 0.5\n",
    "\n",
    "# 学習手法RMSpropの設定\n",
    "lr = 7e-4\n",
    "eps = 1e-5\n",
    "alpha = 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GPUの使用の設定\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メモリオブジェクトの定義\n",
    "\n",
    "\n",
    "class RolloutStorage(object):\n",
    "    '''Advantage学習するためのメモリクラスです'''\n",
    "\n",
    "    def __init__(self, num_steps, num_processes, obs_shape):\n",
    "\n",
    "        self.observations = torch.zeros(\n",
    "            num_steps + 1, num_processes, *obs_shape).to(device)\n",
    "        # *を使うと()リストの中身を取り出す\n",
    "        # obs_shape→(4,84,84)\n",
    "        # *obs_shape→ 4 84 84\n",
    "\n",
    "        self.masks = torch.ones(num_steps + 1, num_processes, 1).to(device)\n",
    "        self.rewards = torch.zeros(num_steps, num_processes, 1).to(device)\n",
    "        self.actions = torch.zeros(\n",
    "            num_steps, num_processes, 1).long().to(device)\n",
    "\n",
    "        # 割引報酬和を格納\n",
    "        self.returns = torch.zeros(num_steps + 1, num_processes, 1).to(device)\n",
    "        self.index = 0  # insertするインデックス\n",
    "\n",
    "    def insert(self, current_obs, action, reward, mask):\n",
    "        '''次のindexにtransitionを格納する'''\n",
    "        self.observations[self.index + 1].copy_(current_obs)\n",
    "        self.masks[self.index + 1].copy_(mask)\n",
    "        self.rewards[self.index].copy_(reward)\n",
    "        self.actions[self.index].copy_(action)\n",
    "\n",
    "        self.index = (self.index + 1) % NUM_ADVANCED_STEP  # インデックスの更新\n",
    "\n",
    "    def after_update(self):\n",
    "        '''Advantageするstep数が完了したら、最新のものをindex0に格納'''\n",
    "        self.observations[0].copy_(self.observations[-1])\n",
    "        self.masks[0].copy_(self.masks[-1])\n",
    "\n",
    "    def compute_returns(self, next_value):\n",
    "        '''Advantageするステップ中の各ステップの割引報酬和を計算する'''\n",
    "\n",
    "        # 注意：5step目から逆向きに計算しています\n",
    "        # 注意：5step目はAdvantage1となる。4ステップ目はAdvantage2となる。・・・\n",
    "        self.returns[-1] = next_value\n",
    "        for ad_step in reversed(range(self.rewards.size(0))):\n",
    "            self.returns[ad_step] = self.returns[ad_step + 1] * \\\n",
    "                GAMMA * self.masks[ad_step + 1] + self.rewards[ad_step]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2Cのディープ・ニューラルネットワークの構築\n",
    "\n",
    "\n",
    "def init(module, gain):\n",
    "    '''層の結合パラメータを初期化する関数を定義'''\n",
    "    nn.init.orthogonal_(module.weight.data, gain=gain)\n",
    "    nn.init.constant_(module.bias.data, 0)\n",
    "    return module\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    '''コンボリューション層の出力画像を1次元に変換する層を定義'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_out):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 結合パラメータの初期化関数\n",
    "        def init_(module): return init(\n",
    "            module, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        # コンボリューション層の定義\n",
    "        self.conv = nn.Sequential(\n",
    "            # 画像サイズの変化12*40→4*18\n",
    "            init_(nn.Conv2d(3, 32, kernel_size=5,stride=2)),\n",
    "            # stackするflameは4画像なのでinput=NUM_STACK_FRAME=4である、出力は32とする、\n",
    "            # sizeの計算  size = (Input_size - Kernel_size + 2*Padding_size)/ Stride_size + 1\n",
    "\n",
    "            nn.ReLU(),\n",
    "            # 画像サイズの変化4*18→3*17\n",
    "            init_(nn.Conv2d(32, 64, kernel_size=2, stride=1)),\n",
    "            nn.ReLU(),\n",
    "            init_(nn.Conv2d(64, 64, kernel_size=2, stride=1)),  # 画像サイズの変化3*17→2*16\n",
    "            nn.ReLU(),\n",
    "            Flatten(),  # 画像形式を1次元に変換\n",
    "            init_(nn.Linear(64 * 2 * 16, 512)),  # 64枚の7×7の画像を、512次元のoutputへ\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 結合パラメータの初期化関数\n",
    "        def init_(module): return init(module, gain=1.0)\n",
    "\n",
    "        # Criticの定義\n",
    "        self.critic = init_(nn.Linear(512, 1))  # 状態価値なので出力は1つ\n",
    "\n",
    "        # 結合パラメータの初期化関数\n",
    "        def init_(module): return init(module, gain=0.01)\n",
    "\n",
    "        # Actorの定義\n",
    "        self.actor = init_(nn.Linear(512, n_out))  # 行動を決めるので出力は行動の種類数\n",
    "\n",
    "        # ネットワークを訓練モードに設定\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''ネットワークのフォワード計算を定義します'''\n",
    "        #input = x / 255.0  # 画像のピクセル値0-255を0-1に正規化する\n",
    "        input = x  # 正規化はしない\n",
    "        conv_output = self.conv(input)  # Convolution層の計算\n",
    "        critic_output = self.critic(conv_output)  # 状態価値の計算\n",
    "        actor_output = self.actor(conv_output)  # 行動の計算\n",
    "\n",
    "        return critic_output, actor_output\n",
    "\n",
    "    def act(self, x):\n",
    "        '''状態xから行動を確率的に求めます'''\n",
    "        value, actor_output = self(x)\n",
    "        probs = F.softmax(actor_output, dim=1)    # dim=1で行動の種類方向に計算\n",
    "        action = probs.multinomial(num_samples=1)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def get_value(self, x):\n",
    "        '''状態xから状態価値を求めます'''\n",
    "        value, actor_output = self(x)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def evaluate_actions(self, x, actions):\n",
    "        '''状態xから状態価値、実際の行動actionsのlog確率とエントロピーを求めます'''\n",
    "        value, actor_output = self(x)\n",
    "\n",
    "        log_probs = F.log_softmax(actor_output, dim=1)  # dim=1で行動の種類方向に計算\n",
    "        action_log_probs = log_probs.gather(1, actions)  # 実際の行動のlog_probsを求める\n",
    "\n",
    "        probs = F.softmax(actor_output, dim=1)  # dim=1で行動の種類方向に計算\n",
    "        dist_entropy = -(log_probs * probs).sum(-1).mean()\n",
    "\n",
    "        return value, action_log_probs, dist_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エージェントが持つ頭脳となるクラスを定義、全エージェントで共有する\n",
    "\n",
    "\n",
    "class Brain_play(object):\n",
    "    def __init__(self, actor_critic,filename='weight_end.pth'):\n",
    "\n",
    "        self.actor_critic = actor_critic  # actor_criticはクラスNetのディープ・ニューラルネットワーク\n",
    "\n",
    "        # 結合パラメータをロードする場合\n",
    "        #filename = 'weight_end.pth'\n",
    "        #filename = 'weight_112500.pth'\n",
    "        param = torch.load(filename, map_location='cpu')\n",
    "        self.actor_critic.load_state_dict(param)\n",
    "\n",
    "        # パラメータ更新の勾配法の設定\n",
    "        self.optimizer = optim.RMSprop(\n",
    "            actor_critic.parameters(), lr=lr, eps=eps, alpha=alpha)\n",
    "\n",
    "    def update(self, rollouts):\n",
    "        '''advanced計算した5つのstepの全てを使って更新します'''\n",
    "        obs_shape = rollouts.observations.size()[2:]  # torch.Size([4, 84, 84])\n",
    "        num_steps = NUM_ADVANCED_STEP\n",
    "        num_processes = NUM_PROCESSES\n",
    "\n",
    "        values, action_log_probs, dist_entropy = self.actor_critic.evaluate_actions(\n",
    "            rollouts.observations[:-1].view(-1, *obs_shape),\n",
    "            rollouts.actions.view(-1, 1))\n",
    "\n",
    "        # 注意：各変数のサイズ\n",
    "        # rollouts.observations[:-1].view(-1, *obs_shape) torch.Size([80, 4, 84, 84])\n",
    "        # rollouts.actions.view(-1, 1) torch.Size([80, 1])\n",
    "        # values torch.Size([80, 1])\n",
    "        # action_log_probs torch.Size([80, 1])\n",
    "        # dist_entropy torch.Size([])\n",
    "\n",
    "        values = values.view(num_steps, num_processes,\n",
    "                             1)  # torch.Size([5, 16, 1])\n",
    "        action_log_probs = action_log_probs.view(num_steps, num_processes, 1)\n",
    "\n",
    "        advantages = rollouts.returns[:-1] - values  # torch.Size([5, 16, 1])\n",
    "        value_loss = advantages.pow(2).mean()\n",
    "\n",
    "        action_gain = (advantages.detach() * action_log_probs).mean()\n",
    "        # detachしてadvantagesを定数として扱う\n",
    "\n",
    "        total_loss = (value_loss * value_loss_coef -\n",
    "                      action_gain - dist_entropy * entropy_coef)\n",
    "\n",
    "        self.optimizer.zero_grad()  # 勾配をリセット\n",
    "        total_loss.backward()  # バックプロパゲーションを計算\n",
    "        nn.utils.clip_grad_norm_(self.actor_critic.parameters(), max_grad_norm)\n",
    "        #  一気に結合パラメータが変化しすぎないように、勾配の大きさは最大0.5までにする\n",
    "\n",
    "        self.optimizer.step()  # 結合パラメータを更新\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resets(Envs):\n",
    "    \"\"\"環境をまとめてリセット\"\"\"\n",
    "    obs = []\n",
    "    obs_append = obs.append\n",
    "    for i in range(len(Envs)):\n",
    "        obs_ = Envs[i].reset()\n",
    "        obs_append(obs_)\n",
    "    obs = np.array(obs)\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steps(Envs, action):\n",
    "    \"\"\"すべての環境で同じだけステップを進める\n",
    "    obsはnumpy, done, runOKはリスト\n",
    "    \"\"\"\n",
    "    obs = []\n",
    "    reward = []\n",
    "    done = []\n",
    "    runOK = []\n",
    "    obs_append = obs.append\n",
    "    reward_append = reward.append\n",
    "    done_append = done.append\n",
    "    runOK_append = runOK.append\n",
    "    for i in range(len(Envs)):\n",
    "        obs_, reward_, done_, runOK_ = Envs[i].step(action[i])\n",
    "        obs_append(obs_)\n",
    "        reward_append(reward_)\n",
    "        done_append(done_)\n",
    "        runOK_append(runOK_)\n",
    "    obs = np.array(obs)\n",
    "    return obs, reward, done, runOK\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_actions(Envs, max_execution=3):\n",
    "    \"\"\"適当にステップを進めて、環境をバラバラにするためのステップを作成。\n",
    "    Envs : 環境のリスト\n",
    "    max_execution : 進める最大のステップ。0~ステップ分進めることになる。\n",
    "    random_actionは複素数で返す。0+1Jは補完したもの。\n",
    "    \"\"\"\n",
    "    # 0~max_executions\n",
    "    # 複素数にして、1jは補完したものとする。\n",
    "    action_shape = Envs[0].action_space.shape[0]\n",
    "    random_actions = []\n",
    "    for i in range(len(Envs)):\n",
    "        i_th_action = []\n",
    "        for j in range(random.randint(0,max_execution)):\n",
    "            i_th_action.append(random.randint(0, action_shape-1))\n",
    "        random_actions.append(i_th_action)\n",
    "        \n",
    "    max_len = max(map(len, random_actions))\n",
    "    random_actions = np.array(list(map(lambda x:x + [1j]*(max_len-len(x)), random_actions)))\n",
    "    random_actions = random_actions.astype(np.complex128)\n",
    "    return random_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_steps(Envs, random_actions, step_reset=True):\n",
    "    \"\"\"random_actions分それぞれステップを進める。\n",
    "    Envs : 環境のリスト\n",
    "    random_actions, len(Envs)行,進めるステップ分で構成された、random_step。\n",
    "    step_reset : Envs内のpresent_timeをリセットするかどうか。\n",
    "    \"\"\"\n",
    "    # random_step分stepを進めて、とりあえず、リストとして保存。\n",
    "    obs_list = []\n",
    "    reward_list = []\n",
    "    done_list = []\n",
    "    runOK_list = []\n",
    "    obs_list_append = obs_list.append\n",
    "    reward_list_append = reward_list.append\n",
    "    done_list_append = done_list.append\n",
    "    runOK_list_append = runOK_list.append\n",
    "    # random_actions.shape[0] == len(Envs)だが、やりたくない環境がある場合\n",
    "    # やらないために、len(Envs)は使わない\n",
    "    for i in range(random_actions.shape[0]):\n",
    "        obs_progress = []\n",
    "        reward_progress = []\n",
    "        done_progress = []\n",
    "        runOK_progress = []\n",
    "        obs_progress_append = obs_progress.append\n",
    "        reward_progress_append = reward_progress.append\n",
    "        done_progress_append = done_progress.append\n",
    "        runOK_progress_append = runOK_progress.append\n",
    "        \n",
    "        for j in range(random_actions.shape[1]):\n",
    "            if random_actions[i,j].imag==0:  # 補完しただけのものには1jが入ってる\n",
    "                obs_, done_, reward_, runOK_ = Envs[i].step(int(random_actions[i,j].real))\n",
    "                obs_progress_append(obs_)\n",
    "                reward_progress_append(reward_)\n",
    "            else:\n",
    "                done_, runOK_ = False, True\n",
    "            done_progress_append(done_)\n",
    "            runOK_progress_append(runOK_)\n",
    "            \n",
    "        obs_list_append(obs_progress)\n",
    "        reward_list_append(reward_progress)\n",
    "        done_list_append(done_progress)\n",
    "        runOK_list_append(runOK_progress)\n",
    "    \n",
    "    # 進めた結果をまとめる。\n",
    "    # obs → 最後のステップのobservation or 進めない場合、そのままのobservation\n",
    "    # reward → 最後のステップのreward or 進めない場合、そのままのreward\n",
    "    # done → 一個でもdoneがあれば、done=Trueとする。\n",
    "    # runOK → 一個でも、Falseがあれば、Falseとする。\n",
    "    obs = []\n",
    "    reward = []\n",
    "    done = []\n",
    "    runOK = []\n",
    "    obs_append = obs.append\n",
    "    reward_append = reward.append\n",
    "    done_append = done.append\n",
    "    runOK_append = runOK.append\n",
    "    for i in range(random_actions.shape[0]):\n",
    "        if obs_list[i]==[]:\n",
    "            obs_ = Envs[i].observation\n",
    "        else:\n",
    "            obs_ = obs_list[i][-1]\n",
    "        obs_append(obs_)\n",
    "        \n",
    "        if reward_list[i]==[]:\n",
    "            reward_ = Envs[i].reward\n",
    "        else:\n",
    "            reward_ = reward_list[i][-1]\n",
    "        reward_append(reward_)\n",
    "        \n",
    "        if any(done_list[i]):\n",
    "            done_ = True\n",
    "        else:\n",
    "            done_ = False\n",
    "        done_append(done_)\n",
    "        \n",
    "        if all(runOK_list[i]):\n",
    "            runOK_ = True\n",
    "        else:\n",
    "            runOK_ = False\n",
    "        runOK_append(runOK_)\n",
    "    obs = np.array(obs)\n",
    "    \n",
    "    if step_reset:\n",
    "        for i in range(random_actions.shape[0]):\n",
    "            Envs[i].present_time=0\n",
    "            \n",
    "    return obs, reward, done, runOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Interrupted by the Keyboard\n",
      "Killing PID 10254\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for dimension 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-006afd47a49d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# 行動を求める\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mcpu_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# tensorをNumPyに\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for dimension 0 with size 6"
     ]
    }
   ],
   "source": [
    "# 実行用の関数\n",
    "\n",
    "NUM_PROCESSES_PLAY = 1\n",
    "PLAY_END = 5000\n",
    "PLAY_STEP = int(PLAY_END/STRIDE)\n",
    "PLAY_WRITE_INTERVAL = 1000\n",
    "\n",
    "# 流体版\n",
    "\n",
    "# seedの設定\n",
    "seed_num = 1\n",
    "torch.manual_seed(seed_num)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "\n",
    "# 実行環境を構築\n",
    "torch.set_num_threads(seed_num)\n",
    "Env_play = makecase(NUM_PROCESSES_PLAY, casename='play',stride=STRIDE, end=PLAY_END,\n",
    "                write_interval=PLAY_WRITE_INTERVAL,xCells=XCELLS, insert_list = INSERT_LIST)\n",
    "\n",
    "# 全エージェントが共有して持つ頭脳Brainを生成\n",
    "n_out = Env_play[0].action_space.shape[0]  # 行動の種類は27\n",
    "actor_critic = Net(n_out).to(device)  # GPUへ\n",
    "global_brain = Brain_play(actor_critic)\n",
    "\n",
    "# 格納用変数の生成\n",
    "obs_shape = Env_play[0].observation_space.shape  # (3, 40, 12)\n",
    "#obs_shape = (obs_shape[0] * NUM_STACK_FRAME,\n",
    "#             *obs_shape[1:])  # (4, 84, 84)\n",
    "# 状態数は一個でやる。よって、current_obsはそのままの値を格納。\n",
    "\n",
    "# torch.Size([16, 3, 40, 12)\n",
    "current_obs = torch.zeros(NUM_PROCESSES, *obs_shape).to(device)\n",
    "rollouts = RolloutStorage(\n",
    "    NUM_ADVANCED_STEP, NUM_PROCESSES, obs_shape)  # rolloutsのオブジェクト\n",
    "episode_rewards = torch.zeros([NUM_PROCESSES, 1])  # 現在の試行の報酬を保持\n",
    "final_rewards = torch.zeros([NUM_PROCESSES, 1])  # 最後の試行の報酬和を保持\n",
    "\n",
    "# 初期状態の開始\n",
    "obs = resets(Env_play)\n",
    "obs = torch.from_numpy(obs).float()  # torch.Size([16, 3, 40, 12])\n",
    "current_obs = obs.to(device) # flameの4番目に最新のobsを格納\n",
    "\n",
    "# advanced学習用のオブジェクトrolloutsの状態の1つ目に、現在の状態を保存\n",
    "rollouts.observations[0].copy_(current_obs)\n",
    "\n",
    "frames = []\n",
    "frames_append = frames.append\n",
    "reward_save = []\n",
    "reward_save_append = reward_save.append\n",
    "main_end = False\n",
    "# 実行ループ\n",
    "\n",
    "for step in range(PLAY_STEP):\n",
    "\n",
    "    # 行動を求める\n",
    "    with torch.no_grad():\n",
    "        action = actor_critic.act(rollouts.observations[step])\n",
    "    \n",
    "    cpu_actions = action.squeeze(1).cpu().numpy()  # tensorをNumPyに\n",
    "    \n",
    "    # 1stepの並列実行、なお返り値のobsのsizeは(16, 1, 84, 84)\n",
    "    obs, reward, done, runOK = steps(Env_play, cpu_actions)\n",
    "    \n",
    "    frames_append(obs)\n",
    "    reward_save_append(reward)\n",
    "    \n",
    "    \n",
    "    # 報酬をtensorに変換し、試行の総報酬に足す\n",
    "    # sizeが(16,)になっているのを(16, 1)に変換\n",
    "    reward = np.expand_dims(np.stack(reward), 1)\n",
    "    reward = torch.from_numpy(reward).float()\n",
    "    episode_rewards += reward\n",
    "    \n",
    "    # 各実行環境それぞれについて、doneならmaskは0に、継続中ならmaskは1にする\n",
    "    masks = torch.FloatTensor(\n",
    "        [[0.0] if done_ or not runOK_ else [1.0] for done_, runOK_ in zip(done,runOK)])\n",
    "    # 最後の試行の総報酬を更新する\n",
    "    final_rewards *= masks  # 継続中の場合は1をかけ算してそのまま、done時には0を掛けてリセット\n",
    "    # 継続中は0を足す、done時にはepisode_rewardsを足す\n",
    "    final_rewards += (1 - masks) * episode_rewards\n",
    "    \n",
    "    \n",
    "    # 試行の総報酬を更新する\n",
    "    episode_rewards *= masks  # 継続中のmaskは1なのでそのまま、doneの場合は0に\n",
    "    \n",
    "    # masksをGPUへ\n",
    "    masks = masks.to(device)\n",
    "    \n",
    "    # 現在の状態をdone時には全部0にする\n",
    "    # maskのサイズをtorch.Size([16, 1])→torch.Size([16, 1, 1 ,1])へ変換して、かけ算\n",
    "    current_obs *= masks.unsqueeze(2).unsqueeze(2)\n",
    "    \n",
    "    # frameをstackする\n",
    "    # torch.Size([16, 1, 40, 12])\n",
    "    obs = torch.from_numpy(obs).float()\n",
    "    current_obs = obs.to(device)  # 最新のobsを格納\n",
    "    \n",
    "    # メモリオブジェクトに今stepのtransitionを挿入\n",
    "    rollouts.insert(current_obs, action.data, reward, masks)\n",
    "    \n",
    "# advancedのfor loop終了\n",
    "\n",
    "# advancedした最終stepの状態から予想する状態価値を計算\n",
    "#with torch.no_grad():\n",
    "#    next_value = actor_critic.get_value(\n",
    "#        rollouts.observations[-1]).detach()\n",
    "    \n",
    "    \n",
    "# 全stepの割引報酬和を計算して、rolloutsの変数returnsを更新\n",
    "#rollouts.compute_returns(next_value)\n",
    "\n",
    "\n",
    "# ネットワークとrolloutの更新\n",
    "#global_brain.update(rollouts)\n",
    "#rollouts.after_update()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Interrupted by the Keyboard\n",
      "Killing PID 29903\n",
      " Interrupted by the Keyboard\n",
      "Killing PID 29913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:49<00:00, 20.33it/s] \n"
     ]
    }
   ],
   "source": [
    "# Breakoutを実行する環境のクラス\n",
    "\n",
    "NUM_PROCESSES = 1\n",
    "\n",
    "\n",
    "\n",
    "# seedの設定\n",
    "seed_num = 1\n",
    "torch.manual_seed(seed_num)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "\n",
    "# 実行環境を構築\n",
    "torch.set_num_threads(seed_num)\n",
    "Envs = makecase(NUM_PROCESSES, stride=STRIDE, end=END,\n",
    "                xCells=XCELLS, insert_list = INSERT_LIST)\n",
    "\n",
    "# 全エージェントが共有して持つ頭脳Brainを生成\n",
    "n_out = Envs[0].action_space.shape[0]  # 行動の種類は4\n",
    "actor_critic = Net(n_out).to(device)  # GPUへ\n",
    "global_brain = Brain(actor_critic)\n",
    "\n",
    "# 格納用変数の生成\n",
    "obs_shape = Envs[0].observation_space.shape  # (3, 40, 12)\n",
    "#obs_shape = (obs_shape[0] * NUM_STACK_FRAME\n",
    "#             *obs_shape[1:])  # (4, 84, 84)\n",
    "# torch.Size([16, 4, 84, 84])\n",
    "current_obs = torch.zeros(NUM_PROCESSES, *obs_shape).to(device)\n",
    "rollouts = RolloutStorage(\n",
    "    NUM_ADVANCED_STEP, NUM_PROCESSES, obs_shape)  # rolloutsのオブジェクト\n",
    "episode_rewards = torch.zeros([NUM_PROCESSES, 1])  # 現在の試行の報酬を保持\n",
    "final_rewards = torch.zeros([NUM_PROCESSES, 1])  # 最後の試行の報酬和を保持\n",
    "\n",
    "# 初期状態の開始\n",
    "obs = resets(Envs)\n",
    "obs = torch.from_numpy(obs).float()  # torch.Size([16, 3, 40, 12])\n",
    "current_obs = obs.to(device)  # flameの4番目に最新のobsを格納\n",
    "\n",
    "# advanced学習用のオブジェクトrolloutsの状態の1つ目に、現在の状態を保存\n",
    "rollouts.observations[0].copy_(current_obs)\n",
    "\n",
    "# 描画用の環境（再生用に追加）\n",
    "env_play = make_playcase(stride=STRIDE, end=END,\n",
    "                xCells=XCELLS, insert_list = INSERT_LIST)\n",
    "obs_play = env_play.reset()\n",
    "\n",
    "# 動画にするために画像を格納する変数（再生用に追加）\n",
    "frames = []\n",
    "main_end = False\n",
    "\n",
    "# 実行ループ\n",
    "for j in tqdm(range(NUM_UPDATES)):\n",
    "\n",
    "    # 報酬が基準を超えたら終わりにする（再生用に追加）\n",
    "    if main_end:\n",
    "        break\n",
    "\n",
    "    # advanced学習するstep数ごとに計算\n",
    "    for step in range(NUM_ADVANCED_STEP):\n",
    "\n",
    "        # 行動を求める\n",
    "        with torch.no_grad():\n",
    "            action = actor_critic.act(rollouts.observations[step])\n",
    "\n",
    "        cpu_actions = action.squeeze(1).cpu().numpy()  # tensorをNumPyに\n",
    "\n",
    "        # 1stepの並列実行、なお返り値のobsのsizeは(16, 1, 84, 84)\n",
    "        obs, reward, done, runOK = steps(Envs, cpu_actions)\n",
    "\n",
    "        # 報酬をtensorに変換し、試行の総報酬に足す\n",
    "        # sizeが(16,)になっているのを(16, 1)に変換\n",
    "        reward = np.expand_dims(np.stack(reward), 1)\n",
    "        reward = torch.from_numpy(reward).float()\n",
    "        episode_rewards += reward\n",
    "\n",
    "        # 各実行環境それぞれについて、doneならmaskは0に、継続中ならmaskは1にする\n",
    "        masks = torch.FloatTensor(\n",
    "            [[0.0] if done_ or not runOK_ else [1.0] for done_, runOK_ in zip(done,runOK)])\n",
    "\n",
    "        # 最後の試行の総報酬を更新する\n",
    "        final_rewards *= masks  # 継続中の場合は1をかけ算してそのまま、done時には0を掛けてリセット\n",
    "        # 継続中は0を足す、done時にはepisode_rewardsを足す\n",
    "        final_rewards += (1 - masks) * episode_rewards\n",
    "\n",
    "        # 画像を取得する(再生用に追加）\n",
    "        obs_play, reward_play, done_play, runOK_play = env_play.step(cpu_actions[0])\n",
    "        frames.append(obs_play)  # 変換した画像を保存\n",
    "        #if done[0]:  # 並列環境の1つ目が終了した場合\n",
    "        #    print(episode_rewards[0][0].numpy())  # 報酬\n",
    "\n",
    "        #    # 報酬が300を超えたら終わりにする\n",
    "        #    if (episode_rewards[0][0].numpy()) > 300:\n",
    "        #        main_end = True\n",
    "        #        break\n",
    "        #    else:\n",
    "        #        obs_view = env_play.reset()\n",
    "        #        frames = []  # 保存した画像をリセット\n",
    "\n",
    "        # 試行の総報酬を更新する\n",
    "        episode_rewards *= masks  # 継続中のmaskは1なのでそのまま、doneの場合は0に\n",
    "\n",
    "        # masksをGPUへ\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        # 現在の状態をdone時には全部0にする\n",
    "        # maskのサイズをtorch.Size([16, 1])→torch.Size([16, 1, 1 ,1])へ変換して、かけ算\n",
    "        current_obs *= masks.unsqueeze(2).unsqueeze(2)\n",
    "\n",
    "        # frameをstackする\n",
    "        # torch.Size([16, 1, 84, 84])\n",
    "        obs = torch.from_numpy(obs).float()\n",
    "        current_obs = obs.to(device)  # 最新のobsを格納\n",
    "\n",
    "        # メモリオブジェクトに今stepのtransitionを挿入\n",
    "        rollouts.insert(current_obs, action.data, reward, masks)\n",
    "\n",
    "    # advancedのfor loop終了\n",
    "\n",
    "    # advancedした最終stepの状態から予想する状態価値を計算\n",
    "    with torch.no_grad():\n",
    "        next_value = actor_critic.get_value(\n",
    "            rollouts.observations[-1]).detach()\n",
    "\n",
    "    # 全stepの割引報酬和を計算して、rolloutsの変数returnsを更新\n",
    "    rollouts.compute_returns(next_value)\n",
    "\n",
    "    # ネットワークとrolloutの更新\n",
    "    # global_brain.update(rollouts)\n",
    "    rollouts.after_update()\n",
    "\n",
    "# 実行ループ終わり\n",
    "#display_frames_as_gif(frames)  # 動画の保存と再生\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakoutを実行する環境のクラス\n",
    "\n",
    "NUM_PROCESSES = 1\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    def run(self):\n",
    "\n",
    "        # seedの設定\n",
    "        seed_num = 1\n",
    "        torch.manual_seed(seed_num)\n",
    "        if use_cuda:\n",
    "            torch.cuda.manual_seed(seed_num)\n",
    "\n",
    "        # 実行環境を構築\n",
    "        torch.set_num_threads(seed_num)\n",
    "        envs = [make_env(ENV_NAME, seed_num, i) for i in range(NUM_PROCESSES)]\n",
    "        envs = SubprocVecEnv(envs)  # マルチプロセスの実行環境にする\n",
    "\n",
    "        # 全エージェントが共有して持つ頭脳Brainを生成\n",
    "        n_out = envs.action_space.n  # 行動の種類は4\n",
    "        actor_critic = Net(n_out).to(device)  # GPUへ\n",
    "        global_brain = Brain(actor_critic)\n",
    "\n",
    "        # 格納用変数の生成\n",
    "        obs_shape = envs.observation_space.shape  # (1, 84, 84)\n",
    "        obs_shape = (obs_shape[0] * NUM_STACK_FRAME,\n",
    "                     *obs_shape[1:])  # (4, 84, 84)\n",
    "        # torch.Size([16, 4, 84, 84])\n",
    "        current_obs = torch.zeros(NUM_PROCESSES, *obs_shape).to(device)\n",
    "        rollouts = RolloutStorage(\n",
    "            NUM_ADVANCED_STEP, NUM_PROCESSES, obs_shape)  # rolloutsのオブジェクト\n",
    "        episode_rewards = torch.zeros([NUM_PROCESSES, 1])  # 現在の試行の報酬を保持\n",
    "        final_rewards = torch.zeros([NUM_PROCESSES, 1])  # 最後の試行の報酬和を保持\n",
    "\n",
    "        # 初期状態の開始\n",
    "        obs = envs.reset()\n",
    "        obs = torch.from_numpy(obs).float()  # torch.Size([16, 1, 84, 84])\n",
    "        current_obs[:, -1:] = obs  # flameの4番目に最新のobsを格納\n",
    "\n",
    "        # advanced学習用のオブジェクトrolloutsの状態の1つ目に、現在の状態を保存\n",
    "        rollouts.observations[0].copy_(current_obs)\n",
    "\n",
    "        # 描画用の環境（再生用に追加）\n",
    "        env_play = make_env_play(ENV_NAME, seed_num, 0)\n",
    "        obs_play = env_play.reset()\n",
    "\n",
    "        # 動画にするために画像を格納する変数（再生用に追加）\n",
    "        frames = []\n",
    "        main_end = False\n",
    "\n",
    "        # 実行ループ\n",
    "        for j in tqdm(range(NUM_UPDATES)):\n",
    "\n",
    "            # 報酬が基準を超えたら終わりにする（再生用に追加）\n",
    "            if main_end:\n",
    "                break\n",
    "\n",
    "            # advanced学習するstep数ごとに計算\n",
    "            for step in range(NUM_ADVANCED_STEP):\n",
    "\n",
    "                # 行動を求める\n",
    "                with torch.no_grad():\n",
    "                    action = actor_critic.act(rollouts.observations[step])\n",
    "\n",
    "                cpu_actions = action.squeeze(1).cpu().numpy()  # tensorをNumPyに\n",
    "\n",
    "                # 1stepの並列実行、なお返り値のobsのsizeは(16, 1, 84, 84)\n",
    "                obs, reward, done, info = envs.step(cpu_actions)\n",
    "\n",
    "                # 報酬をtensorに変換し、試行の総報酬に足す\n",
    "                # sizeが(16,)になっているのを(16, 1)に変換\n",
    "                reward = np.expand_dims(np.stack(reward), 1)\n",
    "                reward = torch.from_numpy(reward).float()\n",
    "                episode_rewards += reward\n",
    "\n",
    "                # 各実行環境それぞれについて、doneならmaskは0に、継続中ならmaskは1にする\n",
    "                masks = torch.FloatTensor(\n",
    "                    [[0.0] if done_ else [1.0] for done_ in done])\n",
    "\n",
    "                # 最後の試行の総報酬を更新する\n",
    "                final_rewards *= masks  # 継続中の場合は1をかけ算してそのまま、done時には0を掛けてリセット\n",
    "                # 継続中は0を足す、done時にはepisode_rewardsを足す\n",
    "                final_rewards += (1 - masks) * episode_rewards\n",
    "\n",
    "                # 画像を取得する(再生用に追加）\n",
    "                obs_play, reward_play, _, _ = env_play.step(cpu_actions[0])\n",
    "                frames.append(obs_play)  # 変換した画像を保存\n",
    "                if done[0]:  # 並列環境の1つ目が終了した場合\n",
    "                    print(episode_rewards[0][0].numpy())  # 報酬\n",
    "\n",
    "                    # 報酬が300を超えたら終わりにする\n",
    "                    if (episode_rewards[0][0].numpy()) > 300:\n",
    "                        main_end = True\n",
    "                        break\n",
    "                    else:\n",
    "                        obs_view = env_play.reset()\n",
    "                        frames = []  # 保存した画像をリセット\n",
    "\n",
    "                # 試行の総報酬を更新する\n",
    "                episode_rewards *= masks  # 継続中のmaskは1なのでそのまま、doneの場合は0に\n",
    "\n",
    "                # masksをGPUへ\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                # 現在の状態をdone時には全部0にする\n",
    "                # maskのサイズをtorch.Size([16, 1])→torch.Size([16, 1, 1 ,1])へ変換して、かけ算\n",
    "                current_obs *= masks.unsqueeze(2).unsqueeze(2)\n",
    "\n",
    "                # frameをstackする\n",
    "                # torch.Size([16, 1, 84, 84])\n",
    "                obs = torch.from_numpy(obs).float()\n",
    "                current_obs[:, :-1] = current_obs[:, 1:]  # 0～2番目に1～3番目を上書き\n",
    "                current_obs[:, -1:] = obs  # 4番目に最新のobsを格納\n",
    "\n",
    "                # メモリオブジェクトに今stepのtransitionを挿入\n",
    "                rollouts.insert(current_obs, action.data, reward, masks)\n",
    "\n",
    "            # advancedのfor loop終了\n",
    "\n",
    "            # advancedした最終stepの状態から予想する状態価値を計算\n",
    "            with torch.no_grad():\n",
    "                next_value = actor_critic.get_value(\n",
    "                    rollouts.observations[-1]).detach()\n",
    "\n",
    "            # 全stepの割引報酬和を計算して、rolloutsの変数returnsを更新\n",
    "            rollouts.compute_returns(next_value)\n",
    "\n",
    "            # ネットワークとrolloutの更新\n",
    "            # global_brain.update(rollouts)\n",
    "            rollouts.after_update()\n",
    "\n",
    "        # 実行ループ終わり\n",
    "        display_frames_as_gif(frames)  # 動画の保存と再生\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net:\n\tsize mismatch for conv.0.weight: copying a param of torch.Size([32, 4, 8, 8]) from checkpoint, where the shape is torch.Size([32, 3, 5, 5]) in current model.\n\tsize mismatch for conv.2.weight: copying a param of torch.Size([64, 32, 4, 4]) from checkpoint, where the shape is torch.Size([64, 32, 2, 2]) in current model.\n\tsize mismatch for conv.4.weight: copying a param of torch.Size([64, 64, 3, 3]) from checkpoint, where the shape is torch.Size([64, 64, 2, 2]) in current model.\n\tsize mismatch for conv.7.weight: copying a param of torch.Size([512, 3136]) from checkpoint, where the shape is torch.Size([512, 2048]) in current model.\n\tsize mismatch for actor.weight: copying a param of torch.Size([4, 512]) from checkpoint, where the shape is torch.Size([27, 512]) in current model.\n\tsize mismatch for actor.bias: copying a param of torch.Size([4]) from checkpoint, where the shape is torch.Size([27]) in current model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-eebeb5338070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbreakout_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreakout_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-e8547d1e24f4>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m  \u001b[0;31m# 行動の種類は4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mactor_critic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# GPUへ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mglobal_brain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_critic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# 格納用変数の生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-21bd6cfe0f95>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, actor_critic)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#filename = 'weight_112500.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# パラメータ更新の勾配法の設定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 719\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Net:\n\tsize mismatch for conv.0.weight: copying a param of torch.Size([32, 4, 8, 8]) from checkpoint, where the shape is torch.Size([32, 3, 5, 5]) in current model.\n\tsize mismatch for conv.2.weight: copying a param of torch.Size([64, 32, 4, 4]) from checkpoint, where the shape is torch.Size([64, 32, 2, 2]) in current model.\n\tsize mismatch for conv.4.weight: copying a param of torch.Size([64, 64, 3, 3]) from checkpoint, where the shape is torch.Size([64, 64, 2, 2]) in current model.\n\tsize mismatch for conv.7.weight: copying a param of torch.Size([512, 3136]) from checkpoint, where the shape is torch.Size([512, 2048]) in current model.\n\tsize mismatch for actor.weight: copying a param of torch.Size([4, 512]) from checkpoint, where the shape is torch.Size([27, 512]) in current model.\n\tsize mismatch for actor.bias: copying a param of torch.Size([4]) from checkpoint, where the shape is torch.Size([27]) in current model."
     ]
    }
   ],
   "source": [
    "# 実行\n",
    "breakout_env = Environment()\n",
    "frames = breakout_env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行用の関数\n",
    "# 2o190509保存版\n",
    "\n",
    "NUM_PROCESSES = 1\n",
    "\n",
    "# 流体版\n",
    "\n",
    "# seedの設定\n",
    "seed_num = 1\n",
    "torch.manual_seed(seed_num)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "\n",
    "# 実行環境を構築\n",
    "torch.set_num_threads(seed_num)\n",
    "Env_play = makecase(NUM_PROCESSES, casename='play',stride=STRIDE, end=END,\n",
    "                xCells=XCELLS, insert_list = INSERT_LIST)\n",
    "\n",
    "# 全エージェントが共有して持つ頭脳Brainを生成\n",
    "n_out = Env_play[0].action_space.shape[0]  # 行動の種類は27\n",
    "actor_critic = Net(n_out).to(device)  # GPUへ\n",
    "global_brain = Brain_play(actor_critic)\n",
    "\n",
    "# 格納用変数の生成\n",
    "obs_shape = Env_play[0].observation_space.shape  # (3, 40, 12)\n",
    "#obs_shape = (obs_shape[0] * NUM_STACK_FRAME,\n",
    "#             *obs_shape[1:])  # (4, 84, 84)\n",
    "# 状態数は一個でやる。よって、current_obsはそのままの値を格納。\n",
    "\n",
    "# torch.Size([16, 3, 40, 12)\n",
    "current_obs = torch.zeros(NUM_PROCESSES, *obs_shape).to(device)\n",
    "rollouts = RolloutStorage(\n",
    "    NUM_ADVANCED_STEP, NUM_PROCESSES, obs_shape)  # rolloutsのオブジェクト\n",
    "episode_rewards = torch.zeros([NUM_PROCESSES, 1])  # 現在の試行の報酬を保持\n",
    "final_rewards = torch.zeros([NUM_PROCESSES, 1])  # 最後の試行の報酬和を保持\n",
    "\n",
    "# 初期状態の開始\n",
    "obs = resets(Env_play)\n",
    "obs = torch.from_numpy(obs).float()  # torch.Size([16, 3, 40, 12])\n",
    "current_obs = obs.to(device) # flameの4番目に最新のobsを格納\n",
    "\n",
    "# advanced学習用のオブジェクトrolloutsの状態の1つ目に、現在の状態を保存\n",
    "rollouts.observations[0].copy_(current_obs)\n",
    "\n",
    "frames = []\n",
    "main_end = False\n",
    "# 実行ループ\n",
    "for j in tqdm(range(NUM_UPDATES)):\n",
    "    # advanced学習するstep数ごとに計算\n",
    "    if main_end:\n",
    "        break\n",
    "        \n",
    "    for step in range(NUM_ADVANCED_STEP):\n",
    "\n",
    "        # 行動を求める\n",
    "        with torch.no_grad():\n",
    "            action = actor_critic.act(rollouts.observations[step])\n",
    "        \n",
    "        cpu_actions = action.squeeze(1).cpu().numpy()  # tensorをNumPyに\n",
    "        \n",
    "        # 1stepの並列実行、なお返り値のobsのsizeは(16, 1, 84, 84)\n",
    "        obs, reward, done, runOK = steps(Env_play, cpu_actions)\n",
    "        \n",
    "        frames.append(obs)\n",
    "        \n",
    "        if done or not runOK:\n",
    "            main_end = True\n",
    "        # 報酬をtensorに変換し、試行の総報酬に足す\n",
    "        # sizeが(16,)になっているのを(16, 1)に変換\n",
    "        reward = np.expand_dims(np.stack(reward), 1)\n",
    "        reward = torch.from_numpy(reward).float()\n",
    "        episode_rewards += reward\n",
    "        \n",
    "        # 各実行環境それぞれについて、doneならmaskは0に、継続中ならmaskは1にする\n",
    "        masks = torch.FloatTensor(\n",
    "            [[0.0] if done_ or not runOK_ else [1.0] for done_, runOK_ in zip(done,runOK)])\n",
    "        # 最後の試行の総報酬を更新する\n",
    "        final_rewards *= masks  # 継続中の場合は1をかけ算してそのまま、done時には0を掛けてリセット\n",
    "        # 継続中は0を足す、done時にはepisode_rewardsを足す\n",
    "        final_rewards += (1 - masks) * episode_rewards\n",
    "        \n",
    "        \n",
    "        # 試行の総報酬を更新する\n",
    "        episode_rewards *= masks  # 継続中のmaskは1なのでそのまま、doneの場合は0に\n",
    "        \n",
    "        # masksをGPUへ\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # 現在の状態をdone時には全部0にする\n",
    "        # maskのサイズをtorch.Size([16, 1])→torch.Size([16, 1, 1 ,1])へ変換して、かけ算\n",
    "        current_obs *= masks.unsqueeze(2).unsqueeze(2)\n",
    "        \n",
    "        # frameをstackする\n",
    "        # torch.Size([16, 1, 40, 12])\n",
    "        obs = torch.from_numpy(obs).float()\n",
    "        current_obs = obs.to(device)  # 最新のobsを格納\n",
    "        \n",
    "        # メモリオブジェクトに今stepのtransitionを挿入\n",
    "        rollouts.insert(current_obs, action.data, reward, masks)\n",
    "        \n",
    "    # advancedのfor loop終了\n",
    "\n",
    "    # advancedした最終stepの状態から予想する状態価値を計算\n",
    "    with torch.no_grad():\n",
    "        next_value = actor_critic.get_value(\n",
    "            rollouts.observations[-1]).detach()\n",
    "        \n",
    "        \n",
    "    # 全stepの割引報酬和を計算して、rolloutsの変数returnsを更新\n",
    "    rollouts.compute_returns(next_value)\n",
    "    \n",
    "    \n",
    "    # ネットワークとrolloutの更新\n",
    "    global_brain.update(rollouts)\n",
    "    rollouts.after_update()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
