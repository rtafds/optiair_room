{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leinforcement pyform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.spaces.box import Box\n",
    "\n",
    "import os\n",
    "import PyFoam\n",
    "import PyFoam.FoamInformation\n",
    "from PyFoam.RunDictionary.SolutionDirectory import SolutionDirectory\n",
    "from PyFoam.RunDictionary.ParsedParameterFile import ParsedParameterFile\n",
    "from PyFoam.Basics.DataStructures import Vector\n",
    "from PyFoam.Execution.BasicRunner import BasicRunner\n",
    "from PyFoam.Basics.TemplateFile import TemplateFile\n",
    "import shlex,sys,json\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyFOAM基本コマンド "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory\n",
    "CASE = SolutionDirectory(\"../aircond2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"./Allclean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('./Makemesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenFOAMのコマンドを実行\n",
    "args=shlex.split(\"buoyantBoussinesqPimpleFoam -case \" + CASE.name)\n",
    "buoyant=BasicRunner(args,silent=True)\n",
    "summary=buoyant.start()\n",
    "buoyant.runOK()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下、棒倒しのDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動画の描画関数の宣言\n",
    "# 参考URL http://nbviewer.jupyter.org/github/patrickmineault\n",
    "# /xcorr-notebooks/blob/master/Render%20OpenAI%20gym%20as%20GIF.ipynb\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(frames[0].shape[1]/72.0, frames[0].shape[0]/72.0),\n",
    "               dpi=72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames),\n",
    "                                   interval=50)\n",
    "\n",
    "    anim.save('movie_cartpole_DQN.mp4')  # 動画のファイル名と保存です\n",
    "    display(display_animation(anim, default_mode='loop'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr(name_a='名前Aです', value_b=100)\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# 本コードでは、namedtupleを使用します。\n",
    "# namedtupleを使うことで、値をフィールド名とペアで格納できます。\n",
    "# すると値に対して、フィールド名でアクセスできて便利です。\n",
    "# https://docs.python.jp/3/library/collections.html#collections.namedtuple\n",
    "# 以下は使用例です\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Tr = namedtuple('tr', ('name_a', 'value_b'))\n",
    "Tr_object = Tr('名前Aです', 100)\n",
    "\n",
    "print(Tr_object)  # 出力：tr(name_a='名前Aです', value_b=100)\n",
    "print(Tr_object.value_b)  # 出力：100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# namedtupleを生成\n",
    "from collections import namedtuple\n",
    "\n",
    "Transition = namedtuple(\n",
    "    'Transition', ('state', 'action', 'next_state', 'reward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定数の設定\n",
    "ENV = 'CartPole-v0'  # 使用する課題名\n",
    "GAMMA = 0.99  # 時間割引率\n",
    "MAX_STEPS = 200  # 1試行のstep数\n",
    "NUM_EPISODES = 500  # 最大試行回数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 経験を保存するメモリクラスを定義します\n",
    "\n",
    "\n",
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, CAPACITY):\n",
    "        self.capacity = CAPACITY  # メモリの最大長さ\n",
    "        self.memory = []  # 経験を保存する変数\n",
    "        self.index = 0  # 保存するindexを示す変数\n",
    "\n",
    "    def push(self, state, action, state_next, reward):\n",
    "        '''transition = (state, action, state_next, reward)をメモリに保存する'''\n",
    "\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)  # メモリが満タンでないときは足す\n",
    "\n",
    "        # namedtupleのTransitionを使用し、値とフィールド名をペアにして保存します\n",
    "        self.memory[self.index] = Transition(state, action, state_next, reward)\n",
    "\n",
    "        self.index = (self.index + 1) % self.capacity  # 保存するindexを1つずらす\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        '''batch_size分だけ、ランダムに保存内容を取り出す'''\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        '''関数lenに対して、現在の変数memoryの長さを返す'''\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エージェントが持つ脳となるクラスです、DQNを実行します\n",
    "# Q関数をディープラーニングのネットワークをクラスとして定義\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "CAPACITY = 10000\n",
    "\n",
    "\n",
    "class Brain:\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        self.num_actions = num_actions  # CartPoleの行動（右に左に押す）の2を取得\n",
    "\n",
    "        # 経験を記憶するメモリオブジェクトを生成\n",
    "        self.memory = ReplayMemory(CAPACITY)\n",
    "\n",
    "        # ニューラルネットワークを構築\n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module('fc1', nn.Linear(num_states, 32))\n",
    "        self.model.add_module('relu1', nn.ReLU())\n",
    "        self.model.add_module('fc2', nn.Linear(32, 32))\n",
    "        self.model.add_module('relu2', nn.ReLU())\n",
    "        self.model.add_module('fc3', nn.Linear(32, num_actions))\n",
    "\n",
    "        print(self.model)  # ネットワークの形を出力\n",
    "\n",
    "        # 最適化手法の設定\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
    "\n",
    "    def replay(self):\n",
    "        '''Experience Replayでネットワークの結合パラメータを学習'''\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 1. メモリサイズの確認\n",
    "        # -----------------------------------------\n",
    "        # 1.1 メモリサイズがミニバッチより小さい間は何もしない\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 2. ミニバッチの作成\n",
    "        # -----------------------------------------\n",
    "        # 2.1 メモリからミニバッチ分のデータを取り出す\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "        # 2.2 各変数をミニバッチに対応する形に変形\n",
    "        # transitionsは1stepごとの(state, action, state_next, reward)が、BATCH_SIZE分格納されている\n",
    "        # つまり、(state, action, state_next, reward)×BATCH_SIZE\n",
    "        # これをミニバッチにしたい。つまり\n",
    "        # (state×BATCH_SIZE, action×BATCH_SIZE, state_next×BATCH_SIZE, reward×BATCH_SIZE)にする\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        # 2.3 各変数の要素をミニバッチに対応する形に変形し、ネットワークで扱えるようVariableにする\n",
    "        # 例えばstateの場合、[torch.FloatTensor of size 1x4]がBATCH_SIZE分並んでいるのですが、\n",
    "        # それを torch.FloatTensor of size BATCH_SIZEx4 に変換します\n",
    "        # 状態、行動、報酬、non_finalの状態のミニバッチのVariableを作成\n",
    "        # catはConcatenates（結合）のことです。\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                           if s is not None])\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 3. 教師信号となるQ(s_t, a_t)値を求める\n",
    "        # -----------------------------------------\n",
    "        # 3.1 ネットワークを推論モードに切り替える\n",
    "        self.model.eval()\n",
    "\n",
    "        # 3.2 ネットワークが出力したQ(s_t, a_t)を求める\n",
    "        # self.model(state_batch)は、右左の両方のQ値を出力しており\n",
    "        # [torch.FloatTensor of size BATCH_SIZEx2]になっている。\n",
    "        # ここから実行したアクションa_tに対応するQ値を求めるため、action_batchで行った行動a_tが右か左かのindexを求め\n",
    "        # それに対応するQ値をgatherでひっぱり出す。\n",
    "        state_action_values = self.model(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # 3.3 max{Q(s_t+1, a)}値を求める。ただし次の状態があるかに注意。\n",
    "\n",
    "        # cartpoleがdoneになっておらず、next_stateがあるかをチェックするインデックスマスクを作成\n",
    "        non_final_mask = torch.ByteTensor(tuple(map(lambda s: s is not None,\n",
    "                                                    batch.next_state)))\n",
    "        # まずは全部0にしておく\n",
    "        next_state_values = torch.zeros(BATCH_SIZE)\n",
    "\n",
    "        # 次の状態があるindexの最大Q値を求める\n",
    "        # 出力にアクセスし、max(1)で列方向の最大値の[値、index]を求めます\n",
    "        # そしてそのQ値（index=0）を出力します\n",
    "        # detachでその値を取り出します\n",
    "        next_state_values[non_final_mask] = self.model(\n",
    "            non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "        # 3.4 教師となるQ(s_t, a_t)値を、Q学習の式から求める\n",
    "        expected_state_action_values = reward_batch + GAMMA * next_state_values\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 4. 結合パラメータの更新\n",
    "        # -----------------------------------------\n",
    "        # 4.1 ネットワークを訓練モードに切り替える\n",
    "        self.model.train()\n",
    "\n",
    "        # 4.2 損失関数を計算する（smooth_l1_lossはHuberloss）\n",
    "        # expected_state_action_valuesは\n",
    "        # sizeが[minbatch]になっているので、unsqueezeで[minibatch x 1]へ\n",
    "        loss = F.smooth_l1_loss(state_action_values,\n",
    "                                expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # 4.3 結合パラメータを更新する\n",
    "        self.optimizer.zero_grad()  # 勾配をリセット\n",
    "        loss.backward()  # バックプロパゲーションを計算\n",
    "        self.optimizer.step()  # 結合パラメータを更新\n",
    "\n",
    "    def decide_action(self, state, episode):\n",
    "        '''現在の状態に応じて、行動を決定する'''\n",
    "        # ε-greedy法で徐々に最適行動のみを採用する\n",
    "        epsilon = 0.5 * (1 / (episode + 1))\n",
    "\n",
    "        if epsilon <= np.random.uniform(0, 1):\n",
    "            self.model.eval()  # ネットワークを推論モードに切り替える\n",
    "            with torch.no_grad():\n",
    "                action = self.model(state).max(1)[1].view(1, 1)\n",
    "            # ネットワークの出力の最大値のindexを取り出します = max(1)[1]\n",
    "            # .view(1,1)は[torch.LongTensor of size 1]　を size 1x1 に変換します\n",
    "\n",
    "        else:\n",
    "            # 0,1の行動をランダムに返す\n",
    "            action = torch.LongTensor(\n",
    "                [[random.randrange(self.num_actions)]])  # 0,1の行動をランダムに返す\n",
    "            # actionは[torch.LongTensor of size 1x1]の形になります\n",
    "\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CartPoleで動くエージェントクラスです、棒付き台車そのものになります\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        '''課題の状態と行動の数を設定する'''\n",
    "        self.brain = Brain(num_states, num_actions)  # エージェントが行動を決定するための頭脳を生成\n",
    "\n",
    "    def update_q_function(self):\n",
    "        '''Q関数を更新する'''\n",
    "        self.brain.replay()\n",
    "\n",
    "    def get_action(self, state, episode):\n",
    "        '''行動を決定する'''\n",
    "        action = self.brain.decide_action(state, episode)\n",
    "        return action\n",
    "\n",
    "    def memorize(self, state, action, state_next, reward):\n",
    "        '''memoryオブジェクトに、state, action, state_next, rewardの内容を保存する'''\n",
    "        self.brain.memory.push(state, action, state_next, reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set action variable\n",
    "# set 9 parameter\n",
    "\n",
    "# speed is 0.1 0.3 0.5\n",
    "# direction is -/8pi, -2/8pi, -3/8pi\n",
    "# temperture is 18, 22, 26\n",
    "SPEED = np.array([0.1,0.3,0.5])\n",
    "DIRECTION = np.array([-1*np.pi/8, -2*np.pi/8,-3*np.pi/8])\n",
    "TEMPERTURE = np.array([18,22,26])\n",
    "#Ux = SPEED*np.cos(DIRECTION)\n",
    "#Uy = SPEED*np.sin(DIRECTION)\n",
    "#Ux**2+Uy**2  # check calculation\n",
    "#U = np.array([Ux,Uy,np.zeros(3)])\n",
    "#U = U.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Action_space= np.empty((0,3),float)\n",
    "for i in range(len(SPEED)):\n",
    "    for j in range(len(DIRECTION)):\n",
    "        for k in range(len(TEMPERTURE)):\n",
    "            Ux = SPEED[i]*np.cos(DIRECTION[j])\n",
    "            Uy = SPEED[i]*np.sin(DIRECTION[j])\n",
    "            Act = np.array([[Ux,Uy,TEMPERTURE[k]]])\n",
    "            Action_space = np.append(Action_space,Act,axis=0)\n",
    "            \n",
    "Action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_initial = np.array(ParsedParameterFile(CASE.initialDir() + '/U').content['internalField'])\n",
    "U_latest = np.array(ParsedParameterFile(CASE.latestDir() + '/U').content['internalField'])\n",
    "T_initial = np.array(ParsedParameterFile(CASE.initialDir() + '/T').content['internalField'])\n",
    "T_latest = np.array(ParsedParameterFile(CASE.latestDir() + '/T').content['internalField'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('uniform (0 0 0)', dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_initial.ndim  # 条件判定に使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uniform (0 0 0)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_value = str(U_initial.all())\n",
    "U_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = U_value[8:].strip('()').split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(list(map(int,U)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(a,(nCells,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_value = str(T_initial.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = T_value[8:].strip('()').split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(list(map(int,T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(map(int,T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 1)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(b,(nCells,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_latest_xy = np.delete(U_latest, axis=1, obj=2)\n",
    "T_latest_x = np.reshape(T_latest, [-1,1], order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation = np.concatenate([U_latest_xy, T_latest_x],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.38276e+02,  2.30520e+02,  5.29759e+08],\n",
       "       [-1.13413e+03,  2.09840e+02,  5.35350e+08],\n",
       "       [-1.83527e+03,  1.45144e+02,  5.38410e+08],\n",
       "       ...,\n",
       "       [-1.56512e+03,  2.28173e+03,  5.88494e+08],\n",
       "       [-1.17065e+03,  1.92441e+03,  5.81617e+08],\n",
       "       [-1.62755e+03,  1.85961e+03,  5.86958e+08]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test:\n",
    "    def __init__(self,a,b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def a_plus_b(self):\n",
    "        return self.a+self.b\n",
    "    def aaa(self):\n",
    "        self.c = self.a + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "initialDir = Path(CASE.initialDir())\n",
    "ini = list(initialDir.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/constant/transportProperties'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/constant/polyMesh'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/constant/turbulenceProperties'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/constant/g')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = Path(CASE.name + \"/constant\")\n",
    "system = Path(CASE.name + \"/system\")\n",
    "list(constant.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(system.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ParsedParameterFile(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blockMeshDict'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intialDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/epsilon'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/k'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/alphat'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/polyMesh'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/T.orig'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/T'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/p'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/U'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/nut'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/p_rgh')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyFoamで最適条件を探す用\n",
    "\n",
    "class pyfoamtest:\n",
    "    \n",
    "    def __init__(self,CASE):\n",
    "        \n",
    "        self.CASE = CASE\n",
    "        \n",
    "        # get nCells\n",
    "        with open (self.CASE.name + '/constant/polyMesh/neighbour') as f:\n",
    "            neighbour = f.read()\n",
    "        nCells_index = neighbour.find('nCells')\n",
    "        nCells_ = neighbour[nCells_index : nCells_index+15]\n",
    "        nCells = int(re.sub(r'\\D', '', nCells_))\n",
    "        self.nCells = nCells\n",
    "        \n",
    "        # 各辞書ファイルの取得\n",
    "        self.initialDir = self.CASE.initialDir()+'/'\n",
    "        self.constant = self.CASE.name + \"/constant/\"\n",
    "        self.system = self.CASE.name + \"/system/\"\n",
    "        self.initialDir_file = []\n",
    "        for x in os.listdir(self.initialDir):\n",
    "            if os.path.isfile(self.initialDir + x):\n",
    "                self.initialDir_file.append(x)\n",
    "        self.constant_file = []\n",
    "        for y in os.listdir(self.constant):\n",
    "            if os.path.isfile(self.constant + y):\n",
    "                self.constant_file.append(y)\n",
    "        self.system_file = []\n",
    "        for z in os.listdir(self.system):\n",
    "            if os.path.isfile(self.system + z):\n",
    "                self.system_file.append(z)\n",
    "        \n",
    "        # 各辞書ファイルをそれぞれのファイル名で保存\n",
    "        for i in range(len(self.initialDir_file)):\n",
    "            self.__dict__[self.initialDir_file[i]] = ParsedParameterFile(self.initialDir + self.initialDir_file[i])\n",
    "        for i in range(len(self.system_file)):\n",
    "            self.__dict__[self.system_file[i]] = ParsedParameterFile(self.system + self.system_file[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pyfoamtest(CASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blockMeshDict',\n",
       " 'fvSolution',\n",
       " 'blockMeshDict_save1',\n",
       " 'createPatchDict',\n",
       " 'refineMeshDict',\n",
       " 'controlDict',\n",
       " 'setFieldsDict',\n",
       " 'fvSchemes']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.system_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solvers': {'p_rgh': {'solver': 'PCG',\n",
       "   'preconditioner': 'DIC',\n",
       "   'tolerance': 1e-08,\n",
       "   'relTol': 0.01},\n",
       "  'p_rghFinal': {'$p_rgh': '', 'relTol': 0}},\n",
       " 'PIMPLE': {'momentumPredictor': no,\n",
       "  'nOuterCorrectors': 1,\n",
       "  'nCorrectors': 2,\n",
       "  'nNonOrthogonalCorrectors': 0,\n",
       "  'pRefCell': 0,\n",
       "  'pRefValue': 0},\n",
       " 'relaxationFactors': {'equations': {}}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.fvSolution.getValueDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimensions': '[ 0 2 -3 0 0 0 0 ]',\n",
       " 'internalField': 'uniform 0.01',\n",
       " 'boundaryField': {'floor': {'type': 'epsilonWallFunction',\n",
       "   'value': 'uniform 0.01'},\n",
       "  'ceiling': {'type': 'epsilonWallFunction', 'value': 'uniform 0.01'},\n",
       "  'fixedWalls': {'type': 'epsilonWallFunction', 'value': 'uniform 0.01'},\n",
       "  'sideWalls': {'type': 'empty'},\n",
       "  'outlet': {'type': 'zeroGradient'},\n",
       "  'inlet': {'type': 'fixedValue', 'value': 'uniform 0.00082175'}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.epsilon.getValueDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimensions': '[ 0 2 -3 0 0 0 0 ]',\n",
       " 'internalField': 'uniform 0.01',\n",
       " 'boundaryField': {'floor': {'type': 'epsilonWallFunction',\n",
       "   'value': 'uniform 0.01'},\n",
       "  'ceiling': {'type': 'epsilonWallFunction', 'value': 'uniform 0.01'},\n",
       "  'fixedWalls': {'type': 'epsilonWallFunction', 'value': 'uniform 0.01'},\n",
       "  'sideWalls': {'type': 'empty'},\n",
       "  'outlet': {'type': 'zeroGradient'},\n",
       "  'inlet': {'type': 'fixedValue', 'value': 'uniform 0.00082175'}}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.p_rgh.getValueDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/epsilon'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/k'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/alphat'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/polyMesh'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/T.orig'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/T'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/p'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/U'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/nut'),\n",
       " PosixPath('/home/mmt3264/OpenFOAM/mmt3264-6/run/aircond2/0/p_rgh')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.initialDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この環境の部分を変える\n",
    "import copy\n",
    "from box import Box\n",
    "\n",
    "class Aircond:\n",
    "    '''Aircondのクラス'''\n",
    "    def __init__(self,CASE):\n",
    "        self.CASE = CASE\n",
    "        \n",
    "        # get nCells\n",
    "        with open (self.CASE.name + '/constant/polyMesh/neighbour') as f:\n",
    "            neighbour = f.read()\n",
    "        nCells_index = neighbour.find('nCells')\n",
    "        nCells_ = neighbour[nCells_index : nCells_index+15]\n",
    "        nCells = int(re.sub(r'\\D', '', nCells_))\n",
    "        self.nCells = nCells\n",
    "        \n",
    "        self.action_SPEED = np.array([0.1,0.3,0.5])\n",
    "        self.action_DIRECTION = np.array([-1*np.pi/8, -2*np.pi/8,-3*np.pi/8])\n",
    "        self.action_TEMPERTURE = np.array([18,22,26])\n",
    "        self.action_space = np.tile(np.array([0,0,0]),(27,1))\n",
    "        self.observation_space = np.tile(np.array([0,0,0]),(self.nCells,1))\n",
    "        self.stride = 1200\n",
    "        self.startTime = 0  # startTimeの初期化\n",
    "        self.endTime = 1200  # 初期化\n",
    "        self.end = 20000\n",
    "        \n",
    "        \n",
    "        # 各辞書ファイルの取得\n",
    "        self.initialDir = self.CASE.initialDir()+'/'\n",
    "        self.constant = self.CASE.name + \"/constant/\"\n",
    "        self.system = self.CASE.name + \"/system/\"\n",
    "        self.initialDir_file = []\n",
    "        for x in os.listdir(self.initialDir):\n",
    "            if os.path.isfile(self.initialDir + x):\n",
    "                self.initialDir_file.append(x)\n",
    "        self.constant_file = []\n",
    "        for y in os.listdir(self.constant):\n",
    "            if os.path.isfile(self.constant + y):\n",
    "                self.constant_file.append(y)\n",
    "        self.system_file = []\n",
    "        for z in os.listdir(self.system):\n",
    "            if os.path.isfile(self.system + z):\n",
    "                self.system_file.append(z)\n",
    "        \n",
    "        # 各辞書ファイルをそれぞれのファイル名で保存\n",
    "        for i in range(len(self.initialDir_file)):\n",
    "            self.__dict__[self.initialDir_file[i]] = ParsedParameterFile(self.initialDir + self.initialDir_file[i])\n",
    "\n",
    "        for i in range(len(self.system_file)):\n",
    "            self.__dict__[self.system_file[i]] = ParsedParameterFile(self.system + self.system_file[i])\n",
    "            \n",
    "    def initial_to_array(self, Parsed):\n",
    "        '''uniformをnp.arrayに変換'''\n",
    "        if Parsed.ndim==0:\n",
    "            Parsed_raw = str(Parsed.all())\n",
    "            Parsed_str = Parsed_raw[8:].strip('()').split(' ')\n",
    "            Parsed_int = np.array(list(map(int,Parsed_str)))\n",
    "            Parsed = np.tile(Parsed_int,(self.nCells,1))\n",
    "        return Parsed\n",
    "\n",
    "    def make_observation(self,Dir):\n",
    "        '''Dirのpathのobservationを取得'''\n",
    "        U_value = np.array(ParsedParameterFile(Dir + '/U').content['internalField'])\n",
    "        T_value = np.array(ParsedParameterFile(Dir + '/T').content['internalField'])\n",
    "        if U_value.ndim == 0:\n",
    "            U_value = self.initial_to_array(U_value)\n",
    "            T_value = self.initial_to_array(T_value)\n",
    "        U_value_xy = np.delete(U_value, axis=1, obj=2)\n",
    "        T_value_x = np.reshape(T_value, [-1,1], order='F')\n",
    "        Observation = np.concatenate([U_value_xy, T_value_x],axis=1)\n",
    "        return Observation    \n",
    "    \n",
    "    def make_action(self):\n",
    "        '''actionの設定'''\n",
    "        Action = np.empty((0,3),float)\n",
    "        for i in range(len(self.action_SPEED)):\n",
    "            for j in range(len(self.action_DIRECTION)):\n",
    "                for k in range(len(self.action_TEMPERTURE)):\n",
    "                    Ux = self.action_SPEED[i]*np.cos(self.action_DIRECTION[j])\n",
    "                    Uy = self.action_SPEED[i]*np.sin(self.action_DIRECTION[j])\n",
    "                    Act = np.array([[Ux,Uy,self.action_TEMPERTURE[k]]])\n",
    "                    Action = np.append(Action,Act,axis=0)\n",
    "                    \n",
    "        return Action\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        '''環境のリセット'''\n",
    "        \n",
    "        # reset control Dict\n",
    "        clDict = ParsedParameterFile(self.CASE.controlDict())\n",
    "        clDict['startTime'] = 0\n",
    "        clDict['endTime'] = self.stride\n",
    "        clDict['deltaT'] = 1\n",
    "        clDict['writeInterval'] = 400\n",
    "        clDict.writeFile()\n",
    "        self.startTime = clDict['startTime']\n",
    "        self.endTime = clDict['endTime']\n",
    "        \n",
    "        os.system('./Allclean')\n",
    "        os.system('./Makemesh')\n",
    "        \n",
    "        # 初期条件の設定（ランダム）\n",
    "        T_initial = ParsedParameterFile(self.CASE.initialDir() + '/T')\n",
    "        #  random parameter from 26 to 35\n",
    "        T_rand = np.random.randint(26+273,35+273)\n",
    "        T_initial['internalField'].setUniform(T_rand)\n",
    "        T_initial.writeFile()\n",
    "        \n",
    "        \n",
    "        # set action and observation\n",
    "        self.action_space= self.make_action()\n",
    "        self.observation = self.make_observation(self.CASE.initialDir())\n",
    "        return self.observation\n",
    "    \n",
    "    def step(self, action):\n",
    "        '''ステップを進める'''\n",
    "        \n",
    "        clDict = ParsedParameterFile(self.CASE.controlDict())      \n",
    "        if clDict['endTime'] == self.end:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "            \n",
    "            # actionに従った、境界条件を設定\n",
    "            # action is 0~26\n",
    "            U_latest = ParsedParameterFile(self.CASE.latestDir() + '/U')\n",
    "            T_latest = ParsedParameterFile(self.CASE.latestDir() + '/T')\n",
    "            self.act = self.action_space[action]\n",
    "            U_latest['boundaryField']['inlet']['value'].setUniform(Vector(self.act[0],self.act[1],0))\n",
    "            U_latest.writeFile()\n",
    "            T_latest['boundaryField']['inlet']['value'].setUniform(self.act[2])\n",
    "            T_latest.writeFile()\n",
    "            \n",
    "            # OpenFOAMのコマンドを実行\n",
    "            args=shlex.split(\"buoyantBoussinesqPimpleFoam -case \" + self.CASE.name)\n",
    "            buoyant=BasicRunner(args,silent=True)\n",
    "            self.summary=buoyant.start()\n",
    "            runOK = buoyant.runOK()\n",
    "            \n",
    "            #os.system(\"buoyantBoussinesqPimpleFoam\")\n",
    "            \n",
    "            # clDictのコントロール\n",
    "            #clDict = ParsedParameterFile(self.CASE.controlDict())\n",
    "            #clDict['startTime'] = self.startTime + self.stride\n",
    "            #clDict['endTime'] = self.endTime + self.stride\n",
    "            #clDict['deltaT'] = 1\n",
    "            #clDict['writeInterval'] = 400\n",
    "            #clDict.writeFile()\n",
    "            \n",
    "            self.startTime = clDict['startTime']\n",
    "            self.endTime = clDict['endTime']\n",
    "            \n",
    "            self.observation = self.make_observation(self.CASE.latestDir())\n",
    "            \n",
    "        return (self.observation, done, runOK)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Aircond(CASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0, 303],\n",
       "       [  0,   0, 303],\n",
       "       [  0,   0, 303],\n",
       "       ...,\n",
       "       [  0,   0, 303],\n",
       "       [  0,   0, 303],\n",
       "       [  0,   0, 303]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-5.22058e+11, -7.43962e+11,  2.99331e+02],\n",
       "        [ 4.78941e+11,  7.77786e+11,  2.99332e+02],\n",
       "        [-5.56393e+11, -7.61285e+11,  2.99334e+02],\n",
       "        ...,\n",
       "        [-3.79360e+11, -6.75051e+11,  2.99341e+02],\n",
       "        [ 4.45513e+11,  6.60686e+11,  2.99341e+02],\n",
       "        [-4.03820e+11, -6.77333e+11,  2.99341e+02]]), False, True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.step(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8400"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "act = a.action[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19134172, -0.46193977])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vector(0.2,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control Dict\n",
    "clDict = ParsedParameterFile(CASE.controlDict())\n",
    "clDict['startTime'] = 0\n",
    "clDict['endTime'] = 1200\n",
    "clDict['deltaT'] = 2\n",
    "clDict['writeInterval'] = 200\n",
    "clDict.writeFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenFOAMのコマンドを実行\n",
    "args=shlex.split(\"buoyantBoussinesqPimpleFoam -case \" + CASE.name)\n",
    "buoyant=BasicRunner(args,silent=True)\n",
    "summary=buoyant.start()\n",
    "buoyant.runOK()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clDict['startTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "clDict['startTime'] = 1200\n",
    "clDict['endTime'] = 2400\n",
    "clDict['deltaT'] = 2\n",
    "clDict['writeInterval'] = 200\n",
    "clDict.writeFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.6860966e-01, 1.4645028e+38, 8.6090848e-02, 3.0545910e+37],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gym analysis\n",
    "env = gym.make(ENV)\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03366172,  0.03967458, -0.01574906,  0.01677343])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00977381, -0.04072757, -0.01555263, -0.0265637 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action = agent.get_action(observation, episode)\n",
    "observation_next,reward,done,info = env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(env.step(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CartPoleを実行する環境のクラスです\n",
    "\n",
    "\n",
    "class Environment:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(ENV)  # 実行する課題を設定\n",
    "        num_states = self.env.observation_space.shape[0]  # 課題の状態数4を取得\n",
    "        num_actions = self.env.action_space.n  # CartPoleの行動（右に左に押す）の2を取得\n",
    "        self.agent = Agent(num_states, num_actions)  # 環境内で行動するAgentを生成\n",
    "\n",
    "        \n",
    "    def run(self):\n",
    "        '''実行'''\n",
    "        episode_10_list = np.zeros(10)  # 10試行分の立ち続けたstep数を格納し、平均ステップ数を出力に利用\n",
    "        complete_episodes = 0  # 195step以上連続で立ち続けた試行数\n",
    "        episode_final = False  # 最後の試行フラグ\n",
    "        frames = []  # 最後の試行を動画にするために画像を格納する変数\n",
    "\n",
    "        for episode in range(NUM_EPISODES):  # 最大試行数分繰り返す\n",
    "            observation = self.env.reset()  # 環境の初期化\n",
    "\n",
    "            state = observation  # 観測をそのまま状態sとして使用\n",
    "            state = torch.from_numpy(state).type(\n",
    "                torch.FloatTensor)  # NumPy変数をPyTorchのテンソルに変換\n",
    "            state = torch.unsqueeze(state, 0)  # size 4をsize 1x4に変換\n",
    "\n",
    "            for step in range(MAX_STEPS):  # 1エピソードのループ\n",
    "\n",
    "                if episode_final is True:  # 最終試行ではframesに各時刻の画像を追加していく\n",
    "                    frames.append(self.env.render(mode='rgb_array'))\n",
    "\n",
    "                action = self.agent.get_action(state, episode)  # 行動を求める\n",
    "\n",
    "                # 行動a_tの実行により、s_{t+1}とdoneフラグを求める\n",
    "                # actionから.item()を指定して、中身を取り出す\n",
    "                observation_next, _, done, _ = self.env.step(\n",
    "                    action.item())  # rewardとinfoは使わないので_にする\n",
    "\n",
    "                # 報酬を与える。さらにepisodeの終了評価と、state_nextを設定する\n",
    "                if done:  # ステップ数が200経過するか、一定角度以上傾くとdoneはtrueになる\n",
    "                    state_next = None  # 次の状態はないので、Noneを格納\n",
    "\n",
    "                    # 直近10episodeの立てたstep数リストに追加\n",
    "                    episode_10_list = np.hstack(\n",
    "                        (episode_10_list[1:], step + 1))\n",
    "\n",
    "                    if step < 195:\n",
    "                        reward = torch.FloatTensor(\n",
    "                            [-1.0])  # 途中でこけたら罰則として報酬-1を与える\n",
    "                        complete_episodes = 0  # 連続成功記録をリセット\n",
    "                    else:\n",
    "                        reward = torch.FloatTensor([1.0])  # 立ったまま終了時は報酬1を与える\n",
    "                        complete_episodes = complete_episodes + 1  # 連続記録を更新\n",
    "                else:\n",
    "                    reward = torch.FloatTensor([0.0])  # 普段は報酬0\n",
    "                    state_next = observation_next  # 観測をそのまま状態とする\n",
    "                    state_next = torch.from_numpy(state_next).type(\n",
    "                        torch.FloatTensor)  # numpy変数をPyTorchのテンソルに変換\n",
    "                    state_next = torch.unsqueeze(state_next, 0)  # size 4をsize 1x4に変換\n",
    "\n",
    "                # メモリに経験を追加\n",
    "                self.agent.memorize(state, action, state_next, reward)\n",
    "\n",
    "                # Experience ReplayでQ関数を更新する\n",
    "                self.agent.update_q_function()\n",
    "\n",
    "                # 観測の更新\n",
    "                state = state_next\n",
    "\n",
    "                # 終了時の処理\n",
    "                if done:\n",
    "                    print('%d Episode: Finished after %d steps：10試行の平均step数 = %.1lf' % (\n",
    "                        episode, step + 1, episode_10_list.mean()))\n",
    "                    break\n",
    "\n",
    "            if episode_final is True:\n",
    "                # 動画を保存と描画\n",
    "                display_frames_as_gif(frames)\n",
    "                break\n",
    "\n",
    "            # 10連続で200step経ち続けたら成功\n",
    "            if complete_episodes >= 10:\n",
    "                print('10回連続成功')\n",
    "                episode_final = True  # 次の試行を描画を行う最終試行とする\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CartPoleを実行する環境のクラスです\n",
    "\n",
    "\n",
    "class Environment:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(ENV)  # 実行する課題を設定\n",
    "        num_states = self.env.observation_space.shape[0]  # 課題の状態数4を取得\n",
    "        num_actions = self.env.action_space.n  # CartPoleの行動（右に左に押す）の2を取得\n",
    "        self.agent = Agent(num_states, num_actions)  # 環境内で行動するAgentを生成\n",
    "\n",
    "        \n",
    "    def run(self):\n",
    "        '''実行'''\n",
    "        episode_10_list = np.zeros(10)  # 10試行分の立ち続けたstep数を格納し、平均ステップ数を出力に利用\n",
    "        complete_episodes = 0  # 195step以上連続で立ち続けた試行数\n",
    "        episode_final = False  # 最後の試行フラグ\n",
    "        frames = []  # 最後の試行を動画にするために画像を格納する変数\n",
    "\n",
    "        for episode in range(NUM_EPISODES):  # 最大試行数分繰り返す\n",
    "            observation = self.env.reset()  # 環境の初期化\n",
    "\n",
    "            state = observation  # 観測をそのまま状態sとして使用\n",
    "            state = torch.from_numpy(state).type(\n",
    "                torch.FloatTensor)  # NumPy変数をPyTorchのテンソルに変換\n",
    "            state = torch.unsqueeze(state, 0)  # size 4をsize 1x4に変換\n",
    "\n",
    "            for step in range(MAX_STEPS):  # 1エピソードのループ\n",
    "\n",
    "                if episode_final is True:  # 最終試行ではframesに各時刻の画像を追加していく\n",
    "                    frames.append(self.env.render(mode='rgb_array'))\n",
    "\n",
    "                action = self.agent.get_action(state, episode)  # 行動を求める\n",
    "                A ='''\n",
    "                # 行動a_tの実行により、s_{t+1}とdoneフラグを求める\n",
    "                # actionから.item()を指定して、中身を取り出す\n",
    "                observation_next, _, done, _ = self.env.step(\n",
    "                    action.item())  # rewardとinfoは使わないので_にする\n",
    "\n",
    "                # 報酬を与える。さらにepisodeの終了評価と、state_nextを設定する\n",
    "                if done:  # ステップ数が200経過するか、一定角度以上傾くとdoneはtrueになる\n",
    "                    state_next = None  # 次の状態はないので、Noneを格納\n",
    "\n",
    "                    # 直近10episodeの立てたstep数リストに追加\n",
    "                    episode_10_list = np.hstack(\n",
    "                        (episode_10_list[1:], step + 1))\n",
    "\n",
    "                    if step < 195:\n",
    "                        reward = torch.FloatTensor(\n",
    "                            [-1.0])  # 途中でこけたら罰則として報酬-1を与える\n",
    "                        complete_episodes = 0  # 連続成功記録をリセット\n",
    "                    else:\n",
    "                        reward = torch.FloatTensor([1.0])  # 立ったまま終了時は報酬1を与える\n",
    "                        complete_episodes = complete_episodes + 1  # 連続記録を更新\n",
    "                else:\n",
    "                    reward = torch.FloatTensor([0.0])  # 普段は報酬0\n",
    "                    state_next = observation_next  # 観測をそのまま状態とする\n",
    "                    state_next = torch.from_numpy(state_next).type(\n",
    "                        torch.FloatTensor)  # numpy変数をPyTorchのテンソルに変換\n",
    "                    state_next = torch.unsqueeze(state_next, 0)  # size 4をsize 1x4に変換\n",
    "\n",
    "                # メモリに経験を追加\n",
    "                self.agent.memorize(state, action, state_next, reward)\n",
    "\n",
    "                # Experience ReplayでQ関数を更新する\n",
    "                self.agent.update_q_function()\n",
    "\n",
    "                # 観測の更新\n",
    "                state = state_next\n",
    "\n",
    "                # 終了時の処理\n",
    "                if done:\n",
    "                    print('%d Episode: Finished after %d steps：10試行の平均step数 = %.1lf' % (\n",
    "                        episode, step + 1, episode_10_list.mean()))\n",
    "                    break\n",
    "\n",
    "            if episode_final is True:\n",
    "                # 動画を保存と描画\n",
    "                display_frames_as_gif(frames)\n",
    "                break\n",
    "\n",
    "            # 10連続で200step経ち続けたら成功\n",
    "            if complete_episodes >= 10:\n",
    "                print('10回連続成功')\n",
    "                episode_final = True  # 次の試行を描画を行う最終試行とする\n",
    "            '''\n",
    "            \n",
    "            return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=4, out_features=32, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main クラス\n",
    "cartpole_env = Environment()\n",
    "cartpole_env.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
